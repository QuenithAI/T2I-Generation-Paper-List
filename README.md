<div align="center">
  <a href="YOUR_OFFICIAL_WEBSITE_URL">
    <img src="assets/logo_run_cn.png" alt="QuenithAI Logo" width="200" height="200">
  </a>
</div>

<div align="center">
  <h1>Awesome Text-to-Image Generation by QuenithAI</h1>
  <p>A curated collection of papers, models, and resources for the field of Text-to-Image Generation.</p>
  <p>
    <a href="https://awesome.re"><img src="https://awesome.re/badge.svg" alt="Awesome"></a>
    &nbsp;
    <a href="https://github.com/QuenithAI/T2I-Generation-Paper-List/pulls"><img src="https://img.shields.io/badge/PRs-Welcome-brightgreen.svg?style=flat-square" alt="PRs Welcome"></a>
    &nbsp;
    <a href="https://github.com/QuenithAI/T2I-Generation-Paper-List/issues"><img src="https://img.shields.io/badge/Issues-Welcome-orange?style=flat-square" alt="Issues Welcome"></a>
  </p>
</div>

> [!NOTE]
> This repository is proudly maintained by the frontline research mentors at **QuenithAI (åº”è¾¾å­¦æœ¯)**. It aims to provide the most comprehensive and cutting-edge map of papers and technologies in the field of Text-to-Image generation.
>
> Your contributions are also vitalâ€”feel free to [open an issue](https://github.com/QuenithAI/T2I-Generation-Paper-List/issues) or [submit a pull request](https://github.com/QuenithAI/T2I-Generation-Paper-List/pulls) to become a collaborator of this repository. We expect your participation!
> 
>  If you require expert 1-on-1 guidance on your submissions to top-tier conferences and journals, we invite you to **contact us via [WeChat](assets/wechat.jpg) or [E-mail]((mailto:christzhaung@gmail.com))**.
>
>
> ---
>
> æœ¬ä»“åº“ç”± **ã€Œåº”è¾¾å­¦æœ¯ã€(QuenithAI)** çš„ä¸€çº¿ç§‘ç ”å¯¼å¸ˆå›¢é˜Ÿå€¾åŠ›æ‰“é€ å¹¶æŒç»­ç»´æŠ¤ï¼Œæ—¨åœ¨ä¸ºæ‚¨å‘ˆç°æ–‡ç”Ÿå›¾é¢†åŸŸæœ€å…¨é¢ã€æœ€å‰æ²¿çš„è®ºæ–‡ã€‚
>
> æ‚¨çš„è´¡çŒ®å¯¹æˆ‘ä»¬å’Œç¤¾åŒºæ¥è¯´è‡³å…³é‡è¦â€”â€”æˆ‘ä»¬è¯šé‚€æœ‰å¿—ä¹‹å£«é€šè¿‡ [open an issue](https://github.com/QuenithAI/T2I-Generation-Paper-List/issues) æˆ– [submit a pull request](https://github.com/QuenithAI/T2I-Generation-Paper-List/pulls) æ¥æˆä¸ºè¿™ä¸ªé¡¹ç›®çš„åˆä½œè€…ä¹‹ä¸€ï¼ŒæœŸå¾…æ‚¨çš„åŠ å…¥ï¼
> 
> å¦‚æœæ‚¨åœ¨å†²åˆºç§‘ç ”é¡¶ä¼šçš„é“è·¯ä¸Šéœ€è¦ä¸“ä¸šçš„1V1æŒ‡å¯¼ï¼Œæ¬¢è¿**é€šè¿‡[å¾®ä¿¡](assets/wechat.jpg)æˆ–[é‚®ä»¶](mailto:christzhaung@gmail.com)è”ç³»æˆ‘ä»¬**ã€‚


<details>
<summary><strong>âš¡ Latest Updates</strong></summary>

- **(Aug 21th, 2025)**: Add a new direction: [ğŸ¨ Personalized Image Generation](#personalized).
- **(Aug 20th, 2025)**: Initial commit and repository structure established.

</details>

---

## <span id="contents">ğŸ“š Table of Contents</span>
- [ğŸ“š Table of Contents](#-table-of-contents)
- [ğŸ“œ Papers \& Models](#-papers--models)
  - [âœï¸ Survey Papers](#ï¸-survey-papers)
  - [ğŸ–¼ï¸ Text-to-Image Generation](#ï¸-text-to-image-generation)
  - [ğŸ•¹ï¸ Conditional Image Generation](#ï¸-conditional-image-generation)
  - [ğŸ¨ Personalized Image Generation](#-personalized-image-generation)
  - [âœ‚ï¸ Image Editing](#ï¸-image-editing)
- [ğŸ—‚ï¸ Datasets](#ï¸-datasets)
- [ğŸ“ About Us](#-about-us)
- [ğŸ¤ Contributing](#-contributing)

---

## <span id="papers">ğŸ“œ Papers & Models</span>

### <span id="survey">âœï¸ Survey Papers</span>



[<small>â‡§ Back to ToC</small>](#contents)

### <span id="t2i">ğŸ–¼ï¸ Text-to-Image Generation</span>

<details>
<summary><h4>âœ¨ 2025</h4></summary>


<details>
<summary><h4>âœ… Published Papers</h4></summary>

* **[CVPR 2025]** ***PreciseCam:*** *Precise Camera Control for Text-to-Image Generation*<br>
   [![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2501.12910)
  [![Project Page](https://img.shields.io/badge/Project-Page-blue?style=for-the-badge&logo=googlechrome&logoColor=white)](https://graphics.unizar.es/projects/PreciseCam2024/)
  [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/edurnebernal/PreciseCam)
  [![Hugging Face](https://img.shields.io/badge/%F0%9F%A4%97-Hugging_Face-yellow?style=for-the-badge)](https://huggingface.co/edurnebb/PreciseCam)

* **[CVPR 2025]** ***Typeâ€‘R:*** *Automatically Retouching Typos for Textâ€‘toâ€‘Image Generation*<br>
   [![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/abs/2411.18159) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/CyberAgentAILab/Type-R) [![Hugging Face](https://img.shields.io/badge/%F0%9F%A4%97-Hugging_Face-yellow?style=for-the-badge)](https://huggingface.co/cyberagent/type-r)

* **[CVPR 2025]** ***Compassâ€¯Control:*** *Multi Object Orientation Control for Textâ€‘toâ€‘Image Generation*<br>
   [![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2504.06752) [![Project Page](https://img.shields.io/badge/Project-Page-blue?style=for-the-badge&logo=googlechrome&logoColor=white)](https://rishubhpar.github.io/CompassControl/)

* **[CVPR 2025]** ***GenerativeÂ Photography:*** *Sceneâ€‘Consistent Camera Control for Realistic Textâ€‘toâ€‘Image Synthesis*<br>
   [![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2412.02168) [![Project Page](https://img.shields.io/badge/Project-Page-blue?style=for-the-badge&logo=googlechrome&logoColor=white)](https://generative-photography.github.io/project/) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/pandayuanyu/generative-photography) [![Hugging Face](https://img.shields.io/badge/%F0%9F%A4%97-Hugging_Face-yellow?style=for-the-badge)](https://huggingface.co/pandaphd/generative_photography)

* **[CVPR 2025]** ***Oneâ€‘WayÂ Ticket:*** *Timeâ€‘Independent Unified Encoder for Distilling Textâ€‘toâ€‘Image Diffusion Models*<br>
   [![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://cvpr.thecvf.com/virtual/2025/poster/32579) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/sen-mao/Loopfree) [![Hugging Face](https://img.shields.io/badge/%F0%9F%A4%97-Hugging_Face-yellow?style=for-the-badge)](https://huggingface.co/senmaonk/loopfree-sd2.1-base)

* **[CVPR 2025]** ***Textâ€¯Embedding is Not All You Need:*** *Attention Control for Textâ€‘toâ€‘Image Semantic Alignment with Text Selfâ€‘Attention Maps*<br>  [![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2411.15236) [![Project Page](https://img.shields.io/badge/Project-Page-blue?style=for-the-badge&logo=googlechrome&logoColor=white)](https://t-sam-diffusion.github.io/) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/t-sam-diffusion/code)

* **[CVPR 2025]** ***TowardsÂ Uncertainty:*** *Understanding and Quantifying Uncertainty for Textâ€‘toâ€‘Image Generation*<br>  [![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2412.03178) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/ENSTA-U2IS-AI/Uncertainty_diffusion)

* **[CVPR 2025]** ***ResponsibleÂ Diffusion:*** *Plugâ€‘andâ€‘Play Interpretable Responsible Textâ€‘toâ€‘Image Generation via Dualâ€‘Space Multiâ€‘faceted Concept Control*<br>  [![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2503.18324) [![Project Page](https://img.shields.io/badge/Project-Page-blue?style=for-the-badge&logo=googlechrome&logoColor=white)](https://basim-azam.github.io/responsiblediffusion/) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/basim-azam/responsiblediffusion)

* **[CVPR 2025]** ***MakeÂ ItÂ Count:*** *Textâ€‘toâ€‘Image Generation with an Accurate Number of Objects*<br>  [![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2406.10210) [![Project Page](https://img.shields.io/badge/Project-Page-blue?style=for-the-badge&logo=googlechrome&logoColor=white)](https://make-it-count-paper.github.io/) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/Litalby1/make-it-count)

* **[CVPR 2025]** ***MCCD:*** *Multiâ€‘Agent Collaborationâ€‘based Compositional Diffusion for Complex Textâ€‘toâ€‘Image Generation*<br>  [![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2505.02648)

* **[CVPR 2025]** ***Debiasâ€‘SD:*** *Rethinking Training for Deâ€‘biasing Textâ€‘toâ€‘Image Generation: Unlocking the Potential of Stable Diffusion*<br>  [![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2408.12692)

* **[CVPR 2025]** ***ShapeWords:*** *Guiding Textâ€‘toâ€‘Image Synthesis with 3D Shapeâ€‘Aware Prompts*<br>  [![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2412.02912) [![Project Page](https://img.shields.io/badge/Project-Page-blue?style=for-the-badge&logo=googlechrome&logoColor=white)](https://lodurality.github.io/shapewords/) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/lodurality/shapewords_paper_code) [![Hugging Face](https://img.shields.io/badge/%F0%9F%A4%97-Hugging_Face-yellow?style=for-the-badge)](https://huggingface.co/spaces/dmpetrov/shapewords)

* **[CVPR 2025]** ***SnapGen:*** *Taming Highâ€‘Resolution Textâ€‘toâ€‘Image Models for Mobile Devices with Efficient Architectures and Training*<br>  [![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2412.09619) [![Project Page](https://img.shields.io/badge/Project-Page-blue?style=for-the-badge&logo=googlechrome&logoColor=white)](https://snap-research.github.io/snapgen/)

* **[CVPR 2025]** ***STORM:*** *Spatial Transport Optimization by Repositioning Attention Map for Trainingâ€‘Free Textâ€‘toâ€‘Image Synthesis*<br>  [![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2503.22168) [![Project Page](https://img.shields.io/badge/Project-Page-blue?style=for-the-badge&logo=googlechrome&logoColor=white)](https://micv-yonsei.github.io/storm2025/) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/MICV-yonsei/STORM)

* **[CVPR 2025]** ***Focusâ€‘Nâ€‘Fix:*** *Regionâ€‘Aware Fineâ€‘Tuning for Textâ€‘toâ€‘Image Generation*<br>  [![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2501.06481)

* **[CVPR 2025]** ***SILMM:*** *Selfâ€‘Improving Large Multimodal Models for Compositional Textâ€‘toâ€‘Image Generation*<br>  [![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2412.05818) [![Project Page](https://img.shields.io/badge/Project-Page-blue?style=for-the-badge&logo=googlechrome&logoColor=white)](https://silmm.github.io/) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/LgQu/SILMM)

* **[CVPR 2025]** ***GLoCE:*** *Localized Concept Erasure for Textâ€‘toâ€‘Image Diffusion Models Using Trainingâ€‘Free Gated Lowâ€‘Rank Adaptation*<br>  [![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2503.12356) [![Project Page](https://img.shields.io/badge/Project-Page-blue?style=for-the-badge&logo=googlechrome&logoColor=white)](https://gl-oce.github.io/) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/Hyun1A/GLoCE)

* **[CVPR 2025]** ***Selfâ€‘Cross Guidance:*** *Selfâ€‘Cross Diffusion Guidance for Textâ€‘toâ€‘Image Synthesis of Similar Subjects*<br>  [![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2411.18936) [![Project Page](https://img.shields.io/badge/Project-Page-blue?style=for-the-badge&logo=googlechrome&logoColor=white)](https://selfcross-guidance.github.io/) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/mengtang-lab/selfcross-guidance)

* **[CVPR 2025]** ***NoiseÂ Diffusion:*** *Enhancing Semantic Faithfulness in Textâ€‘toâ€‘Image Synthesis*<br>  [![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2411.16503) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/Bomingmiao/NoiseDiffusion)

* **[CVPR 2025]** ***PromptSampler:*** *Learning to Sample Effective and Diverse Prompts for Textâ€‘toâ€‘Image Generation*<br>  [![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2410.07838) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/dbsxodud-11/PAG)

* **[CVPR 2025]** ***STEREO:*** *A Twoâ€‘Stage Framework for Adversarially Robust Concept Erasing from Textâ€‘toâ€‘Image Diffusion Models*<br>  [![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2408.16807) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/koushiksrivats/robust-concept-erasing)

* **[CVPR 2025]** ***MinorityPrompt:*** *Minorityâ€‘Focused Textâ€‘toâ€‘Image Generation via Prompt Optimization*<br>  [![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2411.16503) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/soobin-um/MinorityPrompt)

* **[CVPR 2025]** ***DistillT5:*** *Scaling Down Text Encoders of Textâ€‘toâ€‘Image Diffusion Models*<br>  [![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2503.19897) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/LifuWang-66/DistillT5)

* **[CVPR 2025]** ***TIU:*** *The Illusion of Unlearning: The Unstable Nature of Machine Unlearning in Textâ€‘toâ€‘Image Diffusion Models*<br>  [![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/???) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/NGK2110/TIU)

* **[CVPR 2025]** ***Fuseâ€‘DiT:*** *Exploring the Deep Fusion of Large Language Models and Diffusion Transformers for Textâ€‘toâ€‘Image Synthesis*<br>  [![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/???) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/tang-bd/fuse-dit) [![Hugging Face](https://img.shields.io/badge/%F0%9F%A4%97-Hugging_Face-yellow?style=for-the-badge)](https://huggingface.co/ooutlierr/fuse-dit)

* **[CVPR 2025]** **Detectâ€‘andâ€‘Guide:** *Selfâ€‘regulation of Diffusion Models for Safe Textâ€‘toâ€‘Image Generation via Guideline Token Optimization*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2503.15197)

* **[CVPR 2025]** **Multiâ€‘GroupÂ T2I:** *Multiâ€‘Group Proportional Representations for Textâ€‘toâ€‘Image Models*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://openaccess.thecvf.com/content/CVPR2025/papers/Jung_Multi-Group_Proportional_Representations_for_Text-to-Image_Models_CVPR_2025_paper.pdf) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/sangwon-jung94/mpr-t2i)

* **[CVPR 2025]** **VODiff:** *Controlling Object Visibility Order in Textâ€‘toâ€‘Image Generation*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/???) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/dliang293/VODiff)

* **[CVPR 2025]** *Large-Scale Text-to-Image Model with Inpainting is a Zero-Shot Subject-Driven Image Generator*<br>
  [![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://openaccess.thecvf.com/content/CVPR2025/html/Shin_Large-Scale_Text-to-Image_Model_with_Inpainting_is_a_Zero-Shot_Subject-Driven_Image_CVPR_2025_paper.html) [![Project Page](https://img.shields.io/badge/Project-Page-blue?style=for-the-badge&logo=googlechrome&logoColor=white)](https://diptychprompting.github.io/) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/chaehunshin/DiptychPrompting) [![Hugging Face](https://img.shields.io/badge/%F0%9F%A4%97-Hugging_Face-yellow?style=for-the-badge)](https://huggingface.co/alimama-creative/FLUX.1-dev-Controlnet-Inpainting-Beta)

* **[CVPR 2025]** *Sixâ€‘CD: Benchmarking Concept Removals for Text-to-image Diffusion Models*<br>
  [![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://openaccess.thecvf.com/content/CVPR2025/html/Ren_Six-CD_Benchmarking_Concept_Removals_for_Text-to-image_Diffusion_Models_CVPR_2025_paper.html) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/Artanisax/Six-CD)

* **[CVPR 2025]** *ConceptGuard: Continual Personalized Text-to-Image Generation with Forgetting and Confusion Mitigation*<br>
  [![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://openaccess.thecvf.com/content/CVPR2025/html/Guo_ConceptGuard_Continual_Personalized_Text-to-Image_Generation_with_Forgetting_and_Confusion_Mitigation_CVPR_2025_paper.html)

* **[CVPR 2025]** *ChatGen: Automatic Text-to-Image Generation From FreeStyle Chatting*<br>
  [![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://openaccess.thecvf.com/content/CVPR2025/html/Jia_ChatGen_Automatic_Text-to-Image_Generation_From_FreeStyle_Chatting_CVPR_2025_paper.html) [![Project Page](https://img.shields.io/badge/Project-Page-blue?style=for-the-badge&logo=googlechrome&logoColor=white)](https://chengyou-jia.github.io/ChatGen-Home/) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/chengyou-jia/ChatGen) [![Hugging Face](https://img.shields.io/badge/%F0%9F%A4%97-Hugging_Face-yellow?style=for-the-badge)](https://huggingface.co/ChengyouJia/ChatGen-Base-8B)

* **[ICLR 2025]** **ImprovingÂ Longâ€‘Text Alignment:** *Improving Longâ€‘Text Alignment for Textâ€‘toâ€‘Image Diffusion Models*<br>
[![Paper](https://img.shields.io/badge/Paper-OpenReview-D15E5E?style=for-the-badge&logo=open-collective)](https://openreview.net/forum?id=2ZK8zyIt7o) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/luping-liu/LongAlign)

* **[ICLR 2025]** **ITTA:** *InformationÂ Theoretic Textâ€‘toâ€‘Image Alignment*<br>
[![Paper](https://img.shields.io/badge/Paper-OpenReview-D15E5E?style=for-the-badge&logo=open-collective)](https://openreview.net/forum?id=Ugs2W5XFFo) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/Chao0511/mitune)

* **[ICLR 2025]** **Meissonic:** *Revitalizing Masked Generative Transformers for Efficient Highâ€‘Resolution Textâ€‘toâ€‘Image Synthesis*<br>
[![Paper](https://img.shields.io/badge/Paper-OpenReview-D15E5E?style=for-the-badge&logo=open-collective)](https://openreview.net/forum?id=GJsuYHhAga) [![Project Page](https://img.shields.io/badge/Project-Page-blue?style=for-the-badge&logo=googlechrome&logoColor=white)](https://sites.google.com/view/meissonic/home) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/viiika/Meissonic) [![Hugging Face](https://img.shields.io/badge/%F0%9F%A4%97-Hugging_Face-yellow?style=for-the-badge)](https://huggingface.co/MeissonFlow/Meissonic)

* **[ICLR 2025]** **PaRa:** *Personalizing Textâ€‘toâ€‘Image Diffusion via Parameter Rank Reduction*<br>
[![Paper](https://img.shields.io/badge/Paper-OpenReview-D15E5E?style=for-the-badge&logo=open-collective)](https://openreview.net/forum?id=KZgo2YQbhc)

* **[ICLR 2025]** **Fluid:** *Scaling Autoregressive Textâ€‘toâ€‘image Generative Models with Continuous Tokens*<br>
[![Paper](https://img.shields.io/badge/Paper-OpenReview-D15E5E?style=for-the-badge&logo=open-collective)](https://openreview.net/forum?id=jQP5o1VAVc)

* **[ICLR 2025]** **Promptâ€‘Pruning:** *Not All Prompts Are Made Equal â€“ Promptâ€‘based Pruning of Textâ€‘toâ€‘Image Diffusion Models*<br>
[![Paper](https://img.shields.io/badge/Paper-OpenReview-D15E5E?style=for-the-badge&logo=open-collective)](https://openreview.net/forum?id=3BhZCfJ73Y) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/rezashkv/diffusion_pruning) [![Hugging Face](https://img.shields.io/badge/%F0%9F%A4%97-Hugging_Face-yellow?style=for-the-badge)](https://huggingface.co/rezashkv/diffusion_pruning)

* **[ICLR 2025]** **DenoisingÂ ARÂ Transformers:** *Denoising Autoregressive Transformers for Scalable Textâ€‘toâ€‘Image Generation*<br>
[![Paper](https://img.shields.io/badge/Paper-OpenReview-D15E5E?style=for-the-badge&logo=open-collective)](https://openreview.net/forum?id=amDkNPVWcn)

* **[ICLR 2025]** **ProgressiveÂ Compositionality:** *Progressive Compositionality in Textâ€‘toâ€‘Image Generative Models*<br>
[![Paper](https://img.shields.io/badge/Paper-OpenReview-D15E5E?style=for-the-badge&logo=open-collective)](https://openreview.net/forum?id=S85PP4xjFD) [![Project Page](https://img.shields.io/badge/Project-Page-blue?style=for-the-badge&logo=googlechrome&logoColor=white)](https://evansh666.github.io/EvoGen_Page/) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/evansh666/EvoGen)

* **[ICLR 2025]** **ClassifierÂ Scores:** *Mining your own secrets: Diffusion Classifier Scores for Continual Personalization of Textâ€‘toâ€‘Image Diffusion Models*<br>
[![Paper](https://img.shields.io/badge/Paper-OpenReview-D15E5E?style=for-the-badge&logo=open-collective)](https://openreview.net/forum?id=hUdLs6TqZL) [![Project Page](https://img.shields.io/badge/Project-Page-blue?style=for-the-badge&logo=googlechrome&logoColor=white)](https://srvcodes.github.io/continual_personalization)

* **[ICLR 2025]** **Engagement:** *Measuring and Improving Engagement of Textâ€‘toâ€‘Image Generation Models*<br>
[![Paper](https://img.shields.io/badge/Paper-OpenReview-D15E5E?style=for-the-badge&logo=open-collective)](https://openreview.net/forum?id=TmCcNuo03f) [![Project Page](https://img.shields.io/badge/Project-Page-blue?style=for-the-badge&logo=googlechrome&logoColor=white)](https://behavior-in-the-wild.github.io/image-engagement)

* **[ICLR 2025]** **ResidualÂ GateÂ Eraser:** *Concept Pinpoint Eraser for Textâ€‘to-image Diffusion Models via Residual Attention Gate*<br>
[![Paper](https://img.shields.io/badge/Paper-OpenReview-D15E5E?style=for-the-badge&logo=open-collective)](https://openreview.net/forum?id=ZRDhBwKs7l) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/Hyun1A/CPE)

* **[ICLR 2025]** **RandomÂ Seeds:** *Enhancing Compositional Textâ€‘toâ€‘Image Generation with Reliable Random Seeds*<br>
[![Paper](https://img.shields.io/badge/Paper-OpenReview-D15E5E?style=for-the-badge&logo=open-collective)](https://openreview.net/forum?id=5BSlakturs) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/doub7e/Reliable-Random-Seeds)

* **[ICLR 2025]** **Oneâ€‘Promptâ€‘Oneâ€‘Story:** *Freeâ€‘Lunch Consistent Textâ€‘toâ€‘Image Generation Using a Single Prompt*<br>
[![Paper](https://img.shields.io/badge/Paper-OpenReview-D15E5E?style=for-the-badge&logo=open-collective)](https://openreview.net/forum?id=cD1kl2QKv1) [![Project Page](https://img.shields.io/badge/Project-Page-blue?style=for-the-badge&logo=googlechrome&logoColor=white)](https://byliutao.github.io/1Prompt1Story.github.io/) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/byliutao/1Prompt1Story)

* **[ICLR 2025]** **YouÂ OnlyÂ SampleÂ Once:** *Taming Oneâ€‘Step Textâ€‘toâ€‘Image Synthesis by Selfâ€‘Cooperative Diffusion GANs*<br>
[![Paper](https://img.shields.io/badge/Paper-OpenReview-D15E5E?style=for-the-badge&logo=open-collective)](https://openreview.net/forum?id=T7bmHkwzS6) [![Project Page](https://img.shields.io/badge/Project-Page-blue?style=for-the-badge&logo=googlechrome&logoColor=white)](https://yoso-t2i.github.io) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/Luo-Yihong/YOSO) [![Hugging Face](https://img.shields.io/badge/%F0%9F%A4%97-Hugging_Face-yellow?style=for-the-badge)](https://huggingface.co/Luo-Yihong/yoso_pixart512)

* **[ICLR 2025]** **CopyrightÂ Revisiting:** *Rethinking Artistic Copyright Infringements in the Era of Textâ€‘toâ€‘Image Generative Models*<br>
[![Paper](https://img.shields.io/badge/Paper-OpenReview-D15E5E?style=for-the-badge&logo=open-collective)](https://openreview.net/forum?id=0OTVNEm9N4)

* **[ICLR 2025]** **ConceptÂ CombinationÂ Erasing:** *Erasing Concept Combination from Textâ€‘toâ€‘Image Diffusion Model*<br>
[![Paper](https://img.shields.io/badge/Paper-OpenReview-D15E5E?style=for-the-badge&logo=open-collective)](https://openreview.net/forum?id=OBjF5I4PWg)

* **[ICLR 2025]** **Crossâ€‘AttentionÂ Patterns:** *Crossâ€‘Attention Head Position Patterns Can Align with Human Visual Concepts in Textâ€‘toâ€‘Image Generative Models*<br>
[![Paper](https://img.shields.io/badge/Paper-OpenReview-D15E5E?style=for-the-badge&logo=open-collective)](https://openreview.net/forum?id=1vggIT5vvj) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/SNU-DRL/HRV)

* **[ICLR 2025]** **TIGeR:** *Unifying Textâ€‘toâ€‘Image Generation and Retrieval with Large Multimodal Models*<br>
[![Paper](https://img.shields.io/badge/Paper-OpenReview-D15E5E?style=for-the-badge&logo=open-collective)](https://openreview.net/forum?id=mr2icR6dpD) [![Project Page](https://img.shields.io/badge/Project-Page-blue?style=for-the-badge&logo=googlechrome&logoColor=white)](https://tiger-t2i.github.io/) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/LgQu/TIGeR)

* **[ICLR 2025]** **DGQ:** *Distributionâ€‘Aware Group Quantization for Textâ€‘toâ€‘Image Diffusion Models*<br>
[![Paper](https://img.shields.io/badge/Paper-OpenReview-D15E5E?style=for-the-badge&logo=open-collective)](https://openreview.net/forum?id=ZyNEr7Xw5L) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/ugonfor/DGQ)

* **[ICLR 2025]** **JacobiÂ Decoding:** *Accelerating Autoâ€‘regressive Textâ€‘toâ€‘Image Generation with Trainingâ€‘free Speculative Jacobi Decoding*<br>
[![Paper](https://img.shields.io/badge/Paper-OpenReview-D15E5E?style=for-the-badge&logo=open-collective)](https://openreview.net/forum?id=LZfjxvqw0N) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/tyshiwo1/Accelerating-T2I-AR-with-SJD)

* **[ICLR 2025]** **PTâ€‘T2I/V:** *An Efficient Proxyâ€‘Tokenized Diffusion Transformer for Textâ€‘toâ€‘Image/Video Task*<br>
[![Paper](https://img.shields.io/badge/Paper-OpenReview-D15E5E?style=for-the-badge&logo=open-collective)](https://openreview.net/forum?id=lTrrnNdkOX) [![Project Page](https://img.shields.io/badge/Project-Page-blue?style=for-the-badge&logo=googlechrome&logoColor=white)](https://360cvgroup.github.io/Qihoo-T2X/) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/360CVGroup/Qihoo-T2X)

* **[ICLR 2025]** **GeckoÂ Evaluation:** *Revisiting Textâ€‘toâ€‘Image Evaluation with Gecko: on Metrics, Prompts, and Human Rating*<br>
[![Paper](https://img.shields.io/badge/Paper-OpenReview-D15E5E?style=for-the-badge&logo=open-collective)](https://openreview.net/forum?id=Im2neAMlre) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/google-deepmind/gecko_benchmark_t2i)

* **[ICLR 2025]** **SANA:** *Efficient Highâ€‘Resolution Textâ€‘toâ€‘Image Synthesis with Linear Diffusion Transformers*<br>
[![Paper](https://img.shields.io/badge/Paper-OpenReview-D15E5E?style=for-the-badge&logo=open-collective)](https://openreview.net/forum?id=N8Oj1XhtYZ) [![Project Page](https://img.shields.io/badge/Project-Page-blue?style=for-the-badge&logo=googlechrome&logoColor=white)](https://nvlabs.github.io/Sana) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/NVlabs/Sana) [![Hugging Face](https://img.shields.io/badge/%F0%9F%A4%97-Hugging_Face-yellow?style=for-the-badge)](https://huggingface.co/Efficient-Large-Model/Sana_1600M_1024px_diffusers)

* **[ICLR 2025]** **RectifiedÂ Flow:** *Textâ€‘toâ€‘Image Rectified Flow as Plugâ€‘andâ€‘Play Priors*<br>
[![Paper](https://img.shields.io/badge/Paper-OpenReview-D15E5E?style=for-the-badge&logo=open-collective)](https://openreview.net/forum?id=SzPZK856iI) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/yangxiaofeng/rectified_flow_prior)

* **[ICLR 2025]** **HumanÂ FeedbackÂ Filtering:** *Automated Filtering of Human Feedback Data for Aligning Textâ€‘toâ€‘Image Diffusion Models*<br>
[![Paper](https://img.shields.io/badge/Paper-OpenReview-D15E5E?style=for-the-badge&logo=open-collective)](https://openreview.net/forum?id=8jvVNPHtVJ)

* **[ICLR 2025]** **SAFREE:** *Trainingâ€‘Free and Adaptive Guard for Safe Textâ€‘toâ€‘Image and Video Generation*<br>
[![Paper](https://img.shields.io/badge/Paper-OpenReview-D15E5E?style=for-the-badge&logo=open-collective)](https://openreview.net/forum?id=hgTFotBRKl) [![Project Page](https://img.shields.io/badge/Project-Page-blue?style=for-the-badge&logo=googlechrome&logoColor=white)](https://safree-safe-t2i-t2v.github.io) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/jaehong31/SAFREE)

* **[ICLR 2025]** **IterComp:** *Iterative Compositionâ€‘Aware Feedback Learning from Model Gallery for Textâ€‘toâ€‘Image Generation*<br>
[![Paper](https://img.shields.io/badge/Paper-OpenReview-D15E5E?style=for-the-badge&logo=open-collective)](https://openreview.net/forum?id=4w99NAikOE) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/YangLing0818/IterComp) [![Hugging Face](https://img.shields.io/badge/%F0%9F%A4%97-Hugging_Face-yellow?style=for-the-badge)](https://huggingface.co/comin/IterComp)

* **[ICLR 2025]** **ScImage:** *How good are multimodal large language models at scientific textâ€‘toâ€‘image generation?*<br>
[![Paper](https://img.shields.io/badge/Paper-OpenReview-D15E5E?style=for-the-badge&logo=open-collective)](https://openreview.net/forum?id=ugyqNEOjoU) [![Hugging Face](https://img.shields.io/badge/%F0%9F%A4%97-Hugging_Face-yellow?style=for-the-badge)](https://huggingface.co/datasets/casszhao/ScImage)

* **[ICLR 2025]** **ScoreÂ Distillation:** *Guided Score Identity Distillation for Dataâ€‘Free Oneâ€‘Step Textâ€‘toâ€‘Image Generation*<br>
[![Paper](https://img.shields.io/badge/Paper-OpenReview-D15E5E?style=for-the-badge&logo=open-collective)](https://openreview.net/forum?id=HMVDiaWMwM) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/mingyuanzhou/SiD-LSG) [![Hugging Face](https://img.shields.io/badge/%F0%9F%A4%97-Hugging_Face-yellow?style=for-the-badge)](https://huggingface.co/UT-Austin-PML/SiD-LSG)

* **[ICLR 2025]** **CausalÂ Variation:** *Evaluating Semantic Variation in Textâ€‘toâ€‘Image Synthesis: A Causal Perspective*<br>
[![Paper](https://img.shields.io/badge/Paper-OpenReview-D15E5E?style=for-the-badge&logo=open-collective)](https://openreview.net/forum?id=NWb128pSCb) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/zhuxiangru/SemVarBench)

</details>

<details>
<summary><h4>ğŸ’¡ Pre-Print Papers</h4></summary>


- [Plot'n Polish: Zeroâ€‘shot Story Visualization and Disentangled Editing with Textâ€‘toâ€‘Image Diffusion Models](http://arxiv.org/abs/2509.04446v1) [![Project Page](https://img.shields.io/badge/Project-Page-blue?logo=website)](https://plotnpolish.github.io)
- [Skywork UniPicÂ 2.0: Building Kontext Model with OnlineÂ RL for Unified Multimodal Model](http://arxiv.org/abs/2509.04548v1) [![GitHub Stars](https://img.shields.io/github/stars/SkyworkAI/UniPic?style=social)](https://github.com/SkyworkAI/UniPic) [![Project Page](https://img.shields.io/badge/Project-Page-blue?logo=website)](https://unipic-v2.github.io/)
- [PromptEnhancer: A Simple Approach to Enhance Textâ€‘toâ€‘Image Models via Chainâ€‘ofâ€‘Thought Prompt Rewriting](http://arxiv.org/abs/2509.04545v1)
- [FromÂ EditorÂ toÂ DenseÂ GeometryÂ Estimator](http://arxiv.org/abs/2509.04338v1)
- [NoisyÂ LabelÂ RefinementÂ withÂ SemanticallyÂ ReliableÂ SyntheticÂ Images](http://arxiv.org/abs/2509.04298v1)
- [MEPG:Multiâ€‘Expert Planning and Generation for Compositionallyâ€‘Rich Image Generation](http://arxiv.org/abs/2509.04126v1)
- [EasierÂ PaintingÂ ThanÂ Thinking:Â CanÂ Textâ€‘toâ€‘ImageÂ ModelsÂ SetÂ theÂ Stage,Â butÂ NotÂ DirectÂ theÂ Play?](http://arxiv.org/abs/2509.03516v1)
- [Fidelityâ€‘preservingÂ enhancementÂ ofÂ ptychographyÂ withÂ foundationalÂ textâ€‘toâ€‘imageÂ models](http://arxiv.org/abs/2509.04513v1)
- [ExploringÂ DiffusionÂ ModelsÂ forÂ GenerativeÂ ForecastingÂ ofÂ FinancialÂ Charts](http://arxiv.org/abs/2509.02308v1)
- [Dataâ€‘DrivenÂ LossÂ FunctionsÂ forÂ Inferenceâ€‘TimeÂ OptimizationÂ inÂ Textâ€‘toâ€‘ImageÂ Generation](http://arxiv.org/abs/2509.02295v1)
- [PaletteÂ AlignedÂ ImageÂ Diffusion](http://arxiv.org/abs/2509.02000v1)
- [Drawâ€‘Inâ€‘Mind: Learning Precise Image Editing via Chainâ€‘ofâ€‘Thought Imagination](http://arxiv.org/abs/2509.01986v1) [![GitHub Stars](https://img.shields.io/github/stars/showlab/DIM?style=social)](https://github.com/showlab/DIM)
- [DiscreteÂ NoiseÂ InversionÂ forÂ Nextâ€‘scaleÂ AutoregressiveÂ Textâ€‘basedÂ ImageÂ Editing](http://arxiv.org/abs/2509.01984v2)
- [Qâ€‘Sched:Â PushingÂ theÂ BoundariesÂ ofÂ Fewâ€‘StepÂ DiffusionÂ ModelsÂ withÂ Quantizationâ€‘AwareÂ Scheduling](http://arxiv.org/abs/2509.01624v1)
- [RealMat: Realistic Materials with Diffusion and Reinforcement Learning](http://arxiv.org/abs/2509.01134v1)
- [CompSlider: Compositional Slider for Disentangled Multipleâ€‘Attribute Image Generation](http://arxiv.org/abs/2509.01028v2)
- [Prompting Away Stereotypes? Evaluating Bias in Textâ€‘toâ€‘Image Models for Occupations](http://arxiv.org/abs/2509.00849v1)
- [Multiâ€‘LevelÂ CLSÂ TokenÂ FusionÂ forÂ ContrastiveÂ LearningÂ inÂ EndoscopyÂ ImageÂ Classification](http://arxiv.org/abs/2509.00752v1)
- [HADIS: Hybrid Adaptive Diffusion Model Serving for Efficient Textâ€‘toâ€‘Image Generation](http://arxiv.org/abs/2509.00642v1)
- [AMCR: A Framework for Assessing and Mitigating Copyright Risks in Generative Models](http://arxiv.org/abs/2509.00641v1)
- [ReusingÂ ComputationÂ inÂ Textâ€‘toâ€‘ImageÂ DiffusionÂ forÂ EfficientÂ GenerationÂ ofÂ ImageÂ Sets](http://arxiv.org/abs/2508.21032v1)
- [UnderstandingÂ andÂ evaluatingÂ computerÂ visionÂ modelsÂ throughÂ theÂ lensÂ ofÂ counterfactuals](http://arxiv.org/abs/2508.20881v1)
- [Prefâ€‘GRPO: Pairwise Preference Rewardâ€‘based GRPO for Stable Textâ€‘toâ€‘Image Reinforcement Learning](http://arxiv.org/abs/2508.20751v1)
- [Persode: Personalized Visual Journaling with Episodic Memoryâ€‘Aware AIÂ Agent](http://arxiv.org/abs/2508.20585v1)
- [Describe,Â Don'tÂ Dictate:Â SemanticÂ ImageÂ EditingÂ withÂ NaturalÂ LanguageÂ Intent](http://arxiv.org/abs/2508.20505v1)
- [Safeâ€‘Control:Â AÂ SafetyÂ PatchÂ forÂ MitigatingÂ UnsafeÂ ContentÂ inÂ Textâ€‘toâ€‘ImageÂ GenerationÂ Models](http://arxiv.org/abs/2508.21099v1)
- [NotÂ EveryÂ GiftÂ ComesÂ inÂ GoldÂ PaperÂ orÂ withÂ aÂ RedÂ Ribbon: Exploring Color Perception inÂ Textâ€‘toâ€‘ImageÂ Models](http://arxiv.org/abs/2508.19791v1)
- [MonoReliefÂ V2:Â LeveragingÂ RealÂ DataÂ forÂ Highâ€‘FidelityÂ MonocularÂ ReliefÂ Recovery](http://arxiv.org/abs/2508.19555v1)
- [Allâ€‘inâ€‘OneÂ SliderÂ forÂ AttributeÂ ManipulationÂ inÂ DiffusionÂ Models](http://arxiv.org/abs/2508.19195v1) 
- [Visualâ€‘CoG: Stageâ€‘Aware Reinforcement Learning with ChainÂ ofÂ Guidance for Textâ€‘toâ€‘Image Generation](http://arxiv.org/abs/2508.18032v2)
- [CEIDM: A Controlled Entity and Interaction Diffusion Model for Enhanced Textâ€‘toâ€‘Image Generation](http://arxiv.org/abs/2508.17760v1)
- [InstantÂ PreferenceÂ AlignmentÂ forÂ Textâ€‘toâ€‘ImageÂ DiffusionÂ Models](http://arxiv.org/abs/2508.17718v1)
- [T2Iâ€‘ReasonBench: Benchmarking Reasoningâ€‘Informed Textâ€‘toâ€‘ImageÂ Generation](http://arxiv.org/abs/2508.17472v1)
- [BiasÂ AmplificationÂ inÂ StableÂ Diffusion'sÂ RepresentationÂ ofÂ StigmaÂ ThroughÂ SkinÂ TonesÂ andÂ TheirÂ Homogeneity](http://arxiv.org/abs/2508.17465v1)
- [AnÂ LLMâ€‘LVLMÂ DrivenÂ AgentÂ forÂ IterativeÂ andÂ Fineâ€‘GrainedÂ ImageÂ Editing](http://arxiv.org/abs/2508.17435v1)
- [HiCache: Trainingâ€‘free Acceleration of Diffusion Models via Hermite Polynomialâ€‘based Feature Caching](http://arxiv.org/abs/2508.16984v1)
- [Deltaâ€‘SVD: Efficient Compression for Personalized Textâ€‘toâ€‘ImageÂ Models](http://arxiv.org/abs/2508.16863v1)
- [Improving Performance, Robustness, and Fairness of Radiographic AIÂ Models with Finelyâ€‘Controllable SyntheticÂ Data](http://arxiv.org/abs/2508.16783v1)
- [A Framework for Benchmarking Fairnessâ€‘Utility Tradeâ€‘offs inÂ Textâ€‘toâ€‘Image Models viaÂ ParetoÂ Frontiers](http://arxiv.org/abs/2508.16752v1)
- [Aâ€‘FloPS: Accelerating Diffusion Sampling with Adaptive Flow PathÂ Sampler](http://arxiv.org/abs/2509.00036v1)
- [UniEMâ€‘3M: A Universal Electron Micrograph Dataset for Microstructural Segmentation andÂ Generation](http://arxiv.org/abs/2508.16239v1)
- [RAGSR: Regional Attention Guided Diffusion for Image Superâ€‘Resolution](http://arxiv.org/abs/2508.16158v1)
- [ScalingÂ GroupÂ InferenceÂ forÂ DiverseÂ andÂ Highâ€‘QualityÂ Generation](http://arxiv.org/abs/2508.15773v1)
- [Waver: Wave Your Way to Lifelike VideoÂ Generation](http://arxiv.org/abs/2508.15761v2)
- [GenTune: Toward Traceable Prompts to Improve Controllability of ImageÂ RefinementÂ in EnvironmentÂ Design](http://arxiv.org/abs/2508.15227v1)
- [SideÂ EffectsÂ ofÂ ErasingÂ ConceptsÂ fromÂ DiffusionÂ Models](http://arxiv.org/abs/2508.15124v2)
- [CurveFlow:Â Curvatureâ€‘Guided FlowÂ Matching for Image Generation](http://arxiv.org/abs/2508.15093v2)
- [SATURN:Â Autoregressive Image Generation Guided by Scene Graphs](http://arxiv.org/abs/2508.14502v1)
- [MUSE:Â Multiâ€‘SubjectÂ UnifiedÂ SynthesisÂ viaÂ ExplicitÂ LayoutÂ SemanticÂ Expansion](http://arxiv.org/abs/2508.14440v1)
- [CTAâ€‘Flux: Integrating Chinese Cultural Semantics into Highâ€‘QualityÂ English Textâ€‘toâ€‘Image Communities](http://arxiv.org/abs/2508.14405v1)
- [SealingÂ TheÂ Backdoor:Â UnlearningÂ AdversarialÂ TextÂ TriggersÂ InÂ DiffusionÂ ModelsÂ UsingÂ KnowledgeÂ Distillation](http://arxiv.org/abs/2508.18235v1)
- [InferenceÂ TimeÂ DebiasingÂ ConceptsÂ inÂ DiffusionÂ Models](http://arxiv.org/abs/2508.14933v1)
- [PixelsÂ UnderÂ Pressure: Exploring Fineâ€‘Tuning Paradigms for FoundationÂ Models inÂ Highâ€‘ResolutionÂ MedicalÂ Imaging](http://arxiv.org/abs/2508.14931v1)
- [SAGA:Â LearningÂ Signalâ€‘Aligned Distributions for Improved Textâ€‘toâ€‘Image Generation](http://arxiv.org/abs/2508.13866v1)
- [UniECS:Â UnifiedÂ MultimodalÂ Eâ€‘CommerceÂ Search Framework with GatedÂ Crossâ€‘modalÂ Fusion](http://arxiv.org/abs/2508.13843v1)
- [DiffIER: Optimizing Diffusion Models with Iterative Error Reduction](http://arxiv.org/abs/2508.13628v2)
- [7Bench: a Comprehensive Benchmark for Layoutâ€‘guided Textâ€‘toâ€‘imageÂ Models](http://arxiv.org/abs/2508.12919v1)
- [SÂ²â€‘Guidance: Stochastic SelfÂ Guidance for Trainingâ€‘Free Enhancement of DiffusionÂ Models](http://arxiv.org/abs/2508.12880v1)
- [Singleâ€‘Reference Textâ€‘toâ€‘ImageÂ Manipulation with DualÂ ContrastiveÂ DenoisingÂ Score](http://arxiv.org/abs/2508.12718v1)
- [DeCoT: Decomposing Complex Instructions for Enhanced Textâ€‘toâ€‘ImageÂ Generation with Large LanguageÂ Models](http://arxiv.org/abs/2508.12396v1)
- [Navigating the Explorationâ€‘Exploitation TradeoffÂ inÂ Inferenceâ€‘Time Scaling of Diffusion Models](http://arxiv.org/abs/2508.12361v1)
- [SafeCtrl: Regionâ€‘Based Safety ControlÂ forÂ Textâ€‘toâ€‘Image Diffusion via Detectâ€‘Thenâ€‘Suppress](http://arxiv.org/abs/2508.11904v1)
- [LoRAtorio: An intrinsic approachÂ toÂ LoRAÂ SkillÂ Composition](http://arxiv.org/abs/2508.11624v1)
- [SPG: Styleâ€‘Prompting GuidanceÂ forÂ Styleâ€‘SpecificÂ Content Creation](http://arxiv.org/abs/2508.11476v1)
- [MatchÂ &Â Choose: ModelÂ Selection Framework for Fineâ€‘tuningÂ Textâ€‘toâ€‘Image DiffusionÂ Models](http://arxiv.org/abs/2508.10993v1)
- [NextStepâ€‘1: TowardÂ AutoregressiveÂ ImageÂ Generation with Continuous TokensÂ atÂ Scale](http://arxiv.org/abs/2508.10711v2)
- [CountCluster: Trainingâ€‘Free ObjectÂ QuantityÂ Guidance with Crossâ€‘Attention MapÂ Clustering for Textâ€‘toâ€‘ImageÂ Generation](http://arxiv.org/abs/2508.10710v1)
- [NanoControl: A Lightweight Framework for Precise and Efficient Control in DiffusionÂ Transformer](http://arxiv.org/abs/2508.10424v1)
- [TranslationÂ ofÂ TextÂ Embedding viaÂ DeltaÂ VectorÂ toÂ Suppress Strongly Entangled ContentÂ inÂ Textâ€‘toâ€‘ImageÂ DiffusionÂ Models](http://arxiv.org/abs/2508.10407v2)
- [HighÂ Fidelity TextÂ toÂ ImageÂ GenerationÂ withÂ ContrastiveÂ AlignmentÂ andÂ StructuralÂ Guidance](http://arxiv.org/abs/2508.10280v1)
- [Echoâ€‘4o: Harnessing the PowerÂ ofÂ GPTâ€‘4o Synthetic Images for Improved Image Generation](http://arxiv.org/abs/2508.09987v1)
- [WeDesign: Generative AIâ€‘Facilitated CommunityÂ Consultations for UrbanÂ PublicÂ Space Design](http://arxiv.org/abs/2508.19256v1)
- [ImagesÂ SpeakÂ LouderÂ ThanÂ Scores: FailureÂ ModeÂ EscapeÂ forÂ EnhancingÂ Generative Quality](http://arxiv.org/abs/2508.09598v1)
- [DualÂ Recursive Feedback on Generation andÂ AppearanceÂ LatentsÂ for Poseâ€‘RobustÂ Textâ€‘toâ€‘ImageÂ Diffusion](http://arxiv.org/abs/2508.09575v1)
- [UnderstandingÂ DementiaÂ SpeechÂ Alignment with Diffusionâ€‘BasedÂ ImageÂ Generation](http://arxiv.org/abs/2508.09385v1)
- [Perâ€‘QueryÂ VisualÂ ConceptÂ Learning](http://arxiv.org/abs/2508.09045v1)
- [TARA: Tokenâ€‘Aware LoRA for Composable Personalization in DiffusionÂ Models](http://arxiv.org/abs/2508.08812v1)
- [ExploringÂ Palette based ColorÂ Guidance in Diffusion Models](http://arxiv.org/abs/2508.08754v1)
- [SafeFix: Targeted Model Repair viaÂ Controlled Image Generation](http://arxiv.org/abs/2508.08701v1)
- [CLUE: Leveraging Lowâ€‘Rank Adaptation to Capture LatentÂ Uncovered Evidence for Image ForgeryÂ Localization](http://arxiv.org/abs/2508.07413v1)
- [CoAR: ConceptÂ Injection into AutoregressiveÂ Models for PersonalizedÂ Textâ€‘toâ€‘ImageÂ Generation](http://arxiv.org/abs/2508.07341v1)
- [Multiâ€‘taskÂ AdversarialÂ Attacks against Blackâ€‘box Model with Fewâ€‘shotÂ Queries](http://arxiv.org/abs/2508.10039v1)
- [Explainabilityâ€‘inâ€‘Action: Enabling ExpressiveÂ Manipulation andÂ TacitÂ Understanding by Bending DiffusionÂ Models in ComfyUI](http://arxiv.org/abs/2508.07183v1)
- [TrustworthyÂ MedicalÂ Imaging with Large LanguageÂ Models: AÂ StudyÂ ofÂ HallucinationsÂ Across Modalities](http://arxiv.org/abs/2508.07031v1)
- [HiMat:Â DiTâ€‘based Ultraâ€‘High Resolution SVBRDFÂ Generation](http://arxiv.org/abs/2508.07011v2)
- [CannyEdit: Selective CannyÂ Control and Dualâ€‘Prompt Guidance for Trainingâ€‘Free ImageÂ Editing](http://arxiv.org/abs/2508.06937v1) [![Project Page](https://img.shields.io/badge/Project-Page-blue?logo=website)](https://vaynexie.github.io/CannyEdit)
- [ARâ€‘GRPO: Training AutoregressiveÂ ImageÂ GenerationÂ Models via Reinforcement Learning](http://arxiv.org/abs/2508.06924v1)
- [Talk2Image: A Multiâ€‘Agent System for Multiâ€‘TurnÂ Image Generation andÂ Editing](http://arxiv.org/abs/2508.06916v1)
- [Towards Effective PromptÂ StealingÂ Attack against Textâ€‘toâ€‘ImageÂ DiffusionÂ Models](http://arxiv.org/abs/2508.06837v1)
- [Restage4D: Reanimating DeformableÂ 3DÂ Reconstruction from aÂ SingleÂ Video](http://arxiv.org/abs/2508.06715v1)
- [VISTAR:AÂ Userâ€‘Centric and Roleâ€‘DrivenÂ Benchmark for Textâ€‘toâ€‘ImageÂ Evaluation](http://arxiv.org/abs/2508.06152v1)
- [NEP: Autoregressive Image Editing via NextÂ EditingÂ Token Prediction](http://arxiv.org/abs/2508.06044v1)
- [Learning 3D Textureâ€‘AwareÂ Representations for ParsingÂ Diverse HumanÂ Clothing andÂ BodyÂ Parts](http://arxiv.org/abs/2508.06032v1)
- [UnGuide: Learning to Forget with LoRAâ€‘GuidedÂ DiffusionÂ Models](http://arxiv.org/abs/2508.05755v1)
- [WhoseÂ Truth?Â PluralisticÂ Geoâ€‘Alignment for (Agentic) AI](http://arxiv.org/abs/2508.05432v1)
- [UNCAGE: ContrastiveÂ AttentionÂ Guidance for MaskedÂ Generative TransformersÂ inÂ Textâ€‘toâ€‘ImageÂ Generation](http://arxiv.org/abs/2508.05399v1)
- [TextualÂ InversionÂ for EfficientÂ Adaptation of Openâ€‘VocabularyÂ ObjectÂ DetectorsÂ WithoutÂ Forgetting](http://arxiv.org/abs/2508.05323v1)
- [ACMÂ MultimediaÂ GrandÂ ChallengeÂ onÂ ENTÂ EndoscopyÂ Analysis](http://arxiv.org/abs/2508.04801v1)



</details>

</details>

<details>
<summary><h4>âœ¨ 2024</h4></summary>

<details>
<summary><h4>âœ… Published Papers</h4></summary>

* **[CVPR 2024]** ***DistriFusion:*** *Distributed Parallel Inference for High-Resolution Diffusion Models*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2402.19481.pdf) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/mit-han-lab/distrifuser)

* **[CVPR 2024]** ***InstanceDiffusion:*** *Instance-level Control for Image Generation*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2402.03290.pdf) [![Project Page](https://img.shields.io/badge/Project-Page-blue?style=for-the-badge&logo=googlechrome&logoColor=white)](https://people.eecs.berkeley.edu/~xdwang/projects/InstDiff/) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/frank-xwang/InstanceDiffusion)

* **[CVPR 2024]** ***ECLIPSE:*** *A Resource-Efficient Text-to-Image Prior for Image Generations*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2312.04655.pdf) [![Project Page](https://img.shields.io/badge/Project-Page-blue?style=for-the-badge&logo=googlechrome&logoColor=white)](https://github.com/eclipse-t2i/eclipse-inference) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://eclipse-t2i.vercel.app/) [![Hugging Face](https://img.shields.io/badge/%F0%9F%A4%97-Hugging_Face-yellow?style=for-the-badge)](https://huggingface.co/spaces/ECLIPSE-Community/ECLIPSE-Kandinsky-v2.2)

* **[CVPR 2024]** ***Instruct-Imagen:*** *Image Generation with Multi-modal Instruction*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2401.01952.pdf)

* **[CVPR 2024]** ***Continuous 3D Words:*** *Learning Continuous 3D Words for Text-to-Image Generation*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2402.08654.pdf) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/ttchengab/continuous_3d_words_code/)

* **[CVPR 2024]** ***HanDiffuser:*** *Text-to-Image Generation With Realistic Hand Appearances*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2403.01693.pdf)

* **[CVPR 2024]** ***Rich Human Feedback:*** *Rich Human Feedback for Text-to-Image Generation*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2312.10240.pdf)

* **[CVPR 2024]** ***MarkovGen:*** *Structured Prediction for Efficient Text-to-Image Generation*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2308.10997.pdf)

* **[CVPR 2024]** ***Customization Assistant:*** *Customization Assistant for Text-to-image Generation*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2312.03045.pdf)

* **[CVPR 2024]** ***ADI:*** *Learning Disentangled Identifiers for Action-Customized Text-to-Image Generation*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2311.15841.pdf) [![Project Page](https://img.shields.io/badge/Project-Page-blue?style=for-the-badge&logo=googlechrome&logoColor=white)](https://adi-t2i.github.io/ADI/)

* **[CVPR 2024]** ***UFOGen:*** *You Forward Once Large Scale Text-to-Image Generation via Diffusion GANs*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2311.09257.pdf)

* **[CVPR 2024]** ***Interpret Diffusion:*** *Self-Discovering Interpretable Diffusion Latent Directions for Responsible Text-to-Image Generation*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2311.17216.pdf)

* **[CVPR 2024]** ***Tailored Visions:*** *Enhancing Text-to-Image Generation with Personalized Prompt Rewriting*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2310.08129.pdf) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/zzjchen/Tailored-Visions)

* **[CVPR 2024]** ***CoDi:*** *Conditional Diffusion Distillation for Higher-Fidelity and Faster Image Generation*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2310.01407.pdf) [![Project Page](https://img.shields.io/badge/Project-Page-blue?style=for-the-badge&logo=googlechrome&logoColor=white)](https://fast-codi.github.io/) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/fast-codi/CoDi) [![Hugging Face](https://img.shields.io/badge/%F0%9F%A4%97-Hugging_Face-yellow?style=for-the-badge)](https://huggingface.co/spaces/MKFMIKU/CoDi)

* **[CVPR 2024]** ***Arbitraryâ€‘Scale Diffusion:*** *Arbitrary-Scale Image Generation and Upsampling using Latent Diffusion Model and Implicit Neural Decoder*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2403.10255.pdf)

* **[CVPR 2024]** ***Human-Centric Priors:*** *Towards Effective Usage of Human-Centric Priors in Diffusion Models for Text-based Human Image Generation*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2403.05239)

* **[CVPR 2024]** ***ElasticDiffusion:*** *Training-free Arbitrary Size Image Generation*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2311.18822) [![Project Page](https://img.shields.io/badge/Project-Page-blue?style=for-the-badge&logo=googlechrome&logoColor=white)](https://elasticdiffusion.github.io/) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/MoayedHajiAli/ElasticDiffusion-official)

* **[CVPR 2024]** ***CosmicMan:*** *A Text-to-Image Foundation Model for Humans*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2404.01294) [![Project Page](https://img.shields.io/badge/Project-Page-blue?style=for-the-badge&logo=googlechrome&logoColor=white)](https://cosmicman-cvpr2024.github.io/) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/cosmicman-cvpr2024/CosmicMan)

* **[CVPR 2024]** ***PanFusion:*** *Taming Stable Diffusion for Text to 360Â° Panorama Image Generation*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2404.07949) [![Project Page](https://img.shields.io/badge/Project-Page-blue?style=for-the-badge&logo=googlechrome&logoColor=white)](https://chengzhag.github.io/publication/panfusion) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/chengzhag/PanFusion)

* **[CVPR 2024]** ***Intelligent Grimm:*** *Open-ended Visual Storytelling via Latent Diffusion Models*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2306.00973) [![Project Page](https://img.shields.io/badge/Project-Page-blue?style=for-the-badge&logo=googlechrome&logoColor=white)](https://haoningwu3639.github.io/StoryGen_Webpage/) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/haoningwu3639/StoryGen)

* **[CVPR 2024]** ***Scalability:*** *On the Scalability of Diffusion-based Text-to-Image Generation*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2404.02883)

* **[CVPR 2024]** ***MuLAn:*** *A Multi Layer Annotated Dataset for Controllable Text-to-Image Generation*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2404.02790) [![Project Page](https://img.shields.io/badge/Project-Page-blue?style=for-the-badge&logo=googlechrome&logoColor=white)](https://mulan-dataset.github.io/) [![Hugging Face](https://img.shields.io/badge/%F0%9F%A4%97-Hugging_Face-yellow?style=for-the-badge)](https://huggingface.co/datasets/mulan-dataset/v1.0)

* **[CVPR 2024]** ***Multi-dimensional Preferences:*** *Learning Multi-dimensional Human Preference for Text-to-Image Generation*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2405.14705)

* **[CVPR 2024]** ***Dynamic Prompts:*** *Dynamic Prompt Optimizing for Text-to-Image Generation*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2404.04095)

* **[CVPR 2024]** ***Reinforcement Diversification:*** *Training Diffusion Models Towards Diverse Image Generation with Reinforcement Learning*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://openaccess.thecvf.com/content/CVPR2024/papers/Miao_Training_Diffusion_Models_Towards_Diverse_Image_Generation_with_Reinforcement_Learning_CVPR_2024_paper.pdf)

* **[CVPR 2024]** ***HypercGAN:*** *Adversarial Text to Continuous Image Generation*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://openaccess.thecvf.com/content/CVPR2024/papers/Haydarov_Adversarial_Text_to_Continuous_Image_Generation_CVPR_2024_paper.pdf) [![Project Page](https://img.shields.io/badge/Project-Page-blue?style=for-the-badge&logo=googlechrome&logoColor=white)](https://kilichbek.github.io/webpage/hypercgan/)

* **[CVPR 2024]** ***EmoGen:*** *Emotional Image Content Generation with Text-to-Image Diffusion Models*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://openaccess.thecvf.com/content/CVPR2024/papers/Yang_EmoGen_Emotional_Image_Content_Generation_with_Text-to-Image_Diffusion_Models_CVPR_2024_paper.pdf) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/JingyuanYY/EmoGen)

* **[ECCV 2024]** ***LaViâ€‘Bridge:*** *Bridging Different Language Models and Generative Vision Models for Text-to-Image Generation*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2403.07860) [![Project Page](https://img.shields.io/badge/Project-Page-blue?style=for-the-badge&logo=googlechrome&logoColor=white)](https://shihaozhaozsh.github.io/LaVi-Bridge/) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/ShihaoZhaoZSH/LaVi-Bridge)

* **[ECCV 2024]** ***DiffPNG:*** *Exploring Phrase-Level Grounding with Text-to-Image Diffusion Model*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2407.05352v1) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/nini0919/DiffPNG)

* **[ECCV 2024]** ***SPRIGHT:*** *Getting it Right: Improving Spatial Consistency in Text-to-Image Models*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2404.01197) [![Project Page](https://img.shields.io/badge/Project-Page-blue?style=for-the-badge&logo=googlechrome&logoColor=white)](https://spright-t2i.github.io/) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/SPRIGHT-T2I/SPRIGHT)

* **[ECCV 2024]** ***IndicTTI:*** *Navigating Text-to-Image Generative Bias across Indic Languages*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2408.00283v1) [![Project Page](https://img.shields.io/badge/Project-Page-blue?style=for-the-badge&logo=googlechrome&logoColor=white)](https://iab-rubric.org/resources/other-databases/indictti)

* **[ECCV 2024]** ***Safeguard T2I:*** *Safeguard Text-to-Image Diffusion Models with Human Feedback Inversion*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2407.21032)

* **[ECCV 2024]** ***Reality-and-Fantasy:*** *The Fabrication of Reality and Fantasy: Scene Generation with LLM-Assisted Prompt Interpretation*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2407.12579) [![Project Page](https://img.shields.io/badge/Project-Page-blue?style=for-the-badge&logo=googlechrome&logoColor=white)](https://leo81005.github.io/Reality-and-Fantasy/) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://leo81005.github.io/Reality-and-Fantasy/)

* **[ECCV 2024]** ***RECE:*** *Reliable and Efficient Concept Erasure of Text-to-Image Diffusion Models*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2407.12383v1) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/CharlesGong12/RECE)

* **[ECCV 2024]** ***StyleTokenizer:*** *Defining Image Style by a Single Instance for Controlling Diffusion Models*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2409.02543) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/alipay/style-tokenizer)

* **[ECCV 2024]** ***PEA-Diffusion:*** *Parameter-Efficient Adapter with Knowledge Distillation in non-English Text-to-Image Generation*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://www.ecva.net/papers/eccv_2024/papers_ECCV/papers/08492.pdf) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/OPPO-Mente-Lab/PEA-Diffusion)

* **[ECCV 2024]** ***Skewed Relations T2I:*** *Skews in the Phenomenon Space Hinder Generalization in Text-to-Image Generation*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://www.ecva.net/papers/eccv_2024/papers_ECCV/papers/11936.pdf) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/zdxdsw/skewed_relations_T2I)

* **[ECCV 2024]** ***Parrot:*** *Pareto-optimal Multi-Reward Reinforcement Learning Framework for Text-to-Image Generation*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://www.ecva.net/papers/eccv_2024/papers_ECCV/papers/05562.pdf)

* **[ECCV 2024]** ***MobileDiffusion:*** *Instant Text-to-Image Generation on Mobile Devices*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://www.ecva.net/papers/eccv_2024/papers_ECCV/papers/07923.pdf)

* **[ECCV 2024]** ***PixArt-Î£:*** *Weak-to-Strong Training of Diffusion Transformer for 4K Text-to-Image Generation*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2403.04692) [![Project Page](https://img.shields.io/badge/Project-Page-blue?style=for-the-badge&logo=googlechrome&logoColor=white)](https://pixart-alpha.github.io/PixArt-sigma-project/) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/PixArt-alpha/PixArt-sigma)

* **[ECCV 2024]** ***CogView3:*** *Finer and Faster Text-to-Image Generation via Relay Diffusion*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2403.05121) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/THUDM/CogView)

* **[ICLR 2024]** ***Patched Diffusion Models:*** *Patched Denoising Diffusion Models For High-Resolution Image Synthesis*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2308.01316.pdf) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/mlpc-ucsd/patch-dm)

* **[ICLR 2024]** ***Relay Diffusion:*** *Unifying diffusion process across resolutions for image synthesis*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2309.03350.pdf) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/THUDM/RelayDiffusion)

* **[ICLR 2024]** ***SDXL:*** *Improving Latent Diffusion Models for High-Resolution Image Synthesis*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2307.01952.pdf) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/Stability-AI/generative-models)

* **[ICLR 2024]** ***Compose and Conquer:*** *Diffusion-Based 3D Depth Aware Composable Image Synthesis*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2401.09048.pdf) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/tomtom1103/compose-and-conquer)

* **[ICLR 2024]** ***PixArt-Î±:*** *Fast Training of Diffusion Transformer for Photorealistic Text-to-Image Synthesis*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2310.00426.pdf) [![Project Page](https://img.shields.io/badge/Project-Page-blue?style=for-the-badge&logo=googlechrome&logoColor=white)](https://pixart-alpha.github.io/) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/PixArt-alpha/PixArt-alpha) [![Hugging Face](https://img.shields.io/badge/%F0%9F%A4%97-Hugging_Face-yellow?style=for-the-badge)](https://huggingface.co/spaces/PixArt-alpha/PixArt-alpha)

* **[SIGGRAPH 2024]** ***RGBâ†”X:*** *Image Decomposition and Synthesis Using Material- and Lighting-aware Diffusion Models*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://zheng95z.github.io/assets/files/sig24-rgbx.pdf) [![Project Page](https://img.shields.io/badge/Project-Page-blue?style=for-the-badge&logo=googlechrome&logoColor=white)](https://zheng95z.github.io/publications/rgbx24)

* **[AAAI 2024]** ***Semantic-aware Augmentation:*** *Semantic-aware Data Augmentation for Text-to-image Synthesis*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2312.07951.pdf)

* **[AAAI 2024]** ***Abstract Concepts:*** *Text-to-Image Generation for Abstract Concepts*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://ojs.aaai.org/index.php/AAAI/article/view/28122)


</details>

<details>
<summary><h4>ğŸ’¡ Pre-Print Papers</h4></summary>

- [Text-to-Image GAN with Pretrained Representations](http://arxiv.org/abs/2501.00116v1)
- [VMix: Improving Text-to-Image Diffusion Model with Cross-Attention Mixing Control](http://arxiv.org/abs/2412.20800v1) [![GitHub Stars](https://img.shields.io/github/stars/fenfenfenfan/VMix?style=social)](https://github.com/fenfenfenfan/VMix)   [![Project Page](https://img.shields.io/badge/Project-Page-blue?logo=website)](https://vmix-diffusion.github.io/VMix/)
- [INFELM: In-depth Fairness Evaluation of Large Text-To-Image Models](http://arxiv.org/abs/2501.01973v3)
- [Is Your Text-to-Image Model Robust to Caption Noise?](http://arxiv.org/abs/2412.19531v1)
- [DebiasDiff: Debiasing Text-to-image Diffusion Models with Self-discovering Latent Attribute Directions](http://arxiv.org/abs/2412.18810v1) [![GitHub Stars](https://img.shields.io/github/stars/leigest519/DebiasDiff?style=social)](https://github.com/leigest519/DebiasDiff)
- [Explaining in Diffusion: Explaining a Classifier Through Hierarchical Semantics with Text-to-Image Diffusion Models](http://arxiv.org/abs/2412.18604v1)  [![Project Page](https://img.shields.io/badge/Project-Page-blue?logo=website)](https://explain-in-diffusion.github.io/)
- [FameBias: Embedding Manipulation Bias Attack in Text-to-Image Models](http://arxiv.org/abs/2412.18302v1)
- [EvalMuse-40K: A Reliable and Fine-Grained Benchmark with Comprehensive Human Annotations for Text-to-Image Generation Model Evaluation](http://arxiv.org/abs/2412.18150v2)  [![Project Page](https://img.shields.io/badge/Project-Page-blue?logo=website)](https://shh-han.github.io/EvalMuse-project/)  [![Huggingface Face](https://img.shields.io/badge/Hugging-Face-orange?logo=website)](https://huggingface.co/datasets/DY-Evalab/EvalMuse)
- [AEIOU: A Unified Defense Framework against NSFW Prompts in Text-to-Image Models](http://arxiv.org/abs/2412.18123v1)
- [Self-Corrected Flow Distillation for Consistent One-Step and Few-Step Text-to-Image Generation](http://arxiv.org/abs/2412.16906v2)
- [PromptLA: Towards Integrity Verification of Black-box Text-to-Image Diffusion Models](http://arxiv.org/abs/2412.16257v2)
- [GALOT: Generative Active Learning via Optimizable Zero-shot Text-to-image Generation](http://arxiv.org/abs/2412.16227v1)
- [What makes a good metric? Evaluating automatic metrics for text-to-image consistency](http://arxiv.org/abs/2412.13989v1)
- [Maybe you are looking for CroQS: Cross-modal Query Suggestion for Text-to-Image Retrieval](http://arxiv.org/abs/2412.13834v1)
- [CoMPaSS: Enhancing Spatial Understanding in Text-to-Image Diffusion Models](http://arxiv.org/abs/2412.13195v2) [![GitHub Stars](https://img.shields.io/github/stars/blurgyy/CoMPaSS?style=social)](https://github.com/blurgyy/CoMPaSS)  [![Huggingface Face](https://img.shields.io/badge/Hugging-Face-orange?logo=website)](https://huggingface.co/blurgy/CoMPaSS-FLUX.1)
- [ArtAug: Enhancing Text-to-Image Generation through Synthesis-Understanding Interaction](http://arxiv.org/abs/2412.12888v2)  [![Huggingface Face](https://img.shields.io/badge/Hugging-Face-orange?logo=website)](https://huggingface.co/ECNU-CILab/ArtAug-lora-FLUX.1dev-v1)
- [A Framework for Critical Evaluation of Text-to-Image Models: Integrating Art Historical Analysis, Artistic Exploration, and Critical Prompt Engineering](http://arxiv.org/abs/2412.12774v1)
- [Efficient Scaling of Diffusion Transformers for Text-to-Image Generation](http://arxiv.org/abs/2412.12391v1)
- [VersaGen: Unleashing Versatile Visual Control for Text-to-Image Synthesis](http://arxiv.org/abs/2412.11594v3) [![GitHub Stars](https://img.shields.io/github/stars/FelixChan9527/VersaGen_official?style=social)](https://github.com/FelixChan9527/VersaGen_official)
- [Finding a Wolf in Sheep's Clothing: Combating Adversarial Text-To-Image Prompts with Text Summarization](http://arxiv.org/abs/2412.12212v1)
- [AlignGuard: Scalable Safety Alignment for Text-to-Image Generation](http://arxiv.org/abs/2412.10493v2) [![GitHub Stars](https://img.shields.io/github/stars/Visualignment/SafetyDPO?style=social)](https://github.com/Visualignment/SafetyDPO)   [![Project Page](https://img.shields.io/badge/Project-Page-blue?logo=website)](https://alignguard.github.io/) [![Huggingface Face](https://img.shields.io/badge/Hugging-Face-orange?logo=website)](https://huggingface.co/Visualignment/safe-stable-diffusion-v1-5)
- [SnapGen: Taming High-Resolution Text-to-Image Models for Mobile Devices with Efficient Architectures and Training](http://arxiv.org/abs/2412.09619v1)   [![Project Page](https://img.shields.io/badge/Project-Page-blue?logo=website)](https://snap-research.github.io/snapgen/)
- [Context Canvas: Enhancing Text-to-Image Diffusion Models with Knowledge Graph-Based RAG](http://arxiv.org/abs/2412.09614v1)   [![Project Page](https://img.shields.io/badge/Project-Page-blue?logo=website)](https://context-canvas.github.io/)
- [DECOR:Decomposition and Projection of Text Embeddings for Text-to-Image Customization](http://arxiv.org/abs/2412.09169v1)
- [Fast Prompt Alignment for Text-to-Image Generation](http://arxiv.org/abs/2412.08639v1) [![GitHub Stars](https://img.shields.io/github/stars/tiktok/fast_prompt_alignment?style=social)](https://github.com/tiktok/fast_prompt_alignment)
- [FiVA: Fine-grained Visual Attribute Dataset for Text-to-Image Diffusion Models](http://arxiv.org/abs/2412.07674v1)   [![Project Page](https://img.shields.io/badge/Project-Page-blue?logo=website)](https://fiva-dataset.github.io/)
- [Preference Adaptive and Sequential Text-to-Image Generation](http://arxiv.org/abs/2412.10419v2)
- [Boosting Alignment for Post-Unlearning Text-to-Image Generative Models](http://arxiv.org/abs/2412.07808v2) [![GitHub Stars](https://img.shields.io/github/stars/reds-lab/Restricted_gradient_diversity_unlearning?style=social)](https://github.com/reds-lab/Restricted_gradient_diversity_unlearning)
- [Proactive Agents for Multi-Turn Text-to-Image Generation Under Uncertainty](http://arxiv.org/abs/2412.06771v2) [![GitHub Stars](https://img.shields.io/github/stars/google-deepmind/proactive_t2i_agents?style=social)](https://github.com/google-deepmind/proactive_t2i_agents)
- [SILMM: Self-Improving Large Multimodal Models for Compositional Text-to-Image Generation](http://arxiv.org/abs/2412.05818v2) [![GitHub Stars](https://img.shields.io/github/stars/LgQu/SILMM?style=social)](https://github.com/LgQu/SILMM)   [![Project Page](https://img.shields.io/badge/Project-Page-blue?logo=website)](https://silmm.github.io/)
- [Evaluating Hallucination in Text-to-Image Diffusion Models with Scene-Graph based Question-Answering Agent](http://arxiv.org/abs/2412.05722v1)
- [SleeperMark: Towards Robust Watermark against Fine-Tuning Text-to-image Diffusion Models](http://arxiv.org/abs/2412.04852v2) [![GitHub Stars](https://img.shields.io/github/stars/taco-group/SleeperMark?style=social)](https://github.com/taco-group/SleeperMark)
- [LayerFusion: Harmonized Multi-Layer Text-to-Image Generation with Generative Priors](http://arxiv.org/abs/2412.04460v1)   [![Project Page](https://img.shields.io/badge/Project-Page-blue?logo=website)](https://layerfusion.github.io/)
- [T2I-FactualBench: Benchmarking the Factuality of Text-to-Image Models with Knowledge-Intensive Concepts](http://arxiv.org/abs/2412.04300v3)
- [BodyMetric: Evaluating the Realism of Human Bodies in Text-to-Image Generation](http://arxiv.org/abs/2412.04086v2)
- [Safeguarding Text-to-Image Generation via Inference-Time Prompt-Noise Optimization](http://arxiv.org/abs/2412.03876v1)
- [DynamicControl: Adaptive Condition Selection for Improved Text-to-Image Generation](http://arxiv.org/abs/2412.03255v2) [![GitHub Stars](https://img.shields.io/github/stars/hithqd/DynamicControl?style=social)](https://github.com/hithqd/DynamicControl)   [![Project Page](https://img.shields.io/badge/Project-Page-blue?logo=website)](https://hithqd.github.io/projects/Dynamiccontrol/)
- [The Role of Text-to-Image Models in Advanced Style Transfer Applications: A Case Study with DALL-EÂ 3](http://arxiv.org/abs/2412.05325v1)
- [Towards Understanding and Quantifying Uncertainty for Text-to-Image Generation](http://arxiv.org/abs/2412.03178v1)
- [ShapeWords: Guiding Text-to-Image Synthesis with 3D Shape-Aware Prompts](http://arxiv.org/abs/2412.02912v1)
- [ScImage: How Good Are Multimodal Large Language Models at Scientific Text-to-Image Generation?](http://arxiv.org/abs/2412.02368v1)
- [Cross-Attention Head Position Patterns Can Align with Human Visual Concepts in Text-to-Image Generative Models](http://arxiv.org/abs/2412.02237v3)
- [Generative Photography: Scene-Consistent Camera Control for Realistic Text-to-Image Synthesis](http://arxiv.org/abs/2412.02168v3)
- [Switti: Designing Scale-Wise Transformers for Text-to-Image Synthesis](http://arxiv.org/abs/2412.01819v4)
- [Continuous Concepts Removal in Text-to-image Diffusion Models](http://arxiv.org/abs/2412.00580v2)
- [Blind Inverse Problem Solving Made Easy by Text-to-Image Latent Diffusion](http://arxiv.org/abs/2412.00557v1)
- [Safety Alignment Backfires: Preventing the Re-emergence of Suppressed Concepts in Fine-tuned Text-to-Image Diffusion Models](http://arxiv.org/abs/2412.00357v1)
- [Sparrow: Data-Efficient Video-LLM with Text-to-Image Augmentation](http://arxiv.org/abs/2411.19951v5)
- [QUOTA: Quantifying Objects with Text-to-Image Models for Any Domain](http://arxiv.org/abs/2411.19534v1)
- [DreamBlend: Advancing Personalized Fine-tuning of Text-to-Image Diffusion Models](http://arxiv.org/abs/2411.19390v1)
- [EFSA: Episodic Few-Shot Adaptation for Text-to-Image Retrieval](http://arxiv.org/abs/2412.00139v2)
- [Bridging the Gap: Aligning Text-to-Image Diffusion Models with Specific Feedback](http://arxiv.org/abs/2412.00122v1)
- [Self-Cross Diffusion Guidance for Text-to-Image Synthesis of Similar Subjects](http://arxiv.org/abs/2411.18936v2)
- [All Seeds Are Not Equal: Enhancing Compositional Text-to-Image Generation with Reliable Random Seeds](http://arxiv.org/abs/2411.18810v5)
- [An indicator for effectiveness of text-to-image guardrails utilizing the Single-Turn Crescendo Attack (STCA)](http://arxiv.org/abs/2411.18699v1)
- [Enhancing MMDiT-Based Text-to-Image Models for Similar Subject Generation](http://arxiv.org/abs/2411.18301v1)
- [Type-R: Automatically Retouching Typos for Text-to-Image Generation](http://arxiv.org/abs/2411.18159v2)
- [Reward Incremental Learning in Text-to-Image Generation](http://arxiv.org/abs/2411.17310v1)
- [ChatGen: Automatic Text-to-Image Generation From FreeStyle Chatting](http://arxiv.org/abs/2411.17176v1)
- [Relations, Negations, and Numbers: Looking for Logic in Generative Text-to-Image Models](http://arxiv.org/abs/2411.17066v1)
- [Noise Diffusion for Enhancing Semantic Faithfulness in Text-to-Image Synthesis](http://arxiv.org/abs/2411.16503v1)
- [Unlocking the Potential of Text-to-Image Diffusion with PAC-Bayesian Theory](http://arxiv.org/abs/2411.17472v1)
- [CoCoNO: Attention Contrast-and-Complete for Initial Noise Optimization in Text-to-Image Synthesis](http://arxiv.org/abs/2411.16783v1)
- [Text-to-Image Synthesis: A Decade Survey](http://arxiv.org/abs/2411.16164v1)
- [In-Context Experience Replay Facilitates Safety Red-Teaming of Text-to-Image Diffusion Models](http://arxiv.org/abs/2411.16769v2)


</details>

</details>

<details>
<summary><h4>âœ¨ 2023</h4></summary>

<details>
<summary><h4>âœ… Published Papers</h4></summary>

* **[CVPR 2023]** ***GigaGAN:*** *Scaling Up GANs for Text-to-Image Synthesis*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://openaccess.thecvf.com/content/CVPR2023/papers/Kang_Scaling_Up_GANs_for_Text-to-Image_Synthesis_CVPR_2023_paper.pdf) [![Project Page](https://img.shields.io/badge/Project-Page-blue?style=for-the-badge&logo=googlechrome&logoColor=white)](https://mingukkang.github.io/GigaGAN/) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/lucidrains/gigagan-pytorch)

* **[CVPR 2023]** ***ERNIE-ViLGÂ 2.0:*** *Improving Text-to-Image Diffusion Model With Knowledge-Enhanced Mixture-of-Denoising-Experts*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://openaccess.thecvf.com/content/CVPR2023/papers/Feng_ERNIE-ViLG_2.0_Improving_Text-to-Image_Diffusion_Model_With_Knowledge-Enhanced_Mixture-of-Denoising-Experts_CVPR_2023_paper.pdf)

* **[CVPR 2023]** ***ShiftedÂ Diffusion:*** *Shifted Diffusion for Text-to-image Generation*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://openaccess.thecvf.com/content/CVPR2023/papers/Zhou_Shifted_Diffusion_for_Text-to-Image_Generation_CVPR_2023_paper.pdf) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/drboog/Shifted_Diffusion)

* **[CVPR 2023]** ***GALIP:*** *Generative Adversarial CLIPs for Text-to-Image Synthesis*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://openaccess.thecvf.com/content/CVPR2023/papers/Tao_GALIP_Generative_Adversarial_CLIPs_for_Text-to-Image_Synthesis_CVPR_2023_paper.pdf) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/tobran/GALIP)

* **[CVPR 2023]** ***SpecialistÂ Diffusion:*** *Plug-and-Play Sample-Efficient Fine-Tuning of Text-to-Image Diffusion Models to Learn Any Unseen Style*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://openaccess.thecvf.com/content/CVPR2023/papers/Lu_Specialist_Diffusion_Plug-and-Play_Sample-Efficient_Fine-Tuning_of_Text-to-Image_Diffusion_Models_To_CVPR_2023_paper.pdf) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/Picsart-AI-Research/Specialist-Diffusion)

* **[CVPR 2023]** ***Verifiable Evaluation:*** *Toward Verifiable and Reproducible Human Evaluation for Text-to-Image Generation*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://openaccess.thecvf.com/content/CVPR2023/papers/Otani_Toward_Verifiable_and_Reproducible_Human_Evaluation_for_Text-to-Image_Generation_CVPR_2023_paper.pdf)

* **[CVPR 2023]** ***RIATIG:*** *Reliable and Imperceptible Adversarial Text-to-Image Generation with Natural Prompts*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://openaccess.thecvf.com/content/CVPR2023/papers/Liu_RIATIG_Reliable_and_Imperceptible_Adversarial_Text-to-Image_Generation_With_Natural_Prompts_CVPR_2023_paper.pdf) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/WUSTL-CSPL/RIATIG)

* **[CVPR 2023]** ***Custom Diffusion:*** *Multi-Concept Customization of Text-to-Image Diffusion*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://openaccess.thecvf.com/content/CVPR2023/papers/Kumari_Multi-Concept_Customization_of_Text-to-Image_Diffusion_CVPR_2023_paper.pdf) [![Project Page](https://img.shields.io/badge/Project-Page-blue?style=for-the-badge&logo=googlechrome&logoColor=white)](https://www.cs.cmu.edu/~custom-diffusion/) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/adobe-research/custom-diffusion)

* **[ICCV 2023]** ***DiffFit:*** *Unlocking Transferability of Large Diffusion Models via Simple Parameter-Efficient Fine-Tuning*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://openaccess.thecvf.com/content/ICCV2023/papers/Xie_DiffFit_Unlocking_Transferability_of_Large_Diffusion_Models_via_Simple_Parameter-efficient_ICCV_2023_paper.pdf) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/mkshing/DiffFit-pytorch)

* **[NeurIPS 2023]** ***ImageReward:*** *Learning and Evaluating Human Preferences for Text-to-Image Generation*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://openreview.net/pdf?id=JVzeOYEx6d) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/THUDM/ImageReward)

* **[NeurIPS 2023]** ***RAPHAEL:*** *Text-to-Image Generation via Large Mixture of Diffusion Paths*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2305.18295) [![Project Page](https://img.shields.io/badge/Project-Page-blue?style=for-the-badge&logo=googlechrome&logoColor=white)](https://raphael-painter.github.io/)

* **[NeurIPS 2023]** ***Linguistic Binding:*** *Linguistic Binding in Diffusion Models: Enhancing Attribute Correspondence through Attention Map Alignment*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://openreview.net/pdf?id=AOKU4nRw1W) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/RoyiRa/Linguistic-Binding-in-Diffusion-Models)

* **[NeurIPS 2023]** ***DenseDiffusion:*** *Dense Text-to-Image Generation with Attention Modulation*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://openaccess.thecvf.com/content/ICCV2023/papers/Kim_Dense_Text-to-Image_Generation_with_Attention_Modulation_ICCV_2023_paper.pdf) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/naver-ai/densediffusion)

* **[ICLR 2023]** ***Structured Diffusion Guidance:*** *Training-Free Structured Diffusion Guidance for Compositional Text-to-Image Synthesis*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://openreview.net/pdf?id=PUIqjT4rzq7) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/weixi-feng/Structured-Diffusion-Guidance)

* **[ICML 2023]** ***StyleGAN-T:*** *Unlocking the Power of GANs for Fast Large-Scale Text-to-Image Synthesis*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://proceedings.mlr.press/v202/sauer23a/sauer23a.pdf) [![Project Page](https://img.shields.io/badge/Project-Page-blue?style=for-the-badge&logo=googlechrome&logoColor=white)](https://sites.google.com/view/stylegan-t/) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/autonomousvision/stylegan-t)

* **[ICML 2023]** ***Muse:*** *Text-To-Image Generation via Masked Generative Transformers*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://proceedings.mlr.press/v202/chang23b/chang23b.pdf) [![Project Page](https://img.shields.io/badge/Project-Page-blue?style=for-the-badge&logo=googlechrome&logoColor=white)](https://muse-icml.github.io/) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/lucidrains/muse-maskgit-pytorch)

* **[ICML 2023]** ***UniDiffusers:*** *One Transformer Fits All Distributions in Multi-Modal Diffusion at Scale*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2303.06555) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/thu-ml/unidiffuser)

* **[ACMÂ MM 2023]** ***SUR-adapter:*** *Enhancing Text-to-Image Pre-trained Diffusion Models with Large Language Models*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2305.05189.pdf) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/Qrange-group/SUR-adapter)

* **[ACMÂ MM 2023]** ***ControlStyle:*** *Text-Driven Stylized Image Generation Using Diffusion Priors*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2311.05463.pdf)

* **[SIGGRAPH 2023]** ***Attend-and-Excite:*** *Attention-Based Semantic Guidance for Text-to-Image Diffusion Models*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2301.13826.pdf) [![Project Page](https://img.shields.io/badge/Project-Page-blue?style=for-the-badge&logo=googlechrome&logoColor=white)](https://yuval-alaluf.github.io/Attend-and-Excite/) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/yuval-alaluf/Attend-and-Excite) [![Hugging Face](https://img.shields.io/badge/%F0%9F%A4%97-Hugging_Face-yellow?style=for-the-badge)](https://huggingface.co/spaces/AttendAndExcite/Attend-and-Excite)



</details>

<details>
<summary><h4>ğŸ’¡ Pre-Print Papers</h4></summary>

- [RenAIssance: A Survey into AI Textâ€‘toâ€‘Image Generation in the EraÂ ofÂ Large Model](http://arxiv.org/abs/2309.00810v1)
- [Intriguing PropertiesÂ ofÂ DiffusionÂ Models: AnÂ Empirical Study of theÂ Natural AttackÂ CapabilityÂ inÂ Textâ€‘toâ€‘Image GenerativeÂ Models](http://arxiv.org/abs/2308.15692v2)
- [Dense Textâ€‘toâ€‘ImageÂ Generation withÂ Attention Modulation](http://arxiv.org/abs/2308.12964v1) [![GitHub Stars](https://img.shields.io/github/stars/naver-ai/DenseDiffusion?style=social)](https://github.com/naver-ai/DenseDiffusion)   [![Huggingface Face](https://img.shields.io/badge/Hugging-Face-orange?logo=website)](https://huggingface.co/naver-ai/DenseDiffusion)
- [AltDiffusion: A Multilingual Textâ€‘toâ€‘Image DiffusionÂ Model](http://arxiv.org/abs/2308.09991v2) [![GitHub Stars](https://img.shields.io/github/stars/superhero-7/AltDiffusion?style=social)](https://github.com/superhero-7/AltDiffusion)   [![Huggingface Face](https://img.shields.io/badge/Hugging-Face-orange?logo=website)](https://huggingface.co/BAAI/AltDiffusion-m18)
- [Noisyâ€‘CorrespondenceÂ Learning forÂ Textâ€‘toâ€‘Image PersonÂ Reâ€‘identification](http://arxiv.org/abs/2308.09911v3)
- [Likelihoodâ€‘Based Textâ€‘toâ€‘Image Evaluation withÂ Patchâ€‘Level Perceptual andÂ Semantic CreditÂ Assignment](http://arxiv.org/abs/2308.08525v1)
- [Learning toÂ GenerateÂ SemanticÂ Layouts forÂ HigherÂ Textâ€‘Image Correspondence in Textâ€‘toâ€‘Image Synthesis](http://arxiv.org/abs/2308.08157v1)
- [MarkovGen: Structured Prediction forÂ Efficient Textâ€‘toâ€‘Image Generation](http://arxiv.org/abs/2308.10997v3)
- [IPâ€‘Adapter: Text Compatible ImageÂ Prompt Adapter forÂ Textâ€‘toâ€‘Image DiffusionÂ Models](http://arxiv.org/abs/2308.06721v1) [![GitHub Stars](https://img.shields.io/github/stars/tencent-ailab/IP-Adapter?style=social)](https://github.com/tencent-ailab/IP-Adapter)   [![Project Page](https://img.shields.io/badge/Project-Page-blue?logo=website)](https://ip-adapter.github.io/) [![Huggingface Face](https://img.shields.io/badge/Hugging-Face-orange?logo=website)](https://huggingface.co/h94/IP-Adapter)
- [Maskedâ€‘AttentionÂ Diffusion Guidance for Spatially ControllingÂ Textâ€‘toâ€‘ImageÂ Generation](http://arxiv.org/abs/2308.06027v2) [![GitHub Stars](https://img.shields.io/github/stars/endo-yuki-t/MAG?style=social)](https://github.com/endo-yuki-t/MAG)
- [PromptPaint: Steering Textâ€‘toâ€‘ImageÂ Generation ThroughÂ Paint Mediumâ€‘like Interactions](http://arxiv.org/abs/2308.05184v1)
- [LayoutLLMâ€‘T2I: Eliciting Layout Guidance from LLM forÂ Textâ€‘toâ€‘ImageÂ Generation](http://arxiv.org/abs/2308.05095v2) [![GitHub Stars](https://img.shields.io/github/stars/LayoutLLM-T2I/LayoutLLM-T2I?style=social)](https://github.com/LayoutLLM-T2I/LayoutLLM-T2I)   [![Project Page](https://img.shields.io/badge/Project-Page-blue?logo=website)](https://layoutllm-t2i.github.io/)
- [CircumventingÂ ConceptÂ Erasure Methods forÂ Textâ€‘toâ€‘Image GenerativeÂ Models](http://arxiv.org/abs/2308.01508v2) [![GitHub Stars](https://img.shields.io/github/stars/NYU-DICE-Lab/circumventing-concept-erasure?style=social)](https://github.com/NYU-DICE-Lab/circumventing-concept-erasure)
- [The BiasÂ Amplification Paradox in Textâ€‘toâ€‘Image Generation](http://arxiv.org/abs/2308.00755v2)
- [BAGM: A Backdoor Attack forÂ Manipulating Textâ€‘toâ€‘Image GenerativeÂ Models](http://arxiv.org/abs/2307.16489v2) [![GitHub Stars](https://img.shields.io/github/stars/JJ-Vice/BAGM?style=social)](https://github.com/JJ-Vice/BAGM)
- [Subjectâ€‘Diffusion:Â Open DomainÂ Personalized Textâ€‘toâ€‘Image Generation withoutÂ Testâ€‘timeÂ Fineâ€‘tuning](http://arxiv.org/abs/2307.11410v2) [![GitHub Stars](https://img.shields.io/github/stars/OPPO-Mente-Lab/Subject-Diffusion?style=social)](https://github.com/OPPO-Mente-Lab/Subject-Diffusion)   [![Project Page](https://img.shields.io/badge/Project-Page-blue?logo=website)](https://oppo-mente-lab.github.io/subject_diffusion/)
- [BoxDiff: Textâ€‘toâ€‘Image Synthesis with Trainingâ€‘Free Boxâ€‘Constrained Diffusion](http://arxiv.org/abs/2307.10816v4) [![GitHub Stars](https://img.shields.io/github/stars/showlab/BoxDiff?style=social)](https://github.com/showlab/BoxDiff)
- [Beyond theÂ MLÂ Model: Applying Safety Engineering Frameworks toÂ Textâ€‘toâ€‘Image Development](http://arxiv.org/abs/2307.10312v1)
- [DistillingÂ Knowledge from Textâ€‘toâ€‘Image GenerativeÂ Models ImprovesÂ Visioâ€‘Linguistic Reasoning inÂ CLIP](http://arxiv.org/abs/2307.09233v3)
- [Textâ€‘guided ImageÂ Restoration andÂ Semantic Enhancement for Textâ€‘toâ€‘Image PersonÂ Retrieval](http://arxiv.org/abs/2307.09059v4)
- [PromptMagician: Interactive Prompt Engineering for Textâ€‘toâ€‘Image Creation](http://arxiv.org/abs/2307.09036v2)
- [PromptCrafter: Crafting Textâ€‘toâ€‘ImageÂ Prompt through Mixedâ€‘InitiativeÂ Dialogue withÂ LLM](http://arxiv.org/abs/2307.08985v1)
- [ImageÂ Captions are Natural Prompts for Textâ€‘toâ€‘Image Models](http://arxiv.org/abs/2307.08526v2)
- [AnalysingÂ Gender Bias inÂ Textâ€‘toâ€‘Image Models using ObjectÂ Detection](http://arxiv.org/abs/2307.08025v1)
- [Can Preâ€‘TrainedÂ Textâ€‘toâ€‘Image Models Generate VisualÂ Goals for ReinforcementÂ Learning?](http://arxiv.org/abs/2307.07837v1)
- [Fast Adaptation with Bradleyâ€‘Terry Preference Models inÂ Textâ€‘Toâ€‘Image Classification andÂ Generation](http://arxiv.org/abs/2308.07929v2)
- [HyperDreamBooth: HyperNetworks for Fast Personalization ofÂ Textâ€‘toâ€‘Image Models](http://arxiv.org/abs/2307.06949v2) [![GitHub Stars](https://img.shields.io/github/stars/JiauZhang/hyperdreambooth?style=social)](https://github.com/JiauZhang/hyperdreambooth)   [![Project Page](https://img.shields.io/badge/Project-Page-blue?logo=website)](https://hyperdreambooth.github.io/)
- [Domainâ€‘Agnostic Tuningâ€‘Encoder for Fast Personalization ofÂ Textâ€‘Toâ€‘ImageÂ Models](http://arxiv.org/abs/2307.06925v1)  [![Project Page](https://img.shields.io/badge/Project-Page-blue?logo=website)](https://datencoder.github.io/)
- [T2Iâ€‘CompBench++: An Enhanced and Comprehensive Benchmark for Compositional Textâ€‘toâ€‘image Generation](http://arxiv.org/abs/2307.06350v3) [![GitHub Stars](https://img.shields.io/github/stars/Karine-Huang/T2I-CompBench?style=social)](https://github.com/Karine-Huang/T2I-CompBench)   [![Project Page](https://img.shields.io/badge/Project-Page-blue?logo=website)](https://karine-h.github.io/T2I-CompBench/)
- [Towards SafeÂ Selfâ€‘Distillation ofÂ Internetâ€‘Scale Textâ€‘toâ€‘Image DiffusionÂ Models](http://arxiv.org/abs/2307.05977v1)
- [TIAMÂ â€“Â A Metric for Evaluating Alignment in Textâ€‘toâ€‘ImageÂ Generation](http://arxiv.org/abs/2307.05134v2) [![GitHub Stars](https://img.shields.io/github/stars/CEA-LIST/TIAMv2?style=social)](https://github.com/CEA-LIST/TIAMv2)
- [ArticulatedÂ 3D HeadÂ Avatar Generation using Textâ€‘toâ€‘Image DiffusionÂ Models](http://arxiv.org/abs/2307.04859v1)
- [Divide, Evaluate, andÂ Refine: Evaluating andÂ ImprovingÂ Textâ€‘toâ€‘Image AlignmentÂ withÂ Iterative VQAÂ Feedback](http://arxiv.org/abs/2307.04749v2) [![GitHub Stars](https://img.shields.io/github/stars/1jsingh/Divide-Evaluate-and-Refine?style=social)](https://github.com/1jsingh/Divide-Evaluate-and-Refine)
- [AnimateDiff: Animate Your PersonalizedÂ Textâ€‘toâ€‘Image DiffusionÂ Models withoutÂ Specific Tuning](http://arxiv.org/abs/2307.04725v2) [![GitHub Stars](https://img.shields.io/github/stars/guoyww/AnimateDiff?style=social)](https://github.com/guoyww/AnimateDiff)   [![Project Page](https://img.shields.io/badge/Project-Page-blue?logo=website)](https://animatediff.github.io/) [![Huggingface Face](https://img.shields.io/badge/Hugging-Face-orange?logo=website)](https://huggingface.co/guoyww/animatediff)
- [Augmenters atÂ SemEvalâ€‘2023 TaskÂ 1: EnhancingÂ CLIP inÂ Handling Compositionality andÂ Ambiguity forÂ Zeroâ€‘Shot VisualÂ WSD throughÂ PromptÂ Augmentation andÂ Textâ€‘Toâ€‘Image Diffusion](http://arxiv.org/abs/2307.05564v1)
- [Typology ofÂ Risks ofÂ Generative Textâ€‘toâ€‘Image Models](http://arxiv.org/abs/2307.05543v1)
- [DIAGNOSIS: Detecting Unauthorized DataÂ Usages inÂ Textâ€‘toâ€‘image DiffusionÂ Models](http://arxiv.org/abs/2307.03108v3)
- [On the CulturalÂ Gap inÂ Textâ€‘toâ€‘ImageÂ Generation](http://arxiv.org/abs/2307.02971v1)
- [Counting Guidance for High Fidelity Textâ€‘toâ€‘ImageÂ Synthesis](http://arxiv.org/abs/2306.17567v3) [![GitHub Stars](https://img.shields.io/github/stars/furiosa-ai/counting-guidance?style=social)](https://github.com/furiosa-ai/counting-guidance)
- [CLIPAG: Towards Generatorâ€‘FreeÂ Textâ€‘toâ€‘Image Generation](http://arxiv.org/abs/2306.16805v2) [![GitHub Stars](https://img.shields.io/github/stars/royg27/CLIPAG?style=social)](https://github.com/royg27/CLIPAG)
- [Localized Textâ€‘toâ€‘Image Generation forÂ Free viaÂ CrossÂ AttentionÂ Control](http://arxiv.org/abs/2306.14636v1)
- [Aâ€‘STAR: Testâ€‘time AttentionÂ Segregation andÂ Retention forÂ Textâ€‘toâ€‘imageÂ Synthesis](http://arxiv.org/abs/2306.14544v1)
- [Textâ€‘Anchored ScoreÂ Composition: Tackling ConditionÂ Misalignment inÂ Textâ€‘toâ€‘Image DiffusionÂ Models](http://arxiv.org/abs/2306.14408v3)
- [Zeroâ€‘shotÂ spatial layout conditioning for textâ€‘toâ€‘image diffusion models](http://arxiv.org/abs/2306.13754v1)
- [The Cultivated Practices of Textâ€‘toâ€‘ImageÂ Generation](http://arxiv.org/abs/2306.11393v3)
- [Pointâ€‘Cloud Completion withÂ Pretrained Textâ€‘toâ€‘image DiffusionÂ Models](http://arxiv.org/abs/2306.10533v1)
- [Energyâ€‘Efficient DownlinkÂ SemanticÂ Generative Communication withÂ Textâ€‘toâ€‘ImageÂ Generators](http://arxiv.org/abs/2306.05041v1)
- [WOUAF: Weight Modulation forÂ UserÂ Attribution andÂ Fingerprinting inÂ Textâ€‘toâ€‘Image DiffusionÂ Models](http://arxiv.org/abs/2306.04744v3) [![GitHub Stars](https://img.shields.io/github/stars/kylemin/WOUAF?style=social)](https://github.com/kylemin/WOUAF)
- [ConceptBed: Evaluating ConceptÂ Learning Abilities ofÂ Textâ€‘toâ€‘Image DiffusionÂ Models](http://arxiv.org/abs/2306.04695v2) [![GitHub Stars](https://img.shields.io/github/stars/ConceptBed/evaluations?style=social)](https://github.com/ConceptBed/evaluations)   [![Project Page](https://img.shields.io/badge/Project-Page-blue?logo=website)](https://conceptbed.github.io/) [![Huggingface Face](https://img.shields.io/badge/Hugging-Face-orange?logo=website)](https://huggingface.co/conceptbed/resultsexplorer)
- [Composition andÂ Deformance: MeasuringÂ Imageability with aÂ Textâ€‘toâ€‘ImageÂ Model](http://arxiv.org/abs/2306.03168v1)
- [Detector Guidance forÂ Multiâ€‘ObjectÂ Textâ€‘toâ€‘ImageÂ Generation](http://arxiv.org/abs/2306.02236v1)
- [Wordâ€‘Level Explanations forÂ AnalyzingÂ Bias inÂ Textâ€‘toâ€‘ImageÂ Models](http://arxiv.org/abs/2306.05500v1)
- [MultilingualÂ ConceptualÂ Coverage inÂ Textâ€‘toâ€‘ImageÂ Models](http://arxiv.org/abs/2306.01735v1)
- [VideoÂ Colorization with Preâ€‘trainedÂ Textâ€‘toâ€‘Image DiffusionÂ Models](http://arxiv.org/abs/2306.01732v1)
- [StyleDrop: Textâ€‘toâ€‘ImageÂ Generation in AnyÂ Style](http://arxiv.org/abs/2306.00983v1)
- [StableRep: SyntheticÂ Images fromÂ Textâ€‘toâ€‘ImageÂ Models Make StrongÂ VisualÂ RepresentationÂ Learners](http://arxiv.org/abs/2306.00984v2)
- [SnapFusion: Textâ€‘toâ€‘Image DiffusionÂ Model onÂ MobileÂ Devices withinÂ TwoÂ Seconds](http://arxiv.org/abs/2306.00980v3)
- [ViCo: Plugâ€‘andâ€‘playÂ Visual Condition forÂ Personalized Textâ€‘toâ€‘imageÂ Generation](http://arxiv.org/abs/2306.00971v2)
- [T2IAT: Measuring Valence andÂ StereotypicalÂ Biases inÂ Textâ€‘toâ€‘ImageÂ Generation](http://arxiv.org/abs/2306.00905v1)
- [ReFACT: Updating Textâ€‘toâ€‘ImageÂ Models byÂ Editing theÂ TextÂ Encoder](http://arxiv.org/abs/2306.00738v2) [![GitHub Stars](https://img.shields.io/github/stars/Technion-CSNLP/ReFACT?style=social)](https://github.com/technion-cs-nlp/ReFACT)   [![Project Page](https://img.shields.io/badge/Project-Page-blue?logo=website)](https://technion-cs-nlp.github.io/ReFACT/)
- [Wuerstchen: AnÂ EfficientÂ Architecture forÂ Largeâ€‘ScaleÂ Textâ€‘toâ€‘Image DiffusionÂ Models](http://arxiv.org/abs/2306.00637v2) [![GitHub Stars](https://img.shields.io/github/stars/dome272/Wuerstchen?style=social)](https://github.com/dome272/Wuerstchen)
- [RealignDiff: Boosting Textâ€‘toâ€‘ImageÂ DiffusionÂ Model withÂ Coarseâ€‘toâ€‘fineÂ SemanticÂ Reâ€‘alignment](http://arxiv.org/abs/2305.19599v5)
- [Translationâ€‘EnhancedÂ MultilingualÂ Textâ€‘toâ€‘ImageÂ Generation](http://arxiv.org/abs/2305.19216v1)
- [Controllable Textâ€‘toâ€‘ImageÂ Generation withÂ GPTâ€‘4](http://arxiv.org/abs/2305.18583v1)
- [RAPHAEL: Textâ€‘toâ€‘ImageÂ Generation via LargeÂ Mixture ofÂ DiffusionÂ Paths](http://arxiv.org/abs/2305.18295v5)
- [VA3: VirtuallyÂ AssuredÂ AmplificationÂ Attack onÂ ProbabilisticÂ CopyrightÂ Protection forÂ Textâ€‘toâ€‘Image GenerativeÂ Models](http://arxiv.org/abs/2312.00057v2)


</details>

</details>

[<small>â‡§ Back to ToC</small>](#contents)

### <span id="conditional">ğŸ•¹ï¸ Conditional Image Generation</span>

<details>
<summary><h4>âœ¨ 2025</h4></summary>

<details>
<summary><h4>âœ… Published Papers</h4></summary>

* **[CVPR 2024]** ***PLACE:*** *Adaptive Layoutâ€‘Semantic Fusion for Semantic Image Synthesis*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2403.01852.pdf) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/cszy98/PLACE)

* **[CVPR 2024]** ***Oneâ€‘Shot Structureâ€‘Aware Stylized Image Synthesis:*** *Oneâ€‘Shot Structureâ€‘Aware Stylized Image Synthesis*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2402.17275.pdf) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/hansam95/OSASIS)

* **[CVPR 2024]** ***Attention Refocusing:*** *Grounded Textâ€‘toâ€‘Image Synthesis with Attention Refocusing*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2306.05427.pdf) [![Project Page](https://img.shields.io/badge/Project-Page-blue?style=for-the-badge&logo=googlechrome&logoColor=white)](https://attention-refocusing.github.io/) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/Attention-Refocusing/attention-refocusing) [![Hugging Face](https://img.shields.io/badge/%F0%9F%A4%97-Hugging_Face-yellow?style=for-the-badge)](https://huggingface.co/spaces/attention-refocusing/Attention-refocusing)

* **[CVPR 2024]** ***CFLD:*** *Coarseâ€‘toâ€‘Fine Latent Diffusion for Poseâ€‘Guided Person Image Synthesis*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2402.18078.pdf) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/YanzuoLu/CFLD)

* **[CVPR 2024]** ***DetDiffusion:*** *Synergizing Generative and Perceptive Models for Enhanced Data Generation and Perception*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2403.13304)

* **[CVPR 2024]** ***CAN:*** *Conditionâ€‘Aware Neural Network for Controlled Image Generation*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2404.01143.pdf)

* **[CVPR 2024]** ***SceneDiffusion:*** *Move Anything with Layered Scene Diffusion*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2404.07178)

* **[CVPR 2024]** ***Zeroâ€‘Painter:*** *Trainingâ€‘Free Layout Control for Textâ€‘toâ€‘Image Synthesis*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://openaccess.thecvf.com/content/CVPR2024/papers/Ohanyan_Zero-Painter_Training-Free_Layout_Control_for_Text-to-Image_Synthesis_CVPR_2024_paper.pdf) 

* **[CVPR 2024]** ***MIGC:*** *Multiâ€‘Instance Generation Controller for Textâ€‘toâ€‘Image Synthesis*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://openaccess.thecvf.com/content/CVPR2024/papers/Zhou_MIGC_Multi-Instance_Generation_Controller_for_Text-to-Image_Synthesis_CVPR_2024_paper.pdf) [![Project Page](https://img.shields.io/badge/Project-Page-blue?style=for-the-badge&logo=googlechrome&logoColor=white)](https://migcproject.github.io/) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/limuloo/MIGC)

* **[CVPR 2024]** ***FreeControl:*** *Trainingâ€‘Free Spatial Control of Any Textâ€‘toâ€‘Image Diffusion Model with Any Condition*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://openaccess.thecvf.com/content/CVPR2024/papers/Mo_FreeControl_Training-Free_Spatial_Control_of_Any_Text-to-Image_Diffusion_Model_with_CVPR_2024_paper.pdf) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/genforce/freecontrol)

* **[ECCV 2024]** ***PreciseControl:*** *Enhancing Textâ€‘Toâ€‘Image Diffusion Models with Fineâ€‘Grained Attribute Control*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2408.05083) [![Project Page](https://img.shields.io/badge/Project-Page-blue?style=for-the-badge&logo=googlechrome&logoColor=white)](https://rishubhpar.github.io/PreciseControl.home/) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/rishubhpar/PreciseControl)

* **[ECCV 2024]** ***AnyControl:*** *Create Your Artwork with Versatile Control on Textâ€‘toâ€‘Image Generation*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://www.ecva.net/papers/eccv_2024/papers_ECCV/papers/01706.pdf) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/open-mmlab/AnyControl)

* **[NeurIPS 2024]** ***Ctrlâ€‘X:*** *Controlling Structure and Appearance for Textâ€‘Toâ€‘Image Generation Without Guidance*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2406.07540) [![Project Page](https://img.shields.io/badge/Project-Page-blue?style=for-the-badge&logo=googlechrome&logoColor=white)](https://genforce.github.io/ctrl-x/) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/genforce/ctrl-x)

* **[ICLR 2024]** ***PCDMs:*** *Advancing Poseâ€‘Guided Image Synthesis with Progressive Conditional Diffusion Models*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2310.06313.pdf) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/muzishen/PCDMs)

* **[WACV 2024]** ***Layout Control with Crossâ€‘Attention Guidance:*** *Trainingâ€‘Free Layout Control with Crossâ€‘Attention Guidance*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://openaccess.thecvf.com/content/WACV2024/papers/Chen_Training-Free_Layout_Control_With_Cross-Attention_Guidance_WACV_2024_paper.pdf) [![Project Page](https://img.shields.io/badge/Project-Page-blue?style=for-the-badge&logo=googlechrome&logoColor=white)](https://silent-chen.github.io/layout-guidance/) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/silent-chen/layout-guidance) [![Hugging Face](https://img.shields.io/badge/%F0%9F%A4%97-Hugging_Face-yellow?style=for-the-badge)](https://huggingface.co/spaces/silentchen/layout-guidance)

* **[AAAI 2024]** ***SSMG:*** *Spatialâ€‘Semantic Map Guided Diffusion Model for Freeâ€‘form Layoutâ€‘toâ€‘image Generation*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2308.10156.pdf)

* **[AAAI 2024]** ***Attention Map Control:*** *Compositional Textâ€‘toâ€‘Image Synthesis with Attention Map Control of Diffusion Models*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2305.13921.pdf) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/OPPO-Mente-Lab/attention-mask-control)


</details>

<details>
<summary><h4>ğŸ’¡ Pre-Print Papers</h4></summary>

- [Condition Weaving Meets Expert Modulation: Towards Universal and Controllable Image Generation](http://arxiv.org/abs/2508.17364v1) [![GitHub Stars](https://img.shields.io/github/stars/gavin-gqzhang/UniGen?style=social)](https://github.com/gavin-gqzhang/UniGen)
- [SafeFix: Targeted Model Repair via Controlled Image Generation](http://arxiv.org/abs/2508.08701v1) [![GitHub Stars](https://img.shields.io/github/stars/oxu2/SafeFix?style=social)](https://github.com/oxu2/SafeFix)
- [MultiRef: Controllable Image Generation with Multiple Visual References](http://arxiv.org/abs/2508.06905v3) [![GitHub Stars](https://img.shields.io/github/stars/Dipsy0830/MultiRef-code?style=social)](https://github.com/Dipsy0830/MultiRef-code) [![Project Page](https://img.shields.io/badge/Project-Page-blue?logo=website)](https://multiref.github.io/)
- [DivControl: Knowledge Diversion for Controllable Image Generation](http://arxiv.org/abs/2507.23620v1)
- [A Practical Investigation of Spatially-Controlled Image Generation with Transformers](http://arxiv.org/abs/2507.15724v1)
- [ControlThinker: Unveiling Latent Semantics for Controllable Image Generation through Visual Reasoning](http://arxiv.org/abs/2506.03596v1) [![GitHub Stars](https://img.shields.io/github/stars/Maplebb/ControlThinker?style=social)](https://github.com/Maplebb/ControlThinker) [![Huggingface Face](https://img.shields.io/badge/Hugging-Face-orange?logo=website)](https://huggingface.co/maplebb/ControlThinker)
- [Dualâ€‘Process Image Generation](http://arxiv.org/abs/2506.01955v1) [![GitHub Stars](https://img.shields.io/github/stars/g-luo/dual_process?style=social)](https://github.com/g-luo/dual_process) [![Project Page](https://img.shields.io/badge/Project-Page-blue?logo=website)](https://dual-process.github.io/)
- [APâ€‘CAP: Advancing Highâ€‘Quality Data Synthesis for Animal Pose Estimation via a Controllable Image Generation Pipeline](http://arxiv.org/abs/2504.00394v1)
- [STAY Diffusion: Styled Layout Diffusion Model for Diverse Layoutâ€‘toâ€‘Image Generation](http://arxiv.org/abs/2503.12213v1)
- [Contractâ€‘Inspired Contest Theory for Controllable Image Generation in Mobile Edge Metaverse](http://arxiv.org/abs/2501.09391v1)
- [Grounding Textâ€‘toâ€‘Image Diffusion Models for Controlled Highâ€‘Quality Image Generation](http://arxiv.org/abs/2501.09194v2)
- [Testâ€‘time Controllable Image Generation by Explicit Spatial Constraint Enforcement](http://arxiv.org/abs/2501.01368v1)
- [EliGen: Entityâ€‘Level Controlled Image Generation with Regional Attention](http://arxiv.org/abs/2501.01097v3) [![GitHub Stars](https://img.shields.io/github/stars/modelscope/DiffSynth-Studio?style=social)](https://github.com/modelscope/DiffSynth-Studio) [![Huggingface Face](https://img.shields.io/badge/Hugging-Face-orange?logo=website)](https://huggingface.co/modelscope/EliGen)
- [TIDE: Achieving Balanced Subjectâ€‘Driven Image Generation via Targetâ€‘Instructed Diffusion Enhancement](http://arxiv.org/abs/2509.06499v1) [![GitHub Stars](https://img.shields.io/github/stars/KomJay520/TIDE?style=social)](https://github.com/KomJay520/TIDE)
- [LEARN: A Storyâ€‘Driven Layoutâ€‘toâ€‘Image Generation Framework for STEM Instruction](http://arxiv.org/abs/2508.11153v1)
- [Localityâ€‘aware Parallel Decoding for Efficient Autoregressive Image Generation](http://arxiv.org/abs/2507.01957v1) [![GitHub Stars](https://img.shields.io/github/stars/mit-han-lab/lpd?style=social)](https://github.com/mit-han-lab/lpd) [![Huggingface Face](https://img.shields.io/badge/Hugging-Face-orange?logo=website)](https://huggingface.co/mit-han-lab/lpd_l_512)
- [Hyperspectral Image Generation with Unmixing Guided Diffusion Model](http://arxiv.org/abs/2506.02601v3)
- [Conditional Panoramic Image Generation via Masked Autoregressive Modeling](http://arxiv.org/abs/2505.16862v1) [![GitHub Stars](https://img.shields.io/github/stars/zhuqiangLu/AOG-NET-360?style=social)](https://github.com/zhuqiangLu/AOG-NET-360)
- [Contextâ€‘Aware Autoregressive Models for Multiâ€‘Conditional Image Generation](http://arxiv.org/abs/2505.12274v1)


</details>

</details>

<details>
<summary><h4>âœ¨ 2024</h4></summary>

<details>
<summary><h4>âœ… Published Papers</h4></summary>

* **[CVPR 2024]** ***PLACE:*** *Adaptive Layoutâ€‘Semantic Fusion for Semantic Image Synthesis*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2403.01852.pdf) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/cszy98/PLACE)

* **[CVPR 2024]** ***Oneâ€‘Shot Structureâ€‘Aware Stylized Image Synthesis:*** *Oneâ€‘Shot Structureâ€‘Aware Stylized Image Synthesis*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2402.17275.pdf) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/hansam95/OSASIS)

* **[CVPR 2024]** ***Attention Refocusing:*** *Grounded Textâ€‘toâ€‘Image Synthesis with Attention Refocusing*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2306.05427.pdf) [![Project Page](https://img.shields.io/badge/Project-Page-blue?style=for-the-badge&logo=googlechrome&logoColor=white)](https://attention-refocusing.github.io/) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/Attention-Refocusing/attention-refocusing) [![Hugging Face](https://img.shields.io/badge/%F0%9F%A4%97-Hugging_Face-yellow?style=for-the-badge)](https://huggingface.co/spaces/attention-refocusing/Attention-refocusing)

* **[CVPR 2024]** ***CFLD:*** *Coarseâ€‘toâ€‘Fine Latent Diffusion for Poseâ€‘Guided Person Image Synthesis*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2402.18078.pdf) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/YanzuoLu/CFLD)

* **[CVPR 2024]** ***DetDiffusion:*** *Synergizing Generative and Perceptive Models for Enhanced Data Generation and Perception*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2403.13304) 

* **[CVPR 2024]** ***CAN:*** *Conditionâ€‘Aware Neural Network for Controlled Image Generation*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2404.01143.pdf)

* **[CVPR 2024]** ***SceneDiffusion:*** *Move Anything with Layered Scene Diffusion*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2404.07178)

* **[CVPR 2024]** ***Zeroâ€‘Painter:*** *Trainingâ€‘Free Layout Control for Textâ€‘toâ€‘Image Synthesis*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://openaccess.thecvf.com/content/CVPR2024/papers/Ohanyan_Zero-Painter_Training-Free_Layout_Control_for_Text-to-Image_Synthesis_CVPR_2024_paper.pdf) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/Picsart-AI-Research/Zero-Painter)

* **[CVPR 2024]** ***MIGC:*** *Multiâ€‘Instance Generation Controller for Textâ€‘toâ€‘Image Synthesis*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://openaccess.thecvf.com/content/CVPR2024/papers/Zhou_MIGC_Multi-Instance_Generation_Controller_for_Text-to-Image_Synthesis_CVPR_2024_paper.pdf) [![Project Page](https://img.shields.io-badge/Project-Page-blue?style=for-the-badge&logo=googlechrome&logoColor=white)](https://migcproject.github.io/) [![GitHub](https://img.shields.io-badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/limuloo/MIGC)

* **[CVPR 2024]** ***FreeControl:*** *Trainingâ€‘Free Spatial Control of Any Textâ€‘toâ€‘Image Diffusion Model with Any Condition*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://openaccess.thecvf.com/content/CVPR2024/papers/Mo_FreeControl_Training-Free_Spatial_Control_of_Any_Text-to-Image_Diffusion_Model_with_CVPR_2024_paper.pdf) [![GitHub](https://img.shields.io-badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/genforce/freecontrol)

* **[ECCV 2024]** ***PreciseControl:*** *Enhancing Textâ€‘Toâ€‘Image Diffusion Models with Fineâ€‘Grained Attribute Control*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2408.05083) [![Project Page](https://img.shields.io-badge/Project-Page-blue?style=for-the-badge&logo=googlechrome&logoColor=white)](https://rishubhpar.github.io/PreciseControl.home/) [![GitHub](https://img.shields.io-badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/rishubhpar/PreciseControl) 

* **[ECCV 2024]** ***AnyControl:*** *Create Your Artwork with Versatile Control on Textâ€‘toâ€‘Image Generation*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://www.ecva.net/papers/eccv_2024/papers_ECCV/papers/01706.pdf) [![GitHub](https://img.shields.io-badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/open-mmlab/AnyControl) 

* **[NeurIPS 2024]** ***Ctrlâ€‘X:*** *Controlling Structure and Appearance for Textâ€‘Toâ€‘Image Generation Without Guidance*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2406.07540) [![Project Page](https://img.shields.io-badge/Project-Page-blue?style=for-the-badge&logo=googlechrome&logoColor=white)](https://genforce.github.io/ctrl-x/) [![GitHub](https://img.shields.io-badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/genforce/ctrl-x) 

* **[ICLR 2024]** ***PCDMs:*** *Advancing Poseâ€‘Guided Image Synthesis with Progressive Conditional Diffusion Models*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2310.06313.pdf) [![GitHub](https://img.shields.io-badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/muzishen/PCDMs) 

* **[WACV 2024]** ***Layout Control with Crossâ€‘Attention Guidance:*** *Trainingâ€‘Free Layout Control with Crossâ€‘Attention Guidance*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://openaccess.thecvf.com/content/WACV2024/papers/Chen_Training-Free_Layout_Control_With_Cross-Attention_Guidance_WACV_2024_paper.pdf) [![Project Page](https://img.shields.io/badge/Project-Page-blue?style=for-the-badge&logo=googlechrome&logoColor=white)](https://silent-chen.github.io/layout-guidance/) [![GitHub](https://img.shields.io-badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/silent-chen/layout-guidance) [![Hugging Face](https://img.shields.io/badge/%F0%9F%A4%97-Hugging_Face-yellow?style=for-the-badge)](https://huggingface.co/spaces/silentchen/layout-guidance)

* **[AAAI 2024]** ***SSMG:*** *Spatialâ€‘Semantic Map Guided Diffusion Model for Freeâ€‘form Layoutâ€‘toâ€‘image Generation*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2308.10156.pdf)

* **[AAAI 2024]** ***Attention Map Control:*** *Compositional Textâ€‘toâ€‘Image Synthesis with Attention Map Control of Diffusion Models*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2305.13921.pdf) [![GitHub](https://img.shields.io-badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/OPPO-Mente-Lab/attention-mask-control)


</details>

<details>
<summary><h4>ğŸ’¡ Pre-Print Papers</h4></summary>

- [UNICâ€‘Adapter: Unified Imageâ€‘instruction Adapter with Multiâ€‘modal Transformer for Image Generation](http://arxiv.org/abs/2412.18928v1)   [![Huggingface Face](https://img.shields.io/badge/Hugging-Face-orange?logo=website)](https://huggingface.co/AIDC-AI/UNIC-Adapter)
- [Steering Rectified Flow Models in the Vector Field for Controlled Image Generation](http://arxiv.org/abs/2412.00100v1) [![GitHub Stars](https://img.shields.io/github/stars/FlowChef/flowchef?style=social)](https://github.com/FlowChef/flowchef) [![Project Page](https://img.shields.io/badge/Project-Page-blue?logo=website)](https://flowchef.github.io) [![Huggingface Face](https://img.shields.io/badge/Hugging-Face-orange?logo=website)](https://huggingface.co/FlowChef)
- [Enhancing Weakly Supervised Semantic Segmentation for Fibrosis via Controllable Image Generation](http://arxiv.org/abs/2411.03551v1)
- [CtrLoRA: An Extensible and Efficient Framework for Controllable Image Generation](http://arxiv.org/abs/2410.09400v2) [![GitHub Stars](https://img.shields.io/github/stars/xyfJASON/ctrlora?style=social)](https://github.com/xyfJASON/ctrlora) [![Huggingface Face](https://img.shields.io/badge/Hugging-Face-orange?logo=website)](https://huggingface.co/xyfJASON/ctrlora)
- [ControlAR: Controllable Image Generation with Autoregressive Models](http://arxiv.org/abs/2410.02705v3) [![GitHub Stars](https://img.shields.io/github/stars/hustvl/ControlAR?style=social)](https://github.com/hustvl/ControlAR) [![Huggingface Face](https://img.shields.io/badge/Hugging-Face-orange?logo=website)](https://huggingface.co/wondervictor/ControlAR)
- [BrainDreamer: Reasoningâ€‘Coherent and Controllable Image Generation from EEG Brain Signals via Language Guidance](http://arxiv.org/abs/2409.14021v1)
- [CSGO: Contentâ€‘Style Composition in Textâ€‘toâ€‘Image Generation](http://arxiv.org/abs/2408.16766v2) [![GitHub Stars](https://img.shields.io/github/stars/InstantX-research/CSGO?style=social)](https://github.com/InstantXâ€‘research/CSGO) [![Project Page](https://img.shields.io/badge/Project-Page-blue?logo=website)](https://csgo-gen.github.io) [![Huggingface Face](https://img.shields.io/badge/Hugging-Face-orange?logo=website)](https://huggingface.co/InstantX/CSGO)
- [MUSES: 3Dâ€‘Controllable Image Generation via Multiâ€‘Modal Agent Collaboration](http://arxiv.org/abs/2408.10605v5) [![GitHub Stars](https://img.shields.io/github/stars/DINGYANB/MUSES?style=social)](https://github.com/DINGYANB/MUSES) [![Huggingface Face](https://img.shields.io/badge/Hugging-Face-orange?logo=website)](https://huggingface.co/yanboding/MUSES)
- [Promptâ€‘Consistency Image Generation (PCIG): A Unified Framework Integrating LLMs, Knowledge Graphs, and Controllable Diffusion Models](http://arxiv.org/abs/2406.16333v1) [![GitHub Stars](https://img.shields.io/github/stars/TruthAI-Lab/PCIG?style=social)](https://github.com/TruthAI-Lab/PCIG)
- [Controllable Image Generation With Composed Parallel Token Prediction](http://arxiv.org/abs/2405.06535v1)
- [Conditionâ€‘Aware Neural Network for Controlled Image Generation](http://arxiv.org/abs/2404.01143v1) [![GitHub Stars](https://img.shields.io/github/stars/mit-han-lab/efficientvit?style=social)](https://github.com/mit-han-lab/efficientvit)
- [Refining Textâ€‘toâ€‘Image Generation: Towards Accurate Trainingâ€‘Free Glyphâ€‘Enhanced Image Generation](http://arxiv.org/abs/2403.16422v2)
- [GazeFusion: Saliencyâ€‘Guided Image Generation](http://arxiv.org/abs/2407.04191v2) [![GitHub Stars](https://img.shields.io/github/stars/NYU-ICL/saliency-guided-image-generation?style=social)](https://github.com/NYU-ICL/saliency-guided-image-generation)
- [TCIG: Twoâ€‘Stage Controlled Image Generation with Quality Enhancement through Diffusion](http://arxiv.org/abs/2403.01212v1)
- [Text2Street: Controllable Textâ€‘toâ€‘Image Generation for Street Views](http://arxiv.org/abs/2402.04504v1)
- [Spatialâ€‘Aware Latent Initialization for Controllable Image Generation](http://arxiv.org/abs/2401.16157v1)
- [PIXARTâ€‘Î´: Fast and Controllable Image Generation with Latent Consistency Models](http://arxiv.org/abs/2401.05252v1) [![Project Page](https://img.shields.io/badge/Project-Page-blue?logo=website)](https://pixart-alpha.github.io) [![Huggingface Face](https://img.shields.io/badge/Hugging-Face-orange?logo=website)](https://huggingface.co/collections/PixArt-alpha/pixart-delta-lcm)
- [OmniControlNet: Dualâ€‘stage Integration for Conditional Image Generation](http://arxiv.org/abs/2406.05871v1) [![GitHub Stars](https://img.shields.io/github/stars/Yuanshi9815/OminiControl?style=social)](https://github.com/Yuanshi9815/OminiControl) [![Huggingface Face](https://img.shields.io/badge/Hugging-Face-orange?logo=website)](https://huggingface.co/Yuanshi/OminiControl)



</details>

</details>

<details>
<summary><h4>âœ¨ 2023</h4></summary>

<details>
<summary><h4>âœ… Published Papers</h4></summary>

* **[CVPR 2023]** ***GLIGEN:*** *Open-Set Grounded Text-to-Image Generation*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://openaccess.thecvf.com/content/CVPR2023/papers/Li_GLIGEN_Open-Set_Grounded_Text-to-Image_Generation_CVPR_2023_paper.pdf) [![Project Page](https://img.shields.io/badge/Project-Page-blue?style=for-the-badge&logo=googlechrome&logoColor=white)](https://gligen.github.io/) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/gligen/GLIGEN) [![Hugging Face](https://img.shields.io/badge/%F0%9F%A4%97-Hugging_Face-yellow?style=for-the-badge)](https://huggingface.co/spaces/gligen/demo)

* **[CVPR 2022]** ***Autoregressive Image Generation:*** *Using Residual Quantization*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://openaccess.thecvf.com/content/CVPR2022/papers/Lee_Autoregressive_Image_Generation_Using_Residual_Quantization_CVPR_2022_paper.pdf) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/kakaobrain/rq-vae-transformer)

* **[CVPR 2023]** ***SpaText:*** *Spatio-Textual Representation for Controllable Image Generation*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://openaccess.thecvf.com/content/CVPR2023/papers/Avrahami_SpaText_Spatio-Textual_Representation_for_Controllable_Image_Generation_CVPR_2023_paper.pdf) [![Project Page](https://img.shields.io/badge/Project-Page-blue?style=for-the-badge&logo=googlechrome&logoColor=white)](https://omriavrahami.com/spatext/)

* **[CVPR 2022]** ***Text to Image Generation with Semantic-Spatial Aware GAN:*** *Text to Image Generation with Semantic-Spatial Aware GAN*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://openaccess.thecvf.com/content/CVPR2022/papers/Liao_Text_to_Image_Generation_With_Semantic-Spatial_Aware_GAN_CVPR_2022_paper.pdf)

* **[CVPR 2023]** ***ReCo:*** *Region-Controlled Text-to-Image Generation*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://openaccess.thecvf.com/content/CVPR2023/papers/Yang_ReCo_Region-Controlled_Text-to-Image_Generation_CVPR_2023_paper.pdf) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/microsoft/ReCo)

* **[CVPR 2023]** ***LayoutDiffusion:*** *Controllable Diffusion Model for Layout-to-Image Generation*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://openaccess.thecvf.com/content/CVPR2023/papers/Zheng_LayoutDiffusion_Controllable_Diffusion_Model_for_Layout-to-Image_Generation_CVPR_2023_paper.pdf) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/ZGCTroy/LayoutDiffusion)

* **[ICLR 2023]** ***Ctrl-U:*** *Robust Conditional Image Generation via Uncertainty-aware Reward Modeling*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://openreview.net/forum?id=eC2ICbECNM) [![Project Page](https://img.shields.io/badge/Project-Page-blue?style=for-the-badge&logo=googlechrome&logoColor=white)](https://grenoble-zhang.github.io/Ctrl-U-Page/) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/grenoble-zhang/Ctrl-U)

* **[ICCV 2023]** ***ControlNet:*** *Adding Conditional Control to Text-to-Image Diffusion Models*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Adding_Conditional_Control_to_Text-to-Image_Diffusion_Models_ICCV_2023_paper.pdf) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/lllyasviel/ControlNet) [![Hugging Face](https://img.shields.io/badge/%F0%9F%A4%97-Hugging_Face-yellow?style=for-the-badge)](https://huggingface.co/lllyasviel/ControlNet)

* **[ICCV 2023]** ***SceneGenie:*** *Scene Graph Guided Diffusion Models for Image Synthesis*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://openaccess.thecvf.com/content/ICCV2023W/SG2RL/papers/Farshad_SceneGenie_Scene_Graph_Guided_Diffusion_Models_for_Image_Synthesis_ICCVW_2023_paper.pdf)

* **[ICCV 2023]** ***ZestGuide:*** *Zero-Shot Spatial Layout Conditioning for Text-to-Image Diffusion Models*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://openaccess.thecvf.com/content/ICCV2023/papers/Couairon_Zero-Shot_Spatial_Layout_Conditioning_for_Text-to-Image_Diffusion_Models_ICCV_2023_paper.pdf)

* **[ICML 2023]** ***Composer:*** *Creative and Controllable Image Synthesis with Composable Conditions*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://proceedings.mlr.press/v202/huang23b/huang23b.pdf) [![Project Page](https://img.shields.io/badge/Project-Page-blue?style=for-the-badge&logo=googlechrome&logoColor=white)](https://ali-vilab.github.io/composer-page/) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/ali-vilab/composer)

* **[ICML 2023]** ***MultiDiffusion:*** *Fusing Diffusion Paths for Controlled Image Generation*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://proceedings.mlr.press/v202/bar-tal23a/bar-tal23a.pdf) [![Project Page](https://img.shields.io/badge/Project-Page-blue?style=for-the-badge&logo=googlechrome&logoColor=white)](https://multidiffusion.github.io/) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/omerbt/MultiDiffusion) [![Hugging Face](https://img.shields.io/badge/%F0%9F%A4%97-Hugging_Face-yellow?style=for-the-badge)](https://huggingface.co/spaces/weizmannscience/MultiDiffusion)

* **[SIGGRAPH 2023]** ***Sketch-Guided Text-to-Image Diffusion Models:*** *Sketch-Guided Text-to-Image Diffusion Models*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://dl.acm.org/doi/pdf/10.1145/3588432.3591560) [![Project Page](https://img.shields.io/badge/Project-Page-blue?style=for-the-badge&logo=googlechrome&logoColor=white)](https://sketch-guided-diffusion.github.io/) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/ogkalu2/Sketch-Guided-Stable-Diffusion)

* **[NeurIPS 2023]** ***Uni-ControlNet:*** *All-in-One Control to Text-to-Image Diffusion Models*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2305.16322.pdf) [![Project Page](https://img.shields.io/badge/Project-Page-blue?style=for-the-badge&logo=googlechrome&logoColor=white)](https://shihaozhaozsh.github.io/unicontrolnet/) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/ShihaoZhaoZSH/Uni-ControlNet)

* **[NeurIPS 2023]** ***Prompt Diffusion:*** *In-Context Learning Unlocked for Diffusion Models*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://openreview.net/pdf?id=6BZS2EAkns) [![Project Page](https://img.shields.io/badge/Project-Page-blue?style=for-the-badge&logo=googlechrome&logoColor=white)](https://zhendong-wang.github.io/prompt-diffusion.github.io/) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/Zhendong-Wang/Prompt-Diffusion)

* **[WACV 2023]** ***More Control for Free!:*** *Image Synthesis with Semantic Diffusion Guidance*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://openaccess.thecvf.com/content/WACV2023/papers/Liu_More_Control_for_Free_Image_Synthesis_With_Semantic_Diffusion_Guidance_WACV_2023_paper.pdf)

* **[ACM MM 2023]** ***LayoutLLM-T2I:*** *Eliciting Layout Guidance from LLM for Text-to-Image Generation*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2308.05095.pdf)


</details>

<details>
<summary><h4>ğŸ’¡ Pre-Print Papers</h4></summary>

- [DiffusionÂ Selfâ€‘GuidanceÂ forÂ ControllableÂ ImageÂ Generation](http://arxiv.org/abs/2306.00986v3) [![GitHub Stars](https://img.shields.io/github/stars/superolly/self-guidance?style=social)](https://github.com/superolly/self-guidance)
- [RobustÂ ImageÂ OrdinalÂ RegressionÂ withÂ ControllableÂ ImageÂ Generation](http://arxiv.org/abs/2305.04213v3) [![GitHub Stars](https://img.shields.io/github/stars/Ch3ngY1/Controllable-Image-Generation?style=social)](https://github.com/Ch3ngY1/Controllable-Image-Generation)
- [ControllableÂ ImageÂ GenerationÂ viaÂ CollageÂ Representations](http://arxiv.org/abs/2304.13722v1)
- [DiagnosticÂ BenchmarkÂ andÂ IterativeÂ InpaintingÂ forÂ Layoutâ€‘GuidedÂ ImageÂ Generation](http://arxiv.org/abs/2304.06671v3) [![GitHub Stars](https://img.shields.io/github/stars/j-min/IterInpaint?style=social)](https://github.com/j-min/IterInpaint) [![Project Page](https://img.shields.io/badge/Project-Page-blue?logo=website)](https://layoutbench.github.io) [![Huggingface Face](https://img.shields.io/badge/Hugging-Face-orange?logo=website)](https://huggingface.co/spaces/j-min/IterInpaint-CLEVR)
- [NoisyTwins:Â Classâ€‘ConsistentÂ andÂ DiverseÂ ImageÂ GenerationÂ throughÂ StyleGANs](http://arxiv.org/abs/2304.05866v1) [![GitHub Stars](https://img.shields.io/github/stars/val-iisc/NoisyTwins?style=social)](https://github.com/val-iisc/NoisyTwins) [![Project Page](https://img.shields.io/badge/Project-Page-blue?logo=website)](https://rangwani-harsh.github.io/NoisyTwins)
- [GlueGen:Â PlugÂ andÂ PlayÂ Multiâ€‘modalÂ EncodersÂ forÂ Xâ€‘toâ€‘imageÂ Generation](http://arxiv.org/abs/2303.10056v2) [![GitHub Stars](https://img.shields.io/github/stars/salesforce/GlueGen?style=social)](https://github.com/salesforce/GlueGen)
- [MultiDiffusion:Â FusingÂ DiffusionÂ PathsÂ forÂ ControlledÂ ImageÂ Generation](http://arxiv.org/abs/2302.08113v1) [![GitHub Stars](https://img.shields.io/github/stars/omerbt/MultiDiffusion?style=social)](https://github.com/omerbt/MultiDiffusion) [![Project Page](https://img.shields.io/badge/Project-Page-blue?logo=website)](https://multidiffusion.github.io) [![Huggingface Face](https://img.shields.io/badge/Hugging-Face-orange?logo=website)](https://huggingface.co/spaces/weizmannscience/MultiDiffusion)



</details>

</details>

[<small>â‡§ Back to ToC</small>](#contents)

### <span id="personalized">ğŸ¨ Personalized Image Generation</span>

<details>
<summary><h4>âœ¨ 2025</h4></summary>

<details>
<summary><h4>âœ… Published Papers</h4></summary>

* **[CVPR 2025]** ***SerialGen:*** *Personalized Image Generation by First Standardization Then Personalization*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2412.01485) [![Project Page](https://img.shields.io/badge/Project-Page-blue?style=for-the-badge&logo=googlechrome&logoColor=white)](https://serialgen.github.io/) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/)

* **[CVPR 2025]** ***PatchDPO:*** *Patch-level DPO for Finetuning-free Personalized Image Generation*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2412.03177) [![Project Page](https://img.shields.io/badge/Project-Page-blue?style=for-the-badge&logo=googlechrome&logoColor=white)](https://github.com/hqhQAQ/PatchDPO) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/hqhQAQ/PatchDPO) [![Hugging Face](https://img.shields.io/badge/%F0%9F%A4%97-Hugging_Face-yellow?style=for-the-badge)](https://huggingface.co/hqhQAQ/PatchDPO)

* **[CVPR 2025]** ***DreamCache:*** *Finetuning-Free Lightweight Personalized Image Generation via Feature Caching*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2411.17786) [![Project Page](https://img.shields.io/badge/Project-Page-blue?style=for-the-badge&logo=googlechrome&logoColor=white)](https://emanuele97x.github.io/DreamCache) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/Emanuele97x/DreamCache)

* **[NeurIPS 2025]** ***MS-Diffusion:*** *Multi-Subject Zero-shot Image Personalization with Layout Guidance*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2406.07209) [![Project Page](https://img.shields.io/badge/Project-Page-blue?style=for-the-badge&logo=googlechrome&logoColor=white)](https://ms-diffusion.github.io/) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/MS-Diffusion/MS-Diffusion) [![Hugging Face](https://img.shields.io/badge/%F0%9F%A4%97-Hugging_Face-yellow?style=for-the-badge)](https://huggingface.co/doge1516/MS-Diffusion)

* **[NeurIPS 2025]** ***ClassDiffusion:*** *More Aligned Personalization Tuning with Explicit Class Guidance*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://openreview.net/pdf?id=iTm4H6N4aG) [![Project Page](https://img.shields.io/badge/Project-Page-blue?style=for-the-badge&logo=googlechrome&logoColor=white)](https://classdiffusion.github.io/) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/Rbrq03/ClassDiffusion)

* **[NeurIPS 2025]** ***DreamBench++:*** *A Human-Aligned Benchmark for Personalized Image Generation*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2406.16855) [![Project Page](https://img.shields.io/badge/Project-Page-blue?style=for-the-badge&logo=googlechrome&logoColor=white)](https://dreambenchplus.github.io/) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/yuangpeng/dreambench_plus) [![Hugging Face](https://img.shields.io/badge/%F0%9F%A4%97-Hugging_Face-yellow?style=for-the-badge)](https://huggingface.co/datasets/yuangpeng/dreambench_plus)

* **[NeurIPS 2025]** ***TweedieMix:*** *Improving Multi-Concept Fusion for Diffusion-based Image/Video Generation*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2410.05591) [![Project Page](https://img.shields.io/badge/Project-Page-blue?style=for-the-badge&logo=googlechrome&logoColor=white)](https://github.com/KwonGihyun/TweedieMix) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/KwonGihyun/TweedieMix)


</details>

<details>
<summary><h4>ğŸ’¡ Pre-Print Papers</h4></summary>

- [FocusDPO: Dynamic Preference Optimization for Multi-Subject Personalized Image Generation via Adaptive Focus](http://arxiv.org/abs/2509.01181v1) [![GitHub Stars](https://img.shields.io/github/stars/bytedance-fanqie-ai/FocusDPO?style=social)](https://github.com/bytedance-fanqie-ai/FocusDPO)   [![Project Page](https://img.shields.io/badge/Project-Page-blue?logo=website)](https://bytedance-fanqie-ai.github.io/FocusDPO/)
- [MM-R1: Unleashing the Power of Unified Multimodal Large Language Models for Personalized Image Generation](http://arxiv.org/abs/2508.11433v2)
- [Anti-Tamper Protection for Unauthorized Individual Image Generation](http://arxiv.org/abs/2508.06325v1) [![GitHub Stars](https://img.shields.io/github/stars/Seeyn/Anti-Tamper-Perturbation?style=social)](https://github.com/Seeyn/Anti-Tamper-Perturbation)
- [Improving Personalized Image Generation through Social Context Feedback](http://arxiv.org/abs/2507.16095v1)
- [A Training-Free Styleâ€‘Personalization via Scaleâ€‘wise Autoregressive Model](http://arxiv.org/abs/2507.04482v1)
- [Personalized Image Generation from an Author Writing Style](http://arxiv.org/abs/2507.03313v1)
- [TaleForge: Interactive Multimodal System for Personalized Story Creation](http://arxiv.org/abs/2506.21832v1)
- [AlignGen: Boosting Personalized Image Generation with Crossâ€‘Modality Prior Alignment](http://arxiv.org/abs/2505.21911v1)
- [RAGAR: Retrieval Augmented Personalized Image Generation Guided by Recommendation](http://arxiv.org/abs/2505.01657v2)
- [DRC: Enhancing Personalized Image Generation via Disentangled Representation Composition](http://arxiv.org/abs/2504.17349v2)
- [Personalized Textâ€‘toâ€‘Image Generation with Autoâ€‘Regressive Models](http://arxiv.org/abs/2504.13162v1) [![GitHub Stars](https://img.shields.io/github/stars/KaiyueSun98/T2I-Personalization-with-AR?style=social)](https://github.com/KaiyueSun98/T2I-Personalization-with-AR)
- [ACâ€‘LoRA: Auto Component LoRA for Personalized Artistic Style Image Generation](http://arxiv.org/abs/2504.02231v1)
- [Single Image Iterative Subjectâ€‘driven Generation and Editing](http://arxiv.org/abs/2503.16025v1) [![GitHub Stars](https://img.shields.io/github/stars/yairshp/SISO?style=social)](https://github.com/yairshp/SISO)   [![Project Page](https://img.shields.io/badge/Project-Page-blue?logo=website)](https://siso-paper.github.io/)
- [Personalize Anything for Free with Diffusion Transformer](http://arxiv.org/abs/2503.12590v1) [![GitHub Stars](https://img.shields.io/github/stars/fenghora/personalize-anything?style=social)](https://github.com/fenghora/personalize-anything)   [![Project Page](https://img.shields.io/badge/Project-Page-blue?logo=website)](https://fenghora.github.io/Personalize-Anything-Page/) [![Huggingface Face](https://img.shields.io/badge/Hugging-Face-orange?logo=website)](https://huggingface.co/black-forest-labs/FLUX.1-dev)
- [Towards More Accurate Personalized Image Generation: Addressing Overfitting and Evaluation Bias](http://arxiv.org/abs/2503.06632v1) [![GitHub Stars](https://img.shields.io/github/stars/Mingxiao-Li/Towards-More-Accurate-Personalized-Image-Generation?style=social)](https://github.com/Mingxiao-Li/Towards-More-Accurate-Personalized-Image-Generation)
- [Conceptrol: Concept Control of Zeroâ€‘shot Personalized Image Generation](http://arxiv.org/abs/2503.06568v1) [![GitHub Stars](https://img.shields.io/github/stars/QY-H00/Conceptrol?style=social)](https://github.com/QY-H00/Conceptrol)   [![Project Page](https://img.shields.io/badge/Project-Page-blue?logo=website)](https://qy-h00.github.io/Conceptrol/) [![Huggingface Face](https://img.shields.io/badge/Hugging-Face-orange?logo=website)](https://huggingface.co/spaces/qyoo/Conceptrol)
- [Personalized Image Generation with Deep Generative Models: A Decade Survey](http://arxiv.org/abs/2502.13081v1) [![GitHub Stars](https://img.shields.io/github/stars/csyxwei/Awesome-Personalized-Image-Generation?style=social)](https://github.com/csyxwei/Awesome-Personalized-Image-Generation)
- [Beyond Fineâ€‘Tuning: A Systematic Study of Sampling Techniques in Personalized Image Generation](http://arxiv.org/abs/2502.05895v1) [![GitHub Stars](https://img.shields.io/github/stars/ControlGenAI/PersonGenSampler?style=social)](https://github.com/ControlGenAI/PersonGenSampler)
- [Enhanced Multiâ€‘Scale Crossâ€‘Attention for Person Image Generation](http://arxiv.org/abs/2501.08900v1)
- [SceneBooth: Diffusionâ€‘based Framework for Subjectâ€‘preserved Textâ€‘toâ€‘Image Generation](http://arxiv.org/abs/2501.03490v1)


</details>

</details>

<details>
<summary><h4>âœ¨ 2024</h4></summary>

<details>
<summary><h4>âœ… Published Papers</h4></summary>

* **[CVPR 2024]** ***CrossÂ Initialization:*** *PersonalizedÂ Textâ€‘toâ€‘ImageÂ Generation*<br>
  [![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2312.15905.pdf)

* **[CVPR 2024]** ***WhenÂ StyleGANÂ MeetsÂ StableÂ Diffusion:*** *aÂ W+Â AdapterÂ forÂ PersonalizedÂ ImageÂ Generation*<br>
  [![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2311.17461.pdf) [![Project Page](https://img.shields.io/badge/Project-Page-blue?style=for-the-badge&logo=googlechrome&logoColor=white)](https://csxmli2016.github.io/projects/w-plus-adapter/) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/csxmli2016/w-plus-adapter)

* **[CVPR 2024]** ***StyleÂ Aligned:*** *ImageÂ GenerationÂ viaÂ SharedÂ Attention*<br>
  [![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2312.02133.pdf) [![Project Page](https://img.shields.io/badge/Project-Page-blue?style=for-the-badge&logo=googlechrome&logoColor=white)](https://style-aligned-gen.github.io/) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/google/style-aligned)

* **[CVPR 2024]** ***InstantBooth:*** *PersonalizedÂ Textâ€‘toâ€‘ImageÂ GenerationÂ withoutÂ Testâ€‘TimeÂ Finetuning*<br>
  [![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2304.03411.pdf) [![Project Page](https://img.shields.io/badge/Project-Page-blue?style=for-the-badge&logo=googlechrome&logoColor=white)](https://jshi31.github.io/InstantBooth/)

* **[CVPR 2024]** ***HighÂ Fidelity:*** *Personâ€‘centricÂ Subjectâ€‘toâ€‘ImageÂ Synthesis*<br>
  [![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2311.10329.pdf)

* **[CVPR 2024]** ***RealCustom:*** *NarrowingÂ RealÂ TextÂ WordÂ forÂ Realâ€‘TimeÂ Openâ€‘DomainÂ Textâ€‘toâ€‘ImageÂ Customization*<br>
  [![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2403.00483.pdf) [![Project Page](https://img.shields.io/badge/Project-Page-blue?style=for-the-badge&logo=googlechrome&logoColor=white)](https://corleone-huang.github.io/realcustom/) [![ğŸ¤—Â HuggingÂ Face](https://img.shields.io/badge/%F0%9F%A4%97-Hugging_Face-yellow?style=for-the-badge)](https://huggingface.co/bytedance-research/RealCustom)

* **[CVPR 2024]** ***DisenDiff:*** *AttentionÂ CalibrationÂ forÂ DisentangledÂ Textâ€‘toâ€‘ImageÂ Personalization*<br>
  [![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2403.18551) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/Monalissaa/DisenDiff)

* **[CVPR 2024]** ***FreeCustom:*** *Tuningâ€‘FreeÂ CustomizedÂ ImageÂ GenerationÂ forÂ Multiâ€‘ConceptÂ Composition*<br>
  [![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2405.13870v1) [![Project Page](https://img.shields.io/badge/Project-Page-blue?style=for-the-badge&logo=googlechrome&logoColor=white)](https://aim-uofa.github.io/FreeCustom/) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/aim-uofa/FreeCustom)

* **[CVPR 2024]** ***PersonalizedÂ Residuals:*** *forÂ Conceptâ€‘DrivenÂ Textâ€‘toâ€‘ImageÂ Generation*<br>
  [![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2405.12978)

* **[CVPR 2024]** ***Subjectâ€‘AgnosticÂ Guidance:*** *ImprovingÂ Subjectâ€‘DrivenÂ ImageÂ Synthesis*<br>
  [![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2405.01356)

* **[CVPR 2024]** ***JeDi:*** *Jointâ€‘ImageÂ DiffusionÂ ModelsÂ forÂ Finetuningâ€‘FreeÂ PersonalizedÂ Textâ€‘toâ€‘ImageÂ Generation*<br>
  [![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://openaccess.thecvf.com/content/CVPR2024/papers/Zeng_JeDi_Joint-Image_Diffusion_Models_for_Finetuning-Free_Personalized_Text-to-Image_Generation_CVPR_2024_paper.pdf)

* **[CVPR 2024]** ***InfluenceÂ Watermarks:*** *CounteringÂ PersonalizedÂ Textâ€‘toâ€‘ImageÂ Generation*<br>
  [![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://openaccess.thecvf.com/content/CVPR2024/papers/Liu_Countering_Personalized_Text-to-Image_Generation_with_Influence_Watermarks_CVPR_2024_paper.pdf)

* **[CVPR 2024]** ***PIA:*** *YourÂ PersonalizedÂ ImageÂ AnimatorÂ viaÂ Plugâ€‘andâ€‘PlayÂ ModulesÂ inÂ Textâ€‘toâ€‘ImageÂ Models*<br>
  [![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://openaccess.thecvf.com/content/CVPR2024/papers/Zhang_PIA_Your_Personalized_Image_Animator_via_Plug-and-Play_Modules_in_Text-to-Image_CVPR_2024_paper.pdf) [![Project Page](https://img.shields.io/badge/Project-Page-blue?style=for-the-badge&logo=googlechrome&logoColor=white)](https://pi-animator.github.io/) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/open-mmlab/PIA)

* **[CVPR 2024]** ***SSRâ€‘Encoder:*** *EncodingÂ SelectiveÂ SubjectÂ RepresentationÂ forÂ Subjectâ€‘DrivenÂ Generation*<br>
  [![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://openaccess.thecvf.com/content/CVPR2024/papers/Zhang_SSR-Encoder_Encoding_Selective_Subject_Representation_for_Subject-Driven_Generation_CVPR_2024_paper.pdf) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/Xiaojiu-z/SSR_Encoder)

* **[ECCV 2024]** ***BeÂ Yourself:*** *BoundedÂ AttentionÂ forÂ Multiâ€‘SubjectÂ Textâ€‘toâ€‘ImageÂ Generation*<br>
  [![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2403.16990) [![Project Page](https://img.shields.io/badge/Project-Page-blue?style=for-the-badge&logo=googlechrome&logoColor=white)](https://omer11a.github.io/bounded-attention/)

* **[ECCV 2024]** ***PowerfulÂ andÂ Flexible:*** *PersonalizedÂ Textâ€‘toâ€‘ImageÂ GenerationÂ viaÂ ReinforcementÂ Learning*<br>
  [![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](http://arxiv.org/pdf/2407.06642v1) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/wfanyue/DPG-T2I-Personalization)

* **[ECCV 2024]** ***TIGC:*** *Tuningâ€‘FreeÂ ImageÂ CustomizationÂ withÂ ImageÂ andÂ TextÂ Guidance*<br>
  [![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2403.12658) [![Project Page](https://img.shields.io/badge/Project-Page-blue?style=for-the-badge&logo=googlechrome&logoColor=white)](https://zrealli.github.io/TIGIC/) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/zrealli/TIGIC)

* **[ECCV 2024]** ***MasterWeaver:*** *TamingÂ EditabilityÂ andÂ FaceÂ IdentityÂ forÂ PersonalizedÂ Textâ€‘toâ€‘ImageÂ Generation*<br>
  [![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://www.ecva.net/papers/eccv_2024/papers_ECCV/papers/06786.pdf) [![Project Page](https://img.shields.io/badge/Project-Page-blue?style=for-the-badge&logo=googlechrome&logoColor=white)](https://masterweaver.github.io/) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/csyxwei/MasterWeaver)

* **[NeurIPS 2024]** ***RectifID:*** *PersonalizingÂ RectifiedÂ FlowÂ withÂ AnchoredÂ ClassifierÂ Guidance*<br>
  [![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://proceedings.neurips.cc/paper_files/paper/2024/file/afa58a5b6adc0845e0fd632132a64c39-Paper-Conference.pdf) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/feifeiobama/RectifID)

* **[NeurIPS 2024]** ***AttnDreamBooth:*** *TowardsÂ Textâ€‘AlignedÂ PersonalizedÂ ImageÂ Generation*<br>
  [![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://proceedings.neurips.cc/paper_files/paper/2024/file/465a13a95741fab2e912f98adb07df1d-Paper-Conference.pdf) [![Project Page](https://img.shields.io/badge/Project-Page-blue?style=for-the-badge&logo=googlechrome&logoColor=white)](https://attndreambooth.github.io/) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/lyuPang/AttnDreamBooth)

* **[AAAI 2024]** ***DecoupledÂ TextualÂ Embeddings:*** *forÂ CustomizedÂ ImageÂ Generation*<br>
  [![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2312.11826.pdf)


</details>

<details>
<summary><h4>ğŸ’¡ Pre-Print Papers</h4></summary>

- [HyperNet Fields: Efficiently Training Hypernetworks without Ground Truth by Learning Weight Trajectories](http://arxiv.org/abs/2412.17040v2)
- [PersonaMagic: Stage-Regulated High-Fidelity Face Customization with Tandem Equilibrium](http://arxiv.org/abs/2412.15674v1) [![GitHub Stars](https://img.shields.io/github/stars/xzhe-Vision/PersonaMagic?style=social)](https://github.com/xzhe-Vision/PersonaMagic)
- [LoRACLR: Contrastive Adaptation for Customization of Diffusion Models](http://arxiv.org/abs/2412.09622v1)  [![Project Page](https://img.shields.io/badge/Project-Page-blue?logo=website)](https://loraclr.github.io)
- [Learning Flow Fields in Attention for Controllable Person Image Generation](http://arxiv.org/abs/2412.08486v2) [![GitHub Stars](https://img.shields.io/github/stars/franciszzj/Leffa?style=social)](https://github.com/franciszzj/Leffa) [![Hugging-Face](https://img.shields.io/badge/Hugging-Face-orange?logo=website)](https://huggingface.co/spaces/franciszzj/Leffa)
- [PatchDPO: Patch-level DPO for Finetuning-free Personalized Image Generation](http://arxiv.org/abs/2412.03177v2) [![GitHub Stars](https://img.shields.io/github/stars/hqhQAQ/PatchDPO?style=social)](https://github.com/hqhQAQ/PatchDPO) [![Hugging-Face](https://img.shields.io/badge/Hugging-Face-orange?logo=website)](https://huggingface.co/hqhQAQ/PatchDPO)
- [SerialGen: Personalized Image Generation by First Standardization Then Personalization](http://arxiv.org/abs/2412.01485v2)  [![Project Page](https://img.shields.io/badge/Project-Page-blue?logo=website)](https://serialgen.github.io)
- [Refine-by-Align: Reference-Guided Artifacts Refinement through Semantic Alignment](http://arxiv.org/abs/2412.00306v1)  [![Project Page](https://img.shields.io/badge/Project-Page-blue?logo=website)](https://song630.github.io/Refine-by-Align-Project-Page/)
- [DreamBlend: Advancing Personalized Fine-tuning of Text-to-Image Diffusion Models](http://arxiv.org/abs/2411.19390v1)
- [DreamCache: Finetuning-Free Lightweight Personalized Image Generation via Feature Caching](http://arxiv.org/abs/2411.17786v1) [![GitHub Stars](https://img.shields.io/github/stars/Emanuele97x/DreamCache?style=social)](https://github.com/Emanuele97x/DreamCache) [![Project Page](https://img.shields.io/badge/Project-Page-blue?logo=website)](https://emanuele97x.github.io/DreamCache)
- [Personalized Image Generation with Large Multimodal Models](http://arxiv.org/abs/2410.14170v2) [![GitHub Stars](https://img.shields.io/github/stars/YiyanXu/Pigeon?style=social)](https://github.com/YiyanXu/Pigeon)
- [FaceChain-FACT: Face Adapter with Decoupled Training for Identity-preserved Personalization](http://arxiv.org/abs/2410.12312v2) [![GitHub Stars](https://img.shields.io/github/stars/modelscope/facechain?style=social)](https://github.com/modelscope/facechain) [![Project Page](https://img.shields.io/badge/Project-Page-blue?logo=website)](https://facechain-fact.github.io) [![Hugging-Face](https://img.shields.io/badge/Hugging-Face-orange?logo=website)](https://huggingface.co/spaces/modelscope/FaceChain-FACT)
- [Resolving Multi-Condition Confusion for Finetuning-Free Personalized Image Generation (MIP-Adapter)](http://arxiv.org/abs/2409.17920v2) [![GitHub Stars](https://img.shields.io/github/stars/hqhQAQ/MIP-Adapter?style=social)](https://github.com/hqhQAQ/MIP-Adapter) [![Hugging-Face](https://img.shields.io/badge/Hugging-Face-orange?logo=website)](https://huggingface.co/hqhQAQ/MIP-Adapter)
- [Imagine Yourself: Tuning-Free Personalized Image Generation](http://arxiv.org/abs/2409.13346v1)
- [StoryMaker: Towards Holistic Consistent Characters in Text-to-Image Generation](http://arxiv.org/abs/2409.12576v1) [![GitHub Stars](https://img.shields.io/github/stars/RedAIGC/StoryMaker?style=social)](https://github.com/RedAIGC/StoryMaker) [![Hugging-Face](https://img.shields.io/badge/Hugging-Face-orange?logo=website)](https://huggingface.co/RED-AIGC/StoryMaker)
- [TextBoost: Towards One-Shot Personalization of Text-to-Image Models via Fine-tuning Text Encoder](http://arxiv.org/abs/2409.08248v1) [![GitHub Stars](https://img.shields.io/github/stars/nahyeonkaty/textboost?style=social)](https://github.com/nahyeonkaty/textboost) [![Project Page](https://img.shields.io/badge/Project-Page-blue?logo=website)](https://textboost.github.io)
- [EZIGen: Enhancing Zero-shot Personalized Image Generation with Precise Subject Encoding and Decoupled Guidance](http://arxiv.org/abs/2409.08091v4) [![GitHub Stars](https://img.shields.io/github/stars/ZichengDuan/EZIGen?style=social)](https://github.com/ZichengDuan/EZIGen) [![Project Page](https://img.shields.io/badge/Project-Page-blue?logo=website)](https://zichengduan.github.io/pages/EZIGen/)
- [ViPer: Visual Personalization of Generative Models via Individual Preference Learning](http://arxiv.org/abs/2407.17365v1) [![GitHub Stars](https://img.shields.io/github/stars/EPFL-VILAB/ViPer?style=social)](https://github.com/EPFL-VILAB/ViPer)
- [Layout-and-Retouch: A Dual-stage Framework for Improving Diversity in Personalized Image Generation](http://arxiv.org/abs/2407.09779v1)
- [DreamBench++: A Human-Aligned Benchmark for Personalized Image Generation](http://arxiv.org/abs/2406.16855v2)  [![Project Page](https://img.shields.io/badge/Project-Page-blue?logo=website)](https://dreambenchplus.github.io)
- [RectifID: Personalizing Rectified Flow with Anchored Classifier Guidance](http://arxiv.org/abs/2405.14677v4) [![GitHub Stars](https://img.shields.io/github/stars/feifeiobama/RectifID?style=social)](https://github.com/feifeiobama/RectifID)
- [FreeTuner: Any Subject in Any Style with Training-free Diffusion](http://arxiv.org/abs/2405.14201v2)
- [InstantFamily: Masked Attention for Zero-shot Multi-ID Image Generation](http://arxiv.org/abs/2404.19427v1)
- [MoA: Mixture-of-Attention for Subject-Context Disentanglement in Personalized Image Generation](http://arxiv.org/abs/2404.11565v2)  [![Project Page](https://img.shields.io/badge/Project-Page-blue?logo=website)](https://snap-research.github.io/mixture-of-attention)
- [CAT: Contrastive Adapter Training for Personalized Image Generation](http://arxiv.org/abs/2404.07554v2)
- [MoMA: Multimodal LLM Adapter for Fast Personalized Image Generation](http://arxiv.org/abs/2404.05674v1) [![GitHub Stars](https://img.shields.io/github/stars/bytedance/MoMA?style=social)](https://github.com/bytedance/MoMA) [![Project Page](https://img.shields.io/badge/Project-Page-blue?logo=website)](https://moma-adapter.github.io) [![Hugging-Face](https://img.shields.io/badge/Hugging-Face-orange?logo=website)](https://huggingface.co/KunpengSong/MoMA_llava_7b)
- [MM-Diff: High-Fidelity Image Personalization via Multi-Modal Condition Integration](http://arxiv.org/abs/2403.15059v1) [![GitHub Stars](https://img.shields.io/github/stars/alibaba/mm-diff?style=social)](https://github.com/alibaba/mm-diff) [![Project Page](https://img.shields.io-badge/Project-Page-blue?logo=website)](https://mm-diff.github.io)
- [IDAdapter: Learning Mixed Features for Tuning-Free Personalization of Text-to-Image Models](http://arxiv.org/abs/2403.13535v2)
- [Fast Personalized Text-to-Image Syntheses With Attention Injection](http://arxiv.org/abs/2403.11284v1)
- [Gen4Gen: Generative Data Pipeline for Generative Multi-Concept Composition](http://arxiv.org/abs/2402.15504v1) [![GitHub Stars](https://img.shields.io/github/stars/louisYen/Gen4Gen?style=social)](https://github.com/louisYen/Gen4Gen) [![Project Page](https://img.shields.io/badge/Project-Page-blue?logo=website)](https://danielchyeh.github.io/Gen4Gen)
- [Beyond Inserting: Learning Identity Embedding for Semantic-Fidelity Personalized Diffusion Generation (SeFi-IDE)](http://arxiv.org/abs/2402.00631v2)  [![Project Page](https://img.shields.io/badge/Project-Page-blue?logo=website)](https://com-vis.github.io/SeFi-IDE)
- [BootPIG: Bootstrapping Zero-shot Personalized Image Generation Capabilities in Pretrained Diffusion Models](http://arxiv.org/abs/2401.13974v1)


</details>

</details>

<details>
<summary><h4>âœ¨ 2023</h4></summary>

<details>
<summary><h4>âœ… Published Papers</h4></summary>

* **[CVPR 2023]** ***Custom Diffusion:*** *Multi-Concept Customization of Text-to-Image Diffusion*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://openaccess.thecvf.com/content/CVPR2023/papers/Kumari_Multi-Concept_Customization_of_Text-to-Image_Diffusion_CVPR_2023_paper.pdf) [![Project Page](https://img.shields.io/badge/Project-Page-blue?style=for-the-badge&logo=googlechrome&logoColor=white)](https://www.cs.cmu.edu/~custom-diffusion/) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/adobe-research/custom-diffusion) [![Hugging Face](https://img.shields.io/badge/%F0%9F%A4%97-Hugging_Face-yellow?style=for-the-badge)](https://huggingface.co/custom-diffusion-library/cat)

* **[CVPR 2023]** ***DreamBooth:*** *Fine Tuning Text-to-Image Diffusion Models for Subject-Driven Generation*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://openaccess.thecvf.com/content/CVPR2023/papers/Ruiz_DreamBooth_Fine_Tuning_Text-to-Image_Diffusion_Models_for_Subject-Driven_Generation_CVPR_2023_paper.pdf) [![Project Page](https://img.shields.io/badge/Project-Page-blue?style=for-the-badge&logo=googlechrome&logoColor=white)](https://dreambooth.github.io/) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/google/dreambooth) [![Hugging Face](https://img.shields.io/badge/%F0%9F%A4%97-Hugging_Face-yellow?style=for-the-badge)](https://huggingface.co/BAAI/DreamBooth-AltDiffusion)

* **[ICCV 2023]** ***ELITE:*** *Encoding Visual Concepts into Textual Embeddings for Customized Text-to-Image Generation*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://openaccess.thecvf.com/content/ICCV2023/papers/Wei_ELITE_Encoding_Visual_Concepts_into_Textual_Embeddings_for_Customized_Text-to-Image_ICCV_2023_paper.pdf) [![Project Page](https://img.shields.io/badge/Project-Page-blue?style=for-the-badge&logo=googlechrome&logoColor=white)](https://github.com/csyxwei/ELITE) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/csyxwei/ELITE) [![Hugging Face](https://img.shields.io/badge/%F0%9F%A4%97-Hugging_Face-yellow?style=for-the-badge)](https://huggingface.co/ELITE-library/ELITE)

* **[ICLR 2023]** ***Textual Inversion:*** *An Image is Worth One Word: Personalizing Text-to-Image Generation using Textual Inversion*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://openreview.net/pdf?id=NAQvF08TcyG) [![Project Page](https://img.shields.io/badge/Project-Page-blue?style=for-the-badge&logo=googlechrome&logoColor=white)](https://textual-inversion.github.io/) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/rinongal/textual_inversion) [![Hugging Face](https://img.shields.io/badge/%F0%9F%A4%97-Hugging_Face-yellow?style=for-the-badge)](https://huggingface.co/Clyuue/textual_inversion_cat)

* **[SIGGRAPH Asia 2023]** ***Break-A-Scene:*** *Extracting Multiple Concepts from a Single Image*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2305.16311.pdf) [![Project Page](https://img.shields.io/badge/Project-Page-blue?style=for-the-badge&logo=googlechrome&logoColor=white)](https://omriavrahami.com/break-a-scene) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/google/break-a-scene)

* **[SIGGRAPH 2023]** ***Encoderâ€‘Based Domain Tuning:*** *Encoderâ€‘Based Domain Tuning for Fast Personalization of Textâ€‘toâ€‘Image Models*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2302.12228.pdf) [![Project Page](https://img.shields.io/badge/Project-Page-blue?style=for-the-badge&logo=googlechrome&logoColor=white)](https://tuning-encoder.github.io/) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/mkshing/e4t-diffusion)

* **[SIGGRAPH 2023]** ***LayerDiffusion:*** *Layered Controlled Image Editing with Diffusion Models*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://dl.acm.org/doi/pdf/10.1145/3610543.3626172) [![Project Page](https://img.shields.io/badge/Project-Page-blue?style=for-the-badge&logo=googlechrome&logoColor=white)](https://zrealli.github.io/layerdiffusion/index.html) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/lllyasviel/LayerDiffuse) [![Hugging Face](https://img.shields.io/badge/%F0%9F%A4%97-Hugging_Face-yellow?style=for-the-badge)](https://huggingface.co/LayerDiffusion/layerdiffusion-v1)


</details>

<details>
<summary><h4>ğŸ’¡ Pre-Print Papers</h4></summary>

- [PortraitBooth: A Versatile Portrait Model for Fast Identity-preserved Personalization](http://arxiv.org/abs/2312.06354v1)   [![Project Page](https://img.shields.io/badge/Project-Page-blue?logo=website)](https://portraitbooth.github.io/)
- [Disentangled Representation Learning for Controllable Person Image Generation](http://arxiv.org/abs/2312.05798v1)
- [HiFi Tuner: High-Fidelity Subject-Driven Fine-Tuning for Diffusion Models](http://arxiv.org/abs/2312.00079v1)
- [When StyleGAN Meets Stable Diffusion: a \\mathscr{W}\_+ Adapter for Personalized Image Generation](http://arxiv.org/abs/2311.17461v1) [![GitHub Stars](https://img.shields.io/github/stars/csxmli2016/w-plus-adapter?style=social)](https://github.com/csxmli2016/w-plus-adapter)
- [CatVersion: Concatenating Embeddings for Diffusion-Based Text-to-Image Personalization](http://arxiv.org/abs/2311.14631v2) [![GitHub Stars](https://img.shields.io/github/stars/RoyZhao926/CatVersion?style=social)](https://github.com/RoyZhao926/CatVersion)   [![Project Page](https://img.shields.io/badge/Project-Page-blue?logo=website)](https://royzhao926.github.io/CatVersion-page/)
- [FaceChain: A Playground for Human-centric Artificial Intelligence Generated Content](http://arxiv.org/abs/2308.14256v2) [![GitHub Stars](https://img.shields.io/github/stars/modelscope/facechain?style=social)](https://github.com/modelscope/facechain)   [![Project Page](https://img.shields.io/badge/Project-Page-blue?logo=website)](https://facechain-fact.github.io/) [![HuggingFace Face](https://img.shields.io/badge/Hugging-Face-orange?logo=website)](https://huggingface.co/spaces/modelscope/FaceChain)
- [Subject-Diffusion: Open Domain Personalized Text-to-Image Generation without Test-time Fine-tuning](http://arxiv.org/abs/2307.11410v2) [![GitHub Stars](https://img.shields.io/github/stars/OPPO-Mente-Lab/Subject-Diffusion?style=social)](https://github.com/OPPO-Mente-Lab/Subject-Diffusion)   [![Project Page](https://img.shields.io/badge/Project-Page-blue?logo=website)](https://oppo-mente-lab.github.io/subject_diffusion/)
- [FastComposer: Tuning-Free Multi-Subject Image Generation with Localized Attention](http://arxiv.org/abs/2305.10431v2) [![GitHub Stars](https://img.shields.io/github/stars/mit-han-lab/fastcomposer?style=social)](https://github.com/mit-han-lab/fastcomposer) [![HuggingFace Face](https://img.shields.io/badge/Hugging-Face-orange?logo=website)](https://huggingface.co/mit-han-lab/fastcomposer)
- [UPGPT: Universal Diffusion Model for Person Image Generation, Editing and Pose Transfer](http://arxiv.org/abs/2304.08870v2) [![GitHub Stars](https://img.shields.io/github/stars/soon-yau/upgpt?style=social)](https://github.com/soon-yau/upgpt) [![HuggingFace Face](https://img.shields.io/badge/Hugging-Face-orange?logo=website)](https://huggingface.co/soonyau/upgpt)
- [Identity Encoder for Personalized Diffusion](http://arxiv.org/abs/2304.07429v1)
- [InstantBooth: Personalized Text-to-Image Generation without Test-Time Finetuning](http://arxiv.org/abs/2304.03411v1)   [![Project Page](https://img.shields.io/badge/Project-Page-blue?logo=website)](https://jshi31.github.io/InstantBooth/)
- [Semantically Consistent Person Image Generation](http://arxiv.org/abs/2302.14728v2)
- [Learning Invariance from Generated Variance for Unsupervised Person Re-identification](http://arxiv.org/abs/2301.00725v1) [![GitHub Stars](https://img.shields.io/github/stars/chenhao2345/GCL-extended?style=social)](https://github.com/chenhao2345/GCL-extended)


</details>

</details>

[<small>â‡§ Back to ToC</small>](#contents)

### <span id="editing">âœ‚ï¸ Image Editing</span>

<details>
<summary><h4>âœ¨ 2025</h4></summary>

<details>
<summary><h4>âœ… Published Papers</h4></summary>

* **[CVPRÂ 2025]** ***FDS:*** *Frequencyâ€‘AwareÂ DenoisingÂ ScoreÂ forÂ Textâ€‘GuidedÂ LatentÂ DiffusionÂ ImageÂ Editing*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2503.19191)Â [![ProjectÂ Page](https://img.shields.io/badge/Project-Page-blue?style=for-the-badge&logo=googlechrome&logoColor=white)](https://ivrl.github.io/fds-webpage/)Â [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/IVRL/FDS)


* **[CVPRÂ 2025]** *Referenceâ€‘BasedÂ 3Dâ€‘AwareÂ ImageÂ EditingÂ withÂ Triplanes*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2404.03632)Â [![ProjectÂ Page](https://img.shields.io/badge/Project-Page-blue?style=for-the-badge&logo=googlechrome&logoColor=white)](https://three-bee.github.io/triplane_edit/)Â [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/three-bee/triplane_edit)


* **[CVPRÂ 2025]** ***MoEdit:*** *OnÂ LearningÂ QuantityÂ PerceptionÂ forÂ Multiâ€‘objectÂ ImageÂ Editing*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2503.10112)


* **[ICLRÂ 2025]** *Lightningâ€‘FastÂ ImageÂ InversionÂ andÂ EditingÂ forÂ Textâ€‘toâ€‘ImageÂ DiffusionÂ Models*<br>
[![Paper](https://img.shields.io/badge/Paper-OpenReview-D15E5E?style=for-the-badge&logo=open-collective)](https://openreview.net/forum?id=t9l63huPRt)Â [![ProjectÂ Page](https://img.shields.io/badge/Project-Page-blue?style=for-the-badge&logo=googlechrome&logoColor=white)](https://barakmam.github.io/rnri.github.io/)Â [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/dvirsamuel/NewtonRaphsonInversion)


* **[ICLRÂ 2025]** *Multiâ€‘RewardÂ asÂ ConditionÂ forÂ Instructionâ€‘basedÂ ImageÂ Editing*<br>
[![Paper](https://img.shields.io/badge/Paper-OpenReview-D15E5E?style=for-the-badge&logo=open-collective)](https://openreview.net/forum?id=9RFocgIccP)Â [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/bytedance/Multi-Reward-Editing)


* **[ICLRÂ 2025]** ***HQâ€‘Edit:*** *AÂ Highâ€‘QualityÂ DatasetÂ forÂ Instructionâ€‘basedÂ ImageÂ Editing*<br>
[![Paper](https://img.shields.io/badge/Paper-OpenReview-D15E5E?style=for-the-badge&logo=open-collective)](https://openreview.net/forum?id=mZptYYttFj)Â [![ProjectÂ Page](https://img.shields.io/badge/Project-Page-blue?style=for-the-badge&logo=googlechrome&logoColor=white)](https://thefllood.github.io/HQEdit_web/)Â [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/UCSC-VLAA/HQ-Edit)Â [![HuggingÂ Face](https://img.shields.io/badge/%F0%9F%A4%97-Hugging_Face-yellow?style=for-the-badge)](https://huggingface.co/datasets/UCSC-VLAA/HQ-Edit)


* **[ICLRÂ 2025]** ***CLIPDrag:*** *CombiningÂ Textâ€‘basedÂ andÂ Dragâ€‘basedÂ InstructionsÂ forÂ ImageÂ Editing*<br>
[![Paper](https://img.shields.io/badge/Paper-OpenReview-D15E5E?style=for-the-badge&logo=open-collective)](https://openreview.net/forum?id=2HjRezQ1nj)Â [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/HKUST-LongGroup/CLIPDrag)


* **[ICLRÂ 2025]** *SemanticÂ ImageÂ InversionÂ andÂ EditingÂ usingÂ RectifiedÂ StochasticÂ DifferentialÂ Equations*<br>
[![Paper](https://img.shields.io/badge/Paper-OpenReview-D15E5E?style=for-the-badge&logo=open-collective)](https://openreview.net/forum?id=Hu0FSOSEyS)Â [![ProjectÂ Page](https://img.shields.io/badge/Project-Page-blue?style=for-the-badge&logo=googlechrome&logoColor=white)](https://rf-inversion.github.io/)Â [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/LituRout/RF-Inversion)


* **[ICLRÂ 2025]** ***PostEdit:*** *PosteriorÂ SamplingÂ forÂ EfficientÂ Zeroâ€‘ShotÂ ImageÂ Editing*<br>
[![Paper](https://img.shields.io/badge/Paper-OpenReview-D15E5E?style=for-the-badge&logo=open-collective)](https://openreview.net/forum?id=J8YWCBPgx7) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/TFNTF/PostEdit)


* **[ICLRÂ 2025]** ***OmniEdit:*** *BuildingÂ ImageÂ EditingÂ GeneralistÂ ModelsÂ ThroughÂ SpecialistÂ Supervision*<br>
[![Paper](https://img.shields.io/badge/Paper-OpenReview-D15E5E?style=for-the-badge&logo=open-collective)](https://openreview.net/forum?id=Hlm0cga0sv)Â [![ProjectÂ Page](https://img.shields.io/badge/Project-Page-blue?style=for-the-badge&logo=googlechrome&logoColor=white)](https://tiger-ai-lab.github.io/OmniEdit/)Â [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/TIGER-AI-Lab/OmniEdit)Â [![HuggingÂ Face](https://img.shields.io/badge/%F0%9F%A4%97-Hugging_Face-yellow?style=for-the-badge)](https://huggingface.co/datasets/TIGER-Lab/OmniEdit-Filtered-1.2M)


</details>

<details>
<summary><h4>ğŸ’¡ Pre-Print Papers</h4></summary>

- [Inpaint4Drag: Repurposing Inpainting Models for Drag-Based Image Editing via Bidirectional Warping](http://arxiv.org/abs/2509.04582v1) [![GitHub Stars](https://img.shields.io/github/stars/Visual-AI/Inpaint4Drag?style=social)](https://github.com/Visual-AI/Inpaint4Drag) [![Project Page](https://img.shields.io/badge/Project-Page-blue?logo=website)](https://visual-ai.github.io/inpaint4drag/)
- [From Editor to Dense Geometry Estimator](http://arxiv.org/abs/2509.04338v1) [![GitHub Stars](https://img.shields.io/github/stars/AMAP-ML/FE2E?style=social)](https://github.com/AMAP-ML/FE2E) [![Project Page](https://img.shields.io/badge/Project-Page-blue?logo=website)](https://amap-ml.github.io/FE2E/)
- [Improved 3D Scene Stylization via Text-Guided Generative Image Editing with Region-Based Control](http://arxiv.org/abs/2509.05285v1)
- [Fidelity-preserving enhancement of ptychography with foundational text-to-image models](http://arxiv.org/abs/2509.04513v1)
- [Draw-In-Mind: Learning Precise Image Editing via Chain-of-Thought Imagination](http://arxiv.org/abs/2509.01986v1) [![GitHub Stars](https://img.shields.io/github/stars/showlab/DIM?style=social)](https://github.com/showlab/DIM)
- [Discrete Noise Inversion for Next-scale Autoregressive Text-based Image Editing](http://arxiv.org/abs/2509.01984v2)
- [Delta Velocity Rectified Flow for Text-to-Image Editing](http://arxiv.org/abs/2509.05342v1)
- [Neural Scene Designer: Self-Styled Semantic Image Manipulation](http://arxiv.org/abs/2509.01405v1)
- [LatentEdit: Adaptive Latent Control for Consistent Semantic Editing](http://arxiv.org/abs/2509.00541v1)
- [Webly-Supervised Image Manipulation Localization via Category-Aware Auto-Annotation](http://arxiv.org/abs/2508.20987v1)
- [Describe, Don't Dictate: Semantic Image Editing with Natural Language Intent](http://arxiv.org/abs/2508.20505v1)
- [Not Every Gift Comes in Gold Paper or with a Red Ribbon: Exploring Color Perception in Text-to-Image Models](http://arxiv.org/abs/2508.19791v1)
- [SpotEdit: Evaluating Visually-Guided Image Editing Methods](http://arxiv.org/abs/2508.18159v1)
- [An LLM-LVLM Driven Agent for Iterative and Fine-Grained Image Editing](http://arxiv.org/abs/2508.17435v1)
- [Defending Deepfake via Texture Feature Perturbation](http://arxiv.org/abs/2508.17315v1)
- [PosBridge: Multi-View Positional Embedding Transplant for Identity-Aware Image Editing](http://arxiv.org/abs/2508.17302v1)
- [Visual Autoregressive Modeling for Instruction-Guided Image Editing](http://arxiv.org/abs/2508.15772v1)
- [Sketch3DVE: Sketch-based 3D-Aware Scene Video Editing](http://arxiv.org/abs/2508.13797v1)
- [Single-Reference Text-to-Image Manipulation with Dual Contrastive Denoising Score](http://arxiv.org/abs/2508.12718v1)
- [PEdger++: Practical Edge Detection via Assembling Cross Information](http://arxiv.org/abs/2508.11961v1)
- [TimeMachine: Fine-Grained Facial Age Editing with Identity Preservation](http://arxiv.org/abs/2508.11284v2)
- [NextStep-1: Toward Autoregressive Image Generation with Continuous Tokens at Scale](http://arxiv.org/abs/2508.10711v2)
- [A Segmentation-driven Editing Method for Bolt Defect Augmentation and Detection](http://arxiv.org/abs/2508.10509v1)
- [TweezeEdit: Consistent and Efficient Image Editing with Path Regularization](http://arxiv.org/abs/2508.10498v1)
- [Follow-Your-Shape: Shape-Aware Image Editing via Trajectory-Guided Region Control](http://arxiv.org/abs/2508.08134v2) [![GitHub Stars](https://img.shields.io/github/stars/mayuelala/FollowYourShape?style=social)](https://github.com/mayuelala/FollowYourShape) [![Project Page](https://img.shields.io/badge/Project-Page-blue?logo=website)](https://follow-your-shape.github.io/)
- [Omni-Effects: Unified and Spatially-Controllable Visual Effects Generation](http://arxiv.org/abs/2508.07981v2)
- [X2Edit: Revisiting Arbitrary-Instruction Image Editing through Self-Constructed Data and Task-Aware Representation Learning](http://arxiv.org/abs/2508.07607v1)
- [Exploring Multimodal Diffusion Transformers for Enhanced Prompt-based Image Editing](http://arxiv.org/abs/2508.07519v1)
- [CLUE: Leveraging Low-Rank Adaptation to Capture Latent Uncovered Evidence for Image Forgery Localization](http://arxiv.org/abs/2508.07413v1)
- [CannyEdit: Selective Canny Control and Dual-Prompt Guidance for Training-Free Image Editing](http://arxiv.org/abs/2508.06937v1) [![GitHub Stars](https://img.shields.io/github/stars/vaynexie/CannyEdit?style=social)](https://github.com/vaynexie/CannyEdit) [![Project Page](https://img.shields.io/badge/Project-Page-blue?logo=website)](https://vaynexie.github.io/CannyEdit/)
- [Talk2Image: A Multi-Agent System for Multi-Turn Image Generation and Editing](http://arxiv.org/abs/2508.06916v1)
- [UGD-IML: A Unified Generative Diffusion-based Framework for Constrained and Unconstrained Image Manipulation Localization](http://arxiv.org/abs/2508.06101v1)
- [DreamVE: Unified Instruction-based Image and Video Editing](http://arxiv.org/abs/2508.06080v1)
- [NEP: Autoregressive Image Editing via Next Editing Token Prediction](http://arxiv.org/abs/2508.06044v1)
- [InstantEdit: Text-Guided Few-Step Image Editing with Piecewise Rectified Flow](http://arxiv.org/abs/2508.06033v1)
- [Skywork UniPic: Unified Autoregressive Modeling for Visual Understanding and Generation](http://arxiv.org/abs/2508.03320v1)
- [Zero Shot Domain Adaptive Semantic Segmentation by Synthetic Data Generation and Progressive Adaptation](http://arxiv.org/abs/2508.03300v1)
- [LORE: Latent Optimization for Precise Semantic Control in Rectified Flow-based Image Editing](http://arxiv.org/abs/2508.03144v2) [![GitHub Stars](https://img.shields.io/github/stars/oyly16/LORE?style=social)](https://github.com/oyly16/LORE)
- [UniEdit-I: Training-free Image Editing for Unified VLM via Iterative Understanding, Editing and Verifying](http://arxiv.org/abs/2508.03142v1)
- [Transport-Guided Rectified Flow Inversion: Improved Image Editing Using Optimal Transport Theory](http://arxiv.org/abs/2508.02363v1)
- [Qwen-Image Technical Report](http://arxiv.org/abs/2508.02324v1)
- [The Promise of RL for Autoregressive Image Editing](http://arxiv.org/abs/2508.01119v2)
- [Towards Robust Semantic Correspondence: A Benchmark and Insights](http://arxiv.org/abs/2508.00272v1)
- [Training-free Geometric Image Editing on Diffusion Models](http://arxiv.org/abs/2507.23300v2) [![GitHub Stars](https://img.shields.io/github/stars/CIawevy/FreeFine?style=social)](https://github.com/CIawevy/FreeFine)
- [UniLiP: Adapting CLIP for Unified Multimodal Understanding, Generation and Editing](http://arxiv.org/abs/2507.23278v1)
- [GPT-IMAGE-EDIT-1.5M: A Million-Scale, GPT-Generated Image Dataset](http://arxiv.org/abs/2507.21033v1) [![GitHub Stars](https://img.shields.io/github/stars/wyhlovecpp/GPT-Image-Edit?style=social)](https://github.com/wyhlovecpp/GPT-Image-Edit)   [![Project Page](https://img.shields.io/badge/Project-Page-blue?logo=website)](https://ucsc-vlaa.github.io/GPT-Image-Edit/) [![Huggingface Face](https://img.shields.io/badge/Hugging-Face-orange?logo=website)](https://huggingface.co/datasets/UCSC-VLAA/GPT-Image-Edit-1.5M)
- [Lumina-mGPT 2.0: Stand-Alone AutoRegressive Image Modeling](http://arxiv.org/abs/2507.17801v1) [![GitHub Stars](https://img.shields.io/github/stars/Alpha-VLLM/Lumina-mGPT-2.0?style=social)](https://github.com/Alpha-VLLM/Lumina-mGPT-2.0) [![Huggingface Face](https://img.shields.io/badge/Hugging-Face-orange?logo=website)](https://huggingface.co/Alpha-VLLM/Lumina-mGPT-2.0)
- [ADCD-Net: Robust Document Image Forgery Localization via Adaptive DCT Feature and Hierarchical Content Disentanglement](http://arxiv.org/abs/2507.16397v1) [![GitHub Stars](https://img.shields.io/github/stars/KAHIMWONG/ADCD-Net?style=social)](https://github.com/KAHIMWONG/ADCD-Net)
- [Scale Your Instructions: Enhance the Instruction-Following Fidelity of Unified Image Generation Model by Self-Adaptive Attention Scaling](http://arxiv.org/abs/2507.16240v1) [![GitHub Stars](https://img.shields.io/github/stars/zhouchao-ops/SaaS?style=social)](https://github.com/zhouchao-ops/SaaS) 
- [LMM4Edit: Benchmarking and Evaluating Multimodal Image Editing with LMMs](http://arxiv.org/abs/2507.16193v2) [![GitHub Stars](https://img.shields.io/github/stars/IntMeGroup/LMM4Edit?style=social)](https://github.com/IntMeGroup/LMM4Edit) 
- [Light Future: Multimodal Action Frame Prediction via InstructPix2Pix](http://arxiv.org/abs/2507.14809v1)
- [NoHumansRequired: Autonomous High-Quality Image Editing Triplet Mining](http://arxiv.org/abs/2507.14119v1) [![GitHub Stars](https://img.shields.io/github/stars/ai-forever/NoHumansRequired?style=social)](https://github.com/ai-forever/NoHumansRequired)   [![Project Page](https://img.shields.io/badge/Project-Page-blue?logo=website)](https://riko0.github.io/No-Humans-Required/) [![Huggingface Face](https://img.shields.io/badge/Hugging-Face-orange?logo=website)](https://huggingface.co/iitolstykh/NHR-Edit) 
- [Moodifier: MLLM-Enhanced Emotion-Driven Image Editing](http://arxiv.org/abs/2507.14024v1) [![Project Page](https://img.shields.io/badge/Project-Page-blue?logo=website)](https://moodify2024.github.io) [![Huggingface Face](https://img.shields.io/badge/Hugging-Face-orange?logo=website)](https://huggingface.co/moodify2024/moodifyCLIP) 
- [EditGen: Harnessing Cross-Attention Control for Instruction-Based Auto-Regressive Audio Editing](http://arxiv.org/abs/2507.11096v1) [![GitHub Stars](https://img.shields.io/github/stars/billsioros/EditGen?style=social)](https://github.com/billsioros/EditGen) 
- [Sparse Fine-Tuning of Transformers for Generative Tasks](http://arxiv.org/abs/2507.10855v1) [![GitHub Stars](https://img.shields.io/github/stars/liuting20/Sparse-Tuning?style=social)](https://github.com/liuting20/Sparse-Tuning)   [![Project Page](https://img.shields.io/badge/Project-Page-blue?logo=website)](https://weichennone.github.io/myhomepage/_projects/2025iccv/index.html) 
- [LayLens: Improving Deepfake Understanding through Simplified Explanations](http://arxiv.org/abs/2507.10066v2)
- [FlowDrag: 3D-aware Drag-based Image Editing with Mesh-guided Deformation Vector Flow Fields](http://arxiv.org/abs/2507.08285v1) [![GitHub Stars](https://img.shields.io/github/stars/kookie12/FlowDrag?style=social)](https://github.com/kookie12/FlowDrag)   [![Project Page](https://img.shields.io/badge/Project-Page-blue?logo=website)](https://kookie12.github.io/FlowDrag-Projecct-Page/)
- [ADIEE: Automatic Dataset Creation and Scorer for Instruction-Guided Image Editing Evaluation](http://arxiv.org/abs/2507.07317v2) [![GitHub Stars](https://img.shields.io/github/stars/SamsungLabs/ADIEE?style=social)](https://github.com/SamsungLabs/ADIEE) 
- [2D Instance Editing in 3D Space](http://arxiv.org/abs/2507.05819v1)
- [Neural-Driven Image Editing](http://arxiv.org/abs/2507.05397v2) [![GitHub Stars](https://img.shields.io/github/stars/LanceZPF/loongx?style=social)](https://github.com/LanceZPF/loongx)   [![Project Page](https://img.shields.io/badge/Project-Page-blue?logo=website)](https://loongx1.github.io/) 
- [Beyond Simple Edits: Xâ€‘Planner for Complex Instruction-Based Image Editing](http://arxiv.org/abs/2507.05259v1)   [![Project Page](https://img.shields.io/badge/Project-Page-blue?logo=website)](https://danielchyeh.github.io/x-planner/) 
- [S$^2$Edit: Text-Guided Image Editing with Precise Semantic and Spatial Control](http://arxiv.org/abs/2507.04584v1) [![GitHub Stars](https://img.shields.io/github/stars/JohnDreamer/DualCycleDiffusion?style=social)](https://github.com/JohnDreamer/DualCycleDiffusion) 
- [Pose-Star: Anatomy-Aware Editing for Open-World Fashion Images](http://arxiv.org/abs/2507.03402v1) [![GitHub Stars](https://img.shields.io/github/stars/NDYBSNDY/Pose-Star?style=social)](https://github.com/NDYBSNDY/Pose-Star) 
- [LACONIC: A 3D Layout Adapter for Controllable Image Creation](http://arxiv.org/abs/2507.03257v2)
- [Reasoning to Edit: Hypothetical Instruction-Based Image Editing with Visual Reasoning](http://arxiv.org/abs/2507.01908v1) [![GitHub Stars](https://img.shields.io/github/stars/hithqd/ReasonBrain?style=social)](https://github.com/hithqd/ReasonBrain) 
- [ReFlex: Text-Guided Editing of Real Images in Rectified Flow via Mid-Step Feature Extraction and Attention Adaptation](http://arxiv.org/abs/2507.01496v1) [![GitHub Stars](https://img.shields.io/github/stars/wlaud1001/ReFlex?style=social)](https://github.com/wlaud1001/ReFlex) 
- [QC-OT: Optimal Transport with Quasiconformal Mapping](http://arxiv.org/abs/2507.01456v1)
- [A Unified Framework for Stealthy Adversarial Generation via Latent Optimization and Transferability Enhancement](http://arxiv.org/abs/2506.23676v1)
- [TAG-WM: Tamper-Aware Generative Image Watermarking via Diffusion Inversion Sensitivity](http://arxiv.org/abs/2506.23484v2) [![GitHub Stars](https://img.shields.io/github/stars/Suchenl/TAG-WM?style=social)](https://github.com/Suchenl/TAG-WM)
- [OmniVCus: Feedforward Subject-driven Video Customization with Multimodal Control Conditions](http://arxiv.org/abs/2506.23361v1) [![GitHub Stars](https://img.shields.io/github/stars/caiyuanhao1998/Open-OmniVCus?style=social)](https://github.com/caiyuanhao1998/Open-OmniVCus)   [![Project Page](https://img.shields.io/badge/Project-Page-blue?logo=website)](https://caiyuanhao1998.github.io/project/OmniVCus) [![Huggingface Face](https://img.shields.io/badge/Hugging-Face-orange?logo=website)](https://huggingface.co/datasets/CaiYuanhao/OmniVCus)
- [Ovis-U1 Technical Report](http://arxiv.org/abs/2506.23044v2) [![GitHub Stars](https://img.shields.io/github/stars/AIDC-AI/Ovis?style=social)](https://github.com/AIDC-AI/Ovis)   [![Huggingface Face](https://img.shields.io/badge/Hugging-Face-orange?logo=website)](https://huggingface.co/AIDC-AI/Ovis-U1-3B) 
- [Towards Explainable Bilingual Multimodal Misinformation Detection and Localization](http://arxiv.org/abs/2506.22930v1) [![GitHub Stars](https://img.shields.io/github/stars/RaffeLegend/misinformation?style=social)](https://github.com/RaffeLegend/misinformation) 
- [GenEscape: Hierarchical Multi-Agent Generation of Escape Room Puzzles](http://arxiv.org/abs/2506.21839v2)
- [Controllable 3D Placement of Objects with Scene-Aware Diffusion Models](http://arxiv.org/abs/2506.21446v1)
- [Improving Diffusion-Based Image Editing Faithfulness via Guidance and Scheduling](http://arxiv.org/abs/2506.21045v1)
- [M2SFormer: Multi-Spectral and Multi-Scale Attention with Edge-Aware Difficulty Guidance for Image Forgery Localization](http://arxiv.org/abs/2506.20922v1)
- [FaSTA$^*$: Fast-Slow Toolpath Agent with Subroutine Mining for Efficient Multi-turn Image Editing](http://arxiv.org/abs/2506.20911v1) [![GitHub Stars](https://img.shields.io/github/stars/tianyi-lab/FaSTAR?style=social)](https://github.com/tianyi-lab/FaSTAR) [![Huggingface Face](https://img.shields.io/badge/Hugging-Face-orange?logo=website)](https://huggingface.co/datasets/advaitgupta/CoSTAR)
- [EditP23: 3D Editing via Propagation of Image Prompts to Multi-View](http://arxiv.org/abs/2506.20652v1) [![GitHub Stars](https://img.shields.io/github/stars/editp23/editp23?style=social)](https://github.com/editp23/editp23)   [![Project Page](https://img.shields.io/badge/Project-Page-blue?logo=website)](https://editp23.github.io) 
- [Towards Efficient Exemplar Based Image Editing with Multimodal VLMs](http://arxiv.org/abs/2506.20155v1)
- [SceneCrafter: Controllable Multi-View Driving Scene Editing](http://arxiv.org/abs/2506.19488v1)
- [Inverse-and-Edit: Effective and Fast Image Editing by Cycle Consistency Models](http://arxiv.org/abs/2506.19103v1)
- [OmniGen2: Exploration to Advanced Multimodal Generation](http://arxiv.org/abs/2506.18871v2)
- [CPAM: Context-Preserving Adaptive Manipulation for Zero-Shot Real Image Editing](http://arxiv.org/abs/2506.18438v1)
- [Instability in Diffusion ODEs: An Explanation for Inaccurate Image Reconstruction](http://arxiv.org/abs/2506.18290v1)
- [FOCUS: Unified Vision-Language Modeling for Interactive Editing Driven by Referential Segmentation](http://arxiv.org/abs/2506.16806v1)
- [Arch-Router: Aligning LLM Routing with Human Preferences](http://arxiv.org/abs/2506.16655v1)
- [VectorEdits: A Dataset and Benchmark for Instruction-Based Editing of Vector Graphics](http://arxiv.org/abs/2506.15903v1)
- [AttentionDrag: Exploiting Latent Correlation Knowledge in Pre-trained Diffusion Models for Image Editing](http://arxiv.org/abs/2506.13301v1)
- [Balancing Preservation and Modification: A Region and Semantic Aware Metric for Instruction-Based Image Editing](http://arxiv.org/abs/2506.13827v1)
- [ComplexBench-Edit: Benchmarking Complex Instruction-Driven Image Editing via Compositional Dependencies](http://arxiv.org/abs/2506.12830v1)
- [SphereDrag: Spherical Geometry-Aware Panoramic Image Editing](http://arxiv.org/abs/2506.11863v1)
- [VINCIE: Unlocking In-context Image Editing from Video](http://arxiv.org/abs/2506.10941v1)
- [Edit360: 2D Image Edits to 3D Assets from Any Angle](http://arxiv.org/abs/2506.10507v2)
- [EditInspector: A Benchmark for Evaluation of Text-Guided Image Edits](http://arxiv.org/abs/2506.09988v1)
- [ELBO-T2IAlign: A Generic ELBO-Based Method for Calibrating Pixel-level Text-Image Alignment in Diffusion Models](http://arxiv.org/abs/2506.09740v1)
- [Ming-Omni: A Unified Multimodal Model for Perception and Generation](http://arxiv.org/abs/2506.09344v1)
- [Fine-Grained Spatially Varying Material Selection in Images](http://arxiv.org/abs/2506.09023v2)
- [Do Concept Replacement Techniques Really Erase Unacceptable Concepts?](http://arxiv.org/abs/2506.08991v1)
- [RoboSwap: A GAN-driven Video Diffusion Framework For Unsupervised Robot Arm Swapping](http://arxiv.org/abs/2506.08632v1)
- [Highly Compressed Tokenizer Can Generate Without Training](http://arxiv.org/abs/2506.08257v1)
- [PairEdit: Learning Semantic Variations for Exemplar-based Image Editing](http://arxiv.org/abs/2506.07992v1)
- [Diffusion Counterfactual Generation with Semantic Abduction](http://arxiv.org/abs/2506.07883v1)
- [DragNeXt: Rethinking Drag-Based Image Editing](http://arxiv.org/abs/2506.07611v1)
- [Bootstrapping World Models from Dynamics Models in Multimodal Foundation Models](http://arxiv.org/abs/2506.06006v1)
- [FADE: Frequency-Aware Diffusion Model Factorization for Video Editing](http://arxiv.org/abs/2506.05934v1)
- [Towards Reliable Identification of Diffusion-based Image Manipulations](http://arxiv.org/abs/2506.05466v2)
- [SeedEdit 3.0: Fast and High-Quality Generative Image Editing](http://arxiv.org/abs/2506.05083v2)
- [Invisible Backdoor Triggers in Image Editing Model via Deep Watermarking](http://arxiv.org/abs/2506.04879v1)

</details>

</details>

<details>
<summary><h4>âœ¨ 2024</h4></summary>

<details>
<summary><h4>âœ… Published Papers</h4></summary>

* **[CVPRÂ 2024]** ***InfEdit:*** *Inversionâ€‘Free Image Editing with Natural Language*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2312.04965.pdf) [![Project Page](https://img.shields.io/badge/Project-Page-blue?style=for-the-badge&logo=googlechrome&logoColor=white)](https://sled-group.github.io/InfEdit/) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/sled-group/InfEdit)


* **[CVPRÂ 2024]** ***CrossSelfAttention:*** *Towards Understanding CrossÂ andÂ Selfâ€‘Attention inÂ StableÂ Diffusion for Textâ€‘Guided ImageÂ Editing*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2403.03431.pdf) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/alibaba/EasyNLP/tree/master/diffusion/FreePromptEditing)


* **[CVPRÂ 2024]** ***DAC:*** *DoublyÂ Abductive Counterfactual Inference for Textâ€‘based ImageÂ Editing*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2403.02981.pdf) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/xuesong39/DAC)


* **[CVPRÂ 2024]** ***FoI:*** *FocusÂ onÂ YourÂ Instruction:Â Fineâ€‘grained and Multiâ€‘instruction ImageÂ Editing by AttentionÂ Modulation*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2312.10113.pdf) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/guoqincode/Focus-on-Your-Instruction)


* **[CVPRÂ 2024]** ***CDS:*** *ContrastiveÂ DenoisingÂ Score for Textâ€‘guided Latent Diffusion ImageÂ Editing*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2311.18608.pdf) [![Project Page](https://img.shields.io/badge/Project-Page-blue?style=for-the-badge&logo=googlechrome&logoColor=white)](https://hyelinnam.github.io/CDS/)


* **[CVPRÂ 2024]** ***DragDiffusion:*** *Harnessing DiffusionÂ Models for Interactive Pointâ€‘based ImageÂ Editing*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2306.14435.pdf) [![Project Page](https://img.shields.io/badge/Project-Page-blue?style=for-the-badge&logo=googlechrome&logoColor=white)](https://yujun-shi.github.io/projects/dragdiffusion.html) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/Yujun-Shi/DragDiffusion)


* **[CVPRÂ 2024]** ***DiffEditor:*** *Boosting Accuracy and Flexibility on Diffusionâ€‘based ImageÂ Editing*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2402.02583.pdf) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/MC-E/DragonDiffusion)


* **[CVPRÂ 2024]** ***FreeDrag:*** *FeatureÂ Dragging for Reliable Pointâ€‘based ImageÂ Editing*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2307.04684.pdf) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/LPengYang/FreeDrag)


* **[CVPRÂ 2024]** ***LearnableÂ Regions:*** *Textâ€‘Driven ImageÂ Editing viaÂ LearnableÂ Regions*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2311.16432.pdf) [![Project Page](https://img.shields.io/badge/Project-Page-blue?style=for-the-badge&logo=googlechrome&logoColor=white)](https://yuanze-lin.me/LearnableRegions_page/) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/yuanze-lin/Learnable_Regions)


* **[CVPRÂ 2024]** ***LEDITS++:*** *Limitless ImageÂ Editing using Textâ€‘toâ€‘ImageÂ Models*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2311.16711.pdf) [![Project Page](https://img.shields.io/badge/Project-Page-blue?style=for-the-badge&logo=googlechrome&logoColor=white)](https://leditsplusplus-project.static.hf.space/index.html) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://huggingface.co/spaces/editing-images/leditsplusplus/tree/main) [![HuggingÂ Face](https://img.shields.io/badge/%F0%9F%A4%97-Hugging_Face-yellow?style=for-the-badge)](https://huggingface.co/spaces/editing-images/leditsplusplus)


* **[CVPRÂ 2024]** ***SmartEdit:*** *ExploringÂ Complex Instructionâ€‘based ImageÂ Editing with LargeÂ LanguageÂ Models*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2312.06739.pdf) [![Project Page](https://img.shields.io/badge/Project-Page-blue?style=for-the-badge&logo=googlechrome&logoColor=white)](https://yuzhou914.github.io/SmartEdit/) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/TencentARC/SmartEdit)


* **[CVPRÂ 2024]** ***EditÂ OneÂ forÂ All:*** *InteractiveÂ Batch ImageÂ Editing*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2401.10219.pdf) [![Project Page](https://img.shields.io/badge/Project-Page-blue?style=for-the-badge&logo=googlechrome&logoColor=white)](https://thaoshibe.github.io/edit-one-for-all/) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/thaoshibe/edit-one-for-all)


* **[CVPRÂ 2024]** ***DiffMorpher:*** *Unleashing the Capability of DiffusionÂ Models for ImageÂ Morphing*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2312.07409.pdf) [![Project Page](https://img.shields.io/badge/Project-Page-blue?style=for-the-badge&logo=googlechrome&logoColor=white)](https://kevin-thu.github.io/DiffMorpher_page/) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/Kevin-thu/DiffMorpher)


* **[CVPRÂ 2024]** ***TiNOâ€‘Edit:*** *Timestep and NoiseÂ Optimization for Robust Diffusionâ€‘Based ImageÂ Editing*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2404.11120.pdf) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/SherryXTChen/TiNO-Edit)


* **[CVPRÂ 2024]** ***PersonÂ inÂ Place:*** *Generating Associative Skeletonâ€‘Guidance Maps for Humanâ€‘ObjectÂ Interaction ImageÂ Editing*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://openaccess.thecvf.com/content/CVPR2024/papers/Yang_Person_in_Place_Generating_Associative_Skeleton-Guidance_Maps_for_Human-Object_Interaction_CVPR_2024_paper.pdf) [![Project Page](https://img.shields.io/badge/Project-Page-blue?style=for-the-badge&logo=googlechrome&logoColor=white)](https://yangchanghee.github.io/Person-in-Place_page/) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/YangChangHee/CVPR2024_Person-In-Place_RELEASE)


* **[CVPRÂ 2024]** ***ReferringÂ ImageÂ Editing:*** *Objectâ€‘level ImageÂ Editing via ReferringÂ Expressions*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://openaccess.thecvf.com/content/CVPR2024/papers/Liu_Referring_Image_Editing_Object-level_Image_Editing_via_Referring_Expressions_CVPR_2024_paper.pdf)


* **[CVPRÂ 2024]** ***PromptÂ Augmentation:*** *PromptÂ Augmentation for Selfâ€‘supervised Textâ€‘guided ImageÂ Manipulation*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://openaccess.thecvf.com/content/CVPR2024/papers/Bodur_Prompt_Augmentation_for_Self-supervised_Text-guided_Image_Manipulation_CVPR_2024_paper.pdf)


* **[CVPRÂ 2024]** ***StyleFeatureEditor:*** *The Devil is in the DetailsÂ â€” StyleFeatureEditor for Detailâ€‘Rich StyleGANÂ Inversion and HighÂ Quality ImageÂ Editing*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://openaccess.thecvf.com/content/CVPR2024/papers/Bobkov_The_Devil_is_in_the_Details_StyleFeatureEditor_for_Detail-Rich_StyleGAN_CVPR_2024_paper.pdf) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/AIRI-Institute/StyleFeatureEditor)


* **[ECCVÂ 2024]** ***RegionDrag:*** *Fast Regionâ€‘Based ImageÂ Editing with DiffusionÂ Models*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](http://arxiv.org/pdf/2407.18247v1) [![Project Page](https://img.shields.io/badge/Project-Page-blue?style=for-the-badge&logo=googlechrome&logoColor=white)](https://visual-ai.github.io/regiondrag/) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/Visual-AI/RegionDrag)


* **[ECCVÂ 2024]** ***TurboEdit:*** *Instant Textâ€‘Based ImageÂ Editing*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2408.08332v1.pdf) [![Project Page](https://img.shields.io/badge/Project-Page-blue?style=for-the-badge&logo=googlechrome&logoColor=white)](https://betterze.github.io/TurboEdit/)


* **[ECCVÂ 2024]** ***InstructGIE:*** *TowardsÂ Generalizable ImageÂ Editing*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2403.05018.pdf) [![Project Page](https://img.shields.io/badge/Project-Page-blue?style=for-the-badge&logo=googlechrome&logoColor=white)](https://cr8br0ze.github.io/InstructGIE)


* **[ECCVÂ 2024]** ***StableDrag:*** *StableÂ Dragging for Pointâ€‘based ImageÂ Editing*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2403.04437.pdf) [![Project Page](https://img.shields.io/badge/Project-Page-blue?style=for-the-badge&logo=googlechrome&logoColor=white)](https://stabledrag.github.io/)


* **[ECCVÂ 2024]** ***EtaÂ Inversion:*** *Designing an Optimal EtaÂ Function for Diffusionâ€‘based Real ImageÂ Editing*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://www.ecva.net/papers/eccv_2024/papers_ECCV/papers/02157.pdf) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/furiosa-ai/eta-inversion)


* **[ECCVÂ 2024]** ***SwapAnything:*** *EnablingÂ Arbitrary ObjectÂ Swapping in Personalized ImageÂ Editing*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://www.ecva.net/papers/eccv_2024/papers_ECCV/papers/04768.pdf) [![Project Page](https://img.shields.io/badge/Project-Page-blue?style=for-the-badge&logo=googlechrome&logoColor=white)](https://swap-anything.github.io/) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/eric-ai-lab/swap-anything)


* **[ECCVÂ 2024]** ***Guideâ€‘andâ€‘Rescale:*** *Selfâ€‘GuidanceÂ Mechanism forÂ Effective Tuningâ€‘Free Real ImageÂ Editing*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://www.ecva.net/papers/eccv_2024/papers_ECCV/papers/08987.pdf) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/AIRI-Institute/Guide-and-Rescale)


* **[ECCVÂ 2024]** ***FreeDiff:*** *Progressive FrequencyÂ Truncation for ImageÂ Editing with DiffusionÂ Models*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://www.ecva.net/papers/eccv_2024/papers_ECCV/papers/00759.pdf) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/Thermal-Dynamics/FreeDiff)


* **[ECCVÂ 2024]** ***LazyÂ DiffusionÂ Transformer:*** *Lazy DiffusionÂ Transformer for Interactive ImageÂ Editing*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://www.ecva.net/papers/eccv_2024/papers_ECCV/papers/03436.pdf) [![Project Page](https://img.shields.io/badge/Project-Page-blue?style=for-the-badge&logo=googlechrome&logoColor=white)](https://lazydiffusion.github.io/)


* **[ECCVÂ 2024]** ***ByteEdit:*** *Boost, Comply and Accelerate Generative ImageÂ Editing*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://www.ecva.net/papers/eccv_2024/papers_ECCV/papers/00359.pdf) [![Project Page](https://img.shields.io/badge/Project-Page-blue?style=for-the-badge&logo=googlechrome&logoColor=white)](https://byte-edit.github.io/)


* **[ICLRÂ 2024]** ***MGIE:*** *Guiding Instructionâ€‘based ImageÂ Editing viaÂ MultimodalÂ LargeÂ LanguageÂ Models*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2309.17102.pdf) [![Project Page](https://img.shields.io/badge/Project-Page-blue?style=for-the-badge&logo=googlechrome&logoColor=white)](https://mllm-ie.github.io/) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/apple/ml-mgie)


* **[ICLRÂ 2024]** ***SDEâ€‘Drag:*** *The Blessing of RandomnessÂ â€” SDEÂ BeatsÂ ODE in GeneralÂ Diffusionâ€‘based ImageÂ Editing*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2311.01410.pdf) [![Project Page](https://img.shields.io/badge/Project-Page-blue?style=for-the-badge&logo=googlechrome&logoColor=white)](https://ml-gsai.github.io/SDE-Drag-demo/) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/ML-GSAI/SDE-Drag)


* **[ICLRÂ 2024]** ***MotionÂ Guidance:*** *Diffusionâ€‘Based ImageÂ Editing with Differentiable MotionÂ Estimators*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2401.18085.pdf) [![Project Page](https://img.shields.io/badge/Project-Page-blue?style=for-the-badge&logo=googlechrome&logoColor=white)](https://dangeng.github.io/motion_guidance/) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/dangeng/motion_guidance)


* **[ICLRÂ 2024]** ***OIR:*** *Objectâ€‘AwareÂ Inversion andÂ Reassembly for ImageÂ Editing*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2310.12149.pdf) [![Project Page](https://img.shields.io/badge/Project-Page-blue?style=for-the-badge&logo=googlechrome&logoColor=white)](https://aim-uofa.github.io/OIR-Diffusion/) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/aim-uofa/OIR)


* **[ICLRÂ 2024]** ***NoiseÂ MapÂ Guidance:*** *InversionÂ withÂ Spatial Context forÂ RealÂ ImageÂ Editing*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2402.04625.pdf)


* **[AAAIÂ 2024]** ***TIC:*** *Tuningâ€‘Free Inversionâ€‘EnhancedÂ Control for ConsistentÂ ImageÂ Editing*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2312.14611.pdf)


* **[AAAIÂ 2024]** ***BARET:*** *Balanced AttentionÂ based Real ImageÂ Editing driven by Targetâ€‘textÂ Inversion*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2312.05482.pdf)


* **[AAAIÂ 2024]** ***CacheEdit:*** *Accelerating Textâ€‘toâ€‘ImageÂ Editing via Cacheâ€‘Enabled SparseÂ DiffusionÂ Inference*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2305.17423.pdf)


* **[AAAIÂ 2024]** ***Highâ€‘FidelityÂ Editing:*** *Highâ€‘Fidelity Diffusionâ€‘based ImageÂ Editing*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2312.15707.pdf)


* **[AAAIÂ 2024]** ***AdapEdit:*** *Spatioâ€‘Temporal Guided AdaptiveÂ Editing Algorithm for Textâ€‘Based Continuityâ€‘Sensitive ImageÂ Editing*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2312.08019.pdf) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/AnonymousPony/adap-edit)


* **[AAAIÂ 2024]** ***TexFit:*** *Textâ€‘Driven Fashion ImageÂ Editing with DiffusionÂ Models*<br>
[![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://ojs.aaai.org/index.php/AAAI/article/view/28885)

</details>

<details>
<summary><h4>ğŸ’¡ Pre-Print Papers</h4></summary>

- [Edicho: Consistent Image Editing in the Wild](http://arxiv.org/abs/2412.21079v3) [![GitHub Stars](https://img.shields.io/github/stars/ant-research/edicho?style=social)](https://github.com/ant-research/edicho)   [![Project Page](https://img.shields.io/badge/Project-Page-blue?logo=website)](https://ant-research.github.io/edicho/)
- [Unforgettable Lessons from Forgettable Images: Intra-Class Memorability Matters in Computer Vision](http://arxiv.org/abs/2412.20761v4)
- [MADiff: Text-Guided Fashion Image Editing with Mask Prediction and Attention-Enhanced Diffusion](http://arxiv.org/abs/2412.20062v2)
- [DRDM: A Disentangled Representations Diffusion Model for Synthesizing Realistic Person Images](http://arxiv.org/abs/2412.18797v1)
- [Fashionability-Enhancing Outfit Image Editing with Conditional Diffusion Models](http://arxiv.org/abs/2412.18421v1)
- [The Superposition of Diffusion Models Using the ItÃ´ Density Estimator](http://arxiv.org/abs/2412.17762v2)
- [Mapping the Mind of an Instruction-based Image Editing using SMILE](http://arxiv.org/abs/2412.16277v1)
- [Diffusion-Based Conditional Image Editing through Optimized Inference with Guidance](http://arxiv.org/abs/2412.15798v1)
- [UIP2P: Unsupervised Instruction-based Image Editing via Cycle Edit Consistency](http://arxiv.org/abs/2412.15216v1)
- [Affordance-Aware Object Insertion via Mask-Aware Dual Diffusion](http://arxiv.org/abs/2412.14462v2) [![GitHub Stars](https://img.shields.io/github/stars/KaKituken/affordance-aware-any?style=social)](https://github.com/KaKituken/affordance-aware-any)   [![Project Page](https://img.shields.io/badge/Project-Page-blue?logo=website)](https://kakituken.github.io/affordance-any.github.io/) [![Huggingface Face](https://img.shields.io/badge/Hugging-Face-orange?logo=website)](https://huggingface.co/datasets/Kakituken/SAM-FB)
- [Text2Relight: Creative Portrait Relighting with Text Guidance](http://arxiv.org/abs/2412.13734v1) [![Project Page](https://img.shields.io/badge/Project-Page-blue?logo=website)](https://junukcha.github.io/project/text2relight/)
- [Prompt Augmentation for Self-supervised Text-guided Image Manipulation](http://arxiv.org/abs/2412.13081v1)
- [Unsupervised Region-Based Image Editing of Denoising Diffusion Models](http://arxiv.org/abs/2412.12912v1)
- [Pattern Analogies: Learning to Perform Programmatic Image Edits by Analogy](http://arxiv.org/abs/2412.12463v2)
- [Dual-Schedule Inversion: Training- and Tuning-Free Inversion for Real Image Editing](http://arxiv.org/abs/2412.11152v1)
- [BrushEdit: All-In-One Image Inpainting and Editing](http://arxiv.org/abs/2412.10316v3) [![GitHub Stars](https://img.shields.io/github/stars/TencentARC/BrushEdit?style=social)](https://github.com/TencentARC/BrushEdit)   [![Project Page](https://img.shields.io/badge/Project-Page-blue?logo=website)](https://liyaowei-stu.github.io/project/BrushEdit/) [![Huggingface Face](https://img.shields.io/badge/Hugging-Face-orange?logo=website)](https://huggingface.co/TencentARC/BrushEdit)
- [Learning Complex Non-Rigid Image Edits from Multimodal Conditioning](http://arxiv.org/abs/2412.10219v1)
- [Context Canvas: Enhancing Text-to-Image Diffusion Models with Knowledge Graph-Based RAG](http://arxiv.org/abs/2412.09614v1)
- [FluxSpace: Disentangled Semantic Editing in Rectified Flow Transformers](http://arxiv.org/abs/2412.09611v1) [![Project Page](https://img.shields.io/badge/Project-Page-blue?logo=website)](https://fluxspace.github.io/)
- [PrEditor3D: Fast and Precise 3D Shape Editing](http://arxiv.org/abs/2412.06592v1)
- [MoViE: Mobile Diffusion for Video Editing](http://arxiv.org/abs/2412.06578v1) [![GitHub Stars](https://img.shields.io/github/stars/Qualcomm-AI-research/mobile-video-editing?style=social)](https://github.com/Qualcomm-AI-research/mobile-video-editing)   [![Project Page](https://img.shields.io/badge/Project-Page-blue?logo=website)](https://qualcomm-ai-research.github.io/mobile-video-editing/)
- [GraPE: A Generate-Plan-Edit Framework for Compositional T2I Synthesis](http://arxiv.org/abs/2412.06089v2) [![GitHub Stars](https://img.shields.io/github/stars/dair-iitd/PixEdit?style=social)](https://github.com/dair-iitd/PixEdit)   [![Project Page](https://img.shields.io-badge/Project-Page-blue?logo=website)](https://dair-iitd.github.io/GraPE/) [![Huggingface Face](https://img.shields.io/badge/Hugging-Face-orange?logo=website)](https://huggingface.co/aggr8/PixEdit-v1)
- [Text-to-3D Generation by 2D Editing](http://arxiv.org/abs/2412.05929v2)


</details>

</details>

<details>
<summary><h4>âœ¨ 2023</h4></summary>

<details>
<summary><h4>âœ… Published Papers</h4></summary>

* **[CVPR 2023]** ***Diffusion Disentanglement:*** *Uncovering the Disentanglement Capability in Text-to-Image Diffusion Models*<br>
  [![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://openaccess.thecvf.com/content/CVPR2023/papers/Wu_Uncovering_the_Disentanglement_Capability_in_Text-to-Image_Diffusion_Models_CVPR_2023_paper.pdf) [![Project Page](https://img.shields.io/badge/Project-Page-blue?style=for-the-badge&logo=googlechrome&logoColor=white)](https://wuqiuche.github.io/DiffusionDisentanglement-project-page/) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/UCSB-NLP-Chang/DiffusionDisentanglement)

* **[CVPR 2023]** ***SINE:*** *SINgle Image Editing with Text-to-Image Diffusion Models*<br>
  [![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://openaccess.thecvf.com/content/CVPR2023/papers/Zhang_SINE_SINgle_Image_Editing_With_Text-to-Image_Diffusion_Models_CVPR_2023_paper.pdf) [![Project Page](https://img.shields.io/badge/Project-Page-blue?style=for-the-badge&logo=googlechrome&logoColor=white)](https://zhang-zx.github.io/SINE/) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/zhang-zx/SINE)

* **[CVPR 2023]** ***Imagic:*** *Text-Based Real Image Editing with Diffusion Models*<br>
  [![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://openaccess.thecvf.com/content/CVPR2023/papers/Kawar_Imagic_Text-Based_Real_Image_Editing_With_Diffusion_Models_CVPR_2023_paper.pdf) [![Project Page](https://img.shields.io/badge/Project-Page-blue?style=for-the-badge&logo=googlechrome&logoColor=white)](https://imagic-editing.github.io/) [![Hugging Face](https://img.shields.io/badge/%F0%9F%A4%97-Hugging_Face-yellow?style=for-the-badge)](https://huggingface.co/spaces/fffiloni/imagic-stable-diffusion)

* **[CVPR 2023]** ***InstructPix2Pix:*** *Learning to Follow Image Editing Instructions*<br>
  [![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://openaccess.thecvf.com/content/CVPR2023/papers/Brooks_InstructPix2Pix_Learning_To_Follow_Image_Editing_Instructions_CVPR_2023_paper.pdf) [![Project Page](https://img.shields.io/badge/Project-Page-blue?style=for-the-badge&logo=googlechrome&logoColor=white)](https://www.timothybrooks.com/instruct-pix2pix/) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/timothybrooks/instruct-pix2pix) [![Hugging Face](https://img.shields.io/badge/%F0%9F%A4%97-Hugging_Face-yellow?style=for-the-badge)](https://huggingface.co/timbrooks/instruct-pix2pix)

* **[CVPR 2023]** ***Null-text Inversion:*** *Null-text Inversion for Editing Real Images using Guided Diffusion Models*<br>
  [![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://openaccess.thecvf.com/content/CVPR2023/papers/Mokady_NULL-Text_Inversion_for_Editing_Real_Images_Using_Guided_Diffusion_Models_CVPR_2023_paper.pdf) [![Project Page](https://img.shields.io/badge/Project-Page-blue?style=for-the-badge&logo=googlechrome&logoColor=white)](https://null-text-inversion.github.io/) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/google/prompt-to-prompt)

* **[ICCV 2023]** ***MasaCtrl:*** *Tuning-Free Mutual Self-Attention Control for Consistent Image Synthesis and Editing*<br>
  [![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://openaccess.thecvf.com/content/ICCV2023/papers/Cao_MasaCtrl_Tuning-Free_Mutual_Self-Attention_Control_for_Consistent_Image_Synthesis_and_ICCV_2023_paper.pdf) [![Project Page](https://img.shields.io/badge/Project-Page-blue?style=for-the-badge&logo=googlechrome&logoColor=white)](https://ljzycmd.github.io/projects/MasaCtrl/) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/TencentARC/MasaCtrl)

* **[ICCV 2023]** ***Local Prompt Mixing:*** *Localizing Object-level Shape Variations with Text-to-Image Diffusion Models*<br>
  [![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://openaccess.thecvf.com/content/ICCV2023/papers/Patashnik_Localizing_Object-Level_Shape_Variations_with_Text-to-Image_Diffusion_Models_ICCV_2023_paper.pdf) [![Project Page](https://img.shields.io/badge/Project-Page-blue?style=for-the-badge&logo=googlechrome&logoColor=white)](https://orpatashnik.github.io/local-prompt-mixing/) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/orpatashnik/local-prompt-mixing) [![Hugging Face](https://img.shields.io/badge/%F0%9F%A4%97-Hugging_Face-yellow?style=for-the-badge)](https://huggingface.co/spaces/orpatashnik/local-prompt-mixing)

* **[ICLR 2022]** ***SDEdit:*** *Guided Image Synthesis and Editing with Stochastic Differential Equations*<br>
  [![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2108.01073.pdf) [![Project Page](https://img.shields.io/badge/Project-Page-blue?style=for-the-badge&logo=googlechrome&logoColor=white)](https://sde-image-editing.github.io/) [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/ermongroup/SDEdit)


</details>

<details>
<summary><h4>ğŸ’¡ Pre-Print Papers</h4></summary>

- [ZONE: Zero-Shot Instruction-Guided Local Editing](http://arxiv.org/abs/2312.16794v2) [![GitHub Stars](https://img.shields.io/github/stars/lsl001006/ZONE?style=social)](https://github.com/lsl001006/ZONE)
- [UniHuman: A Unified Model for Editing Human Images in the Wild](http://arxiv.org/abs/2312.14985v2) [![GitHub Stars](https://img.shields.io/github/stars/adobe-research/UniHuman?style=social)](https://github.com/adobe-research/UniHuman)
- [AppAgent: Multimodal Agents as Smartphone Users](http://arxiv.org/abs/2312.13771v2) [![GitHub Stars](https://img.shields.io/github/stars/TencentQQGYLab/AppAgent?style=social)](https://github.com/TencentQQGYLab/AppAgent)   [![Project Page](https://img.shields.io/badge/Project-Page-blue?logo=website)](https://appagent-official.github.io/)
- [Lightning-Fast Image Inversion and Editing for Text-to-Image Diffusion Models](http://arxiv.org/abs/2312.12540v5) [![GitHub Stars](https://img.shields.io/github/stars/dvirsamuel/NewtonRaphsonInversion?style=social)](https://github.com/dvirsamuel/NewtonRaphsonInversion)   [![Project Page](https://img.shields.io/badge/Project-Page-blue?logo=website)](https://barakmam.github.io/rnri.github.io/)
- [MAG-Edit: Localized Image Editing in Complex Scenarios via Mask-Based Attention-Adjusted Guidance](http://arxiv.org/abs/2312.11396v2) [![GitHub Stars](https://img.shields.io/github/stars/HelenMao/MAG-Edit?style=social)](https://github.com/HelenMao/MAG-Edit)   [![Project Page](https://img.shields.io/badge/Project-Page-blue?logo=website)](https://mag-edit.github.io)
- [CLOVA: A Closed-Loop Visual Assistant with Tool Usage and Update](http://arxiv.org/abs/2312.10908v3) [![GitHub Stars](https://img.shields.io/github/stars/clova-tool/CLOVA-tool?style=social)](https://github.com/clova-tool/CLOVA-tool)   [![Project Page](https://img.shields.io/badge/Project-Page-blue?logo=website)](https://clova-tool.github.io)
- [Latent Space Editing in Transformer-Based Flow Matching](http://arxiv.org/abs/2312.10825v1) [![GitHub Stars](https://img.shields.io/github/stars/dongzhuoyao/uspace?style=social)](https://github.com/dongzhuoyao/uspace)
- [VidToMe: Video Token Merging for Zero-Shot Video Editing](http://arxiv.org/abs/2312.10656v2) [![GitHub Stars](https://img.shields.io/github/stars/lixirui142/VidToMe?style=social)](https://github.com/lixirui142/VidToMe)   [![Project Page](https://img.shields.io/badge/Project-Page-blue?logo=website)](https://vidtome-diffusion.github.io)
- [Focus on Your Instruction: Fine-grained and Multi-instruction Image Editing by Attention Modulation](http://arxiv.org/abs/2312.10113v1) [![GitHub Stars](https://img.shields.io/github/stars/guoqincode/Focus-on-Your-Instruction?style=social)](https://github.com/guoqincode/Focus-on-Your-Instruction)
- [SHAP-EDITOR: Instruction-guided Latent 3D Editing in Seconds](http://arxiv.org/abs/2312.09246v1) [![GitHub Stars](https://img.shields.io/github/stars/silent-chen/Shap-Editor?style=social)](https://github.com/silent-chen/Shap-Editor)   [![Project Page](https://img.shields.io/badge/Project-Page-blue?logo=website)](https://silent-chen.github.io) [![Huggingface Face](https://img.shields.io/badge/Hugging-Face-orange?logo=website)](https://huggingface.co/spaces/silent-chen/Shap-Editor)
- [Clockwork Diffusion: Efficient Generation With Model-Step Distillation](http://arxiv.org/abs/2312.08128v2) [![GitHub Stars](https://img.shields.io/github/stars/Qualcomm-AI-research/clockwork-diffusion?style=social)](https://github.com/Qualcomm-AI-research/clockwork-diffusion)
- [SmartEdit: Exploring Complex Instruction-based Image Editing with Multimodal Large Language Models](http://arxiv.org/abs/2312.06739v1) [![GitHub Stars](https://img.shields.io/github/stars/TencentARC/SmartEdit?style=social)](https://github.com/TencentARC/SmartEdit)   [![Project Page](https://img.shields.io/badge/Project-Page-blue?logo=website)](https://yuzhou914.github.io/projects/SmartEdit/)
- [Inversion-Free Image Editing with Natural Language](http://arxiv.org/abs/2312.04965v1) [![GitHub Stars](https://img.shields.io/github/stars/sled-group/InfEdit?style=social)](https://github.com/sled-group/InfEdit)   [![Project Page](https://img.shields.io/badge/Project-Page-blue?logo=website)](https://sled-group.github.io/InfEdit/)
- [BIVDiff: A Training-Free Framework for General-Purpose Video Synthesis via Bridging Image and Video Diffusion Models](http://arxiv.org/abs/2312.02813v2) [![GitHub Stars](https://img.shields.io/github/stars/MCG-NJU/BIVDiff?style=social)](https://github.com/MCG-NJU/BIVDiff)   [![Project Page](https://img.shields.io/badge/Project-Page-blue?logo=website)](https://bivdiff.github.io/)
- [Customize your NeRF: Adaptive Source Driven 3D Scene Editing via Local-Global Iterative Training](http://arxiv.org/abs/2312.01663v1) [![GitHub Stars](https://img.shields.io/github/stars/hrz2000/CustomNeRF?style=social)](https://github.com/hrz2000/CustomNeRF)   [![Project Page](https://img.shields.io/badge/Project-Page-blue?logo=website)](https://customnerf.github.io/)
- [Diffusion Handles: Enabling 3D Edits for Diffusion Models by Lifting Activations to 3D](http://arxiv.org/abs/2312.02190v2) [![GitHub Stars](https://img.shields.io/github/stars/adobe-research/DiffusionHandles?style=social)](https://github.com/adobe-research/DiffusionHandles)   [![Project Page](https://img.shields.io/badge/Project-Page-blue?logo=website)](https://diffusionhandles.github.io/)
- [Adversarial Score Distillation: When score distillation meets GAN](http://arxiv.org/abs/2312.00739v2) [![GitHub Stars](https://img.shields.io/github/stars/2y7c3/ASD?style=social)](https://github.com/2y7c3/ASD)   [![Project Page](https://img.shields.io/badge/Project-Page-blue?logo=website)](https://2y7c3.github.io/ASD/asd.html)
- [Motion-Conditioned Image Animation for Video Editing](http://arxiv.org/abs/2311.18827v1) [![GitHub Stars](https://img.shields.io/github/stars/facebookresearch/MoCA?style=social)](https://github.com/facebookresearch/MoCA)   [![Project Page](https://img.shields.io/badge/Project-Page-blue?logo=website)](https://facebookresearch.github.io/MoCA/)
- [Contrastive Denoising Score for Text-guided Latent Diffusion Image Editing](http://arxiv.org/abs/2311.18608v2) [![GitHub Stars](https://img.shields.io/github/stars/HyelinNAM/ContrastiveDenoisingScore?style=social)](https://github.com/HyelinNAM/ContrastiveDenoisingScore)   [![Project Page](https://img.shields.io/badge/Project-Page-blue?logo=website)](https://hyelinnam.github.io/CDS/)
- [On Exact Inversion of DPM-Solvers](http://arxiv.org/abs/2311.18387v1) [![GitHub Stars](https://img.shields.io/github/stars/smhongok/inv-dpm?style=social)](https://github.com/smhongok/inv-dpm)   [![Project Page](https://img.shields.io/badge/Project-Page-blue?logo=website)](https://smhongok.github.io/inv-dpm.html)
- [COLE: A Hierarchical Generation Framework for Multi-Layered and Editable Graphic Design](http://arxiv.org/abs/2311.16974v2) [![GitHub Stars](https://img.shields.io/github/stars/CyberAgentAILab/OpenCOLE?style=social)](https://github.com/CyberAgentAILab/OpenCOLE)   [![Huggingface Face](https://img.shields.io/badge/Hugging-Face-orange?logo=website)](https://huggingface.co/cyberagent/opencole)
- [LEDITS++: Limitless Image Editing using Text-to-Image Models](http://arxiv.org/abs/2311.16711v2) [![GitHub Stars](https://img.shields.io/github/stars/ml-research/ledits_pp?style=social)](https://github.com/ml-research/ledits_pp)   [![Huggingface Face](https://img.shields.io/badge/Hugging-Face-orange?logo=website)](https://huggingface.co/spaces/leditsplusplus/project)
- [Text-Driven Image Editing via Learnable Regions](http://arxiv.org/abs/2311.16432v2) [![GitHub Stars](https://img.shields.io/github/stars/yuanze-lin/Learnable_Regions?style=social)](https://github.com/yuanze-lin/Learnable_Regions)
- [Self-correcting LLM-controlled Diffusion Models](http://arxiv.org/abs/2311.16090v1) [![GitHub Stars](https://img.shields.io/github/stars/tsunghan-wu/SLD?style=social)](https://github.com/tsunghan-wu/SLD)   [![Project Page](https://img.shields.io/badge/Project-Page-blue?logo=website)](https://self-correcting-llm-diffusion.github.io/)
- [EditShield: Protecting Unauthorized Image Editing by Instruction-guided Diffusion Models](http://arxiv.org/abs/2311.12066v2) [![GitHub Stars](https://img.shields.io/github/stars/Allen-piexl/Editshield?style=social)](https://github.com/Allen-piexl/Editshield)
- [EditVal: Benchmarking Diffusion Based Text-Guided Image Editing Methods](http://arxiv.org/abs/2310.02426v1) [![GitHub Stars](https://img.shields.io/github/stars/deep-ml-research/editval?style=social)](https://github.com/deep-ml-research/editval)   [![Project Page](https://img.shields.io/badge/Project-Page-blue?logo=website)](https://deep-ml-research.github.io/editval/)
- [ImagenHub: Standardizing the evaluation of conditional image generation models](http://arxiv.org/abs/2310.01596v4) [![GitHub Stars](https://img.shields.io/github/stars/TIGER-AI-Lab/ImagenHub?style=social)](https://github.com/TIGER-AI-Lab/ImagenHub)   [![Project Page](https://img.shields.io/badge/Project-Page-blue?logo=website)](https://tiger-ai-lab.github.io/ImagenHub/)
- [TokenFlow: Consistent Diffusion Features for Consistent Video Editing](http://arxiv.org/abs/2307.10373v3) [![GitHub Stars](https://img.shields.io/github/stars/omerbt/TokenFlow?style=social)](https://github.com/omerbt/TokenFlow)   [![Project Page](https://img.shields.io/badge/Project-Page-blue?logo=website)](https://diffusion-tokenflow.github.io/) [![Huggingface Face](https://img.shields.io/badge/Hugging-Face-orange?logo=website)](https://huggingface.co/weizmannscience/tokenflow)
- [FreeDrag: Feature Dragging for Reliable Point-based Image Editing](http://arxiv.org/abs/2307.04684v4) [![GitHub Stars](https://img.shields.io/github/stars/LPengYang/FreeDrag?style=social)](https://github.com/LPengYang/FreeDrag)
- [DragonDiffusion: Enabling Drag-style Manipulation on Diffusion Models](http://arxiv.org/abs/2307.02421v2) [![GitHub Stars](https://img.shields.io/github/stars/MC-E/DragonDiffusion?style=social)](https://github.com/MC-E/DragonDiffusion)   [![Project Page](https://img.shields.io/badge/Project-Page-blue?logo=website)](https://mc-e.github.io/project/DragonDiffusion/)
- [LEDITS: Real Image Editing with DDPM Inversion and Semantic Guidance](http://arxiv.org/abs/2307.00522v1) [![GitHub Stars](https://img.shields.io/github/stars/camenduru/ledits-hf?style=social)](https://github.com/camenduru/ledits-hf)   [![Huggingface Face](https://img.shields.io/badge/Hugging-Face-orange?logo=website)](https://huggingface.co/spaces/editing-images/project)
- [DragDiffusion: Harnessing Diffusion Models for Interactive Point-based Image Editing](http://arxiv.org/abs/2306.14435v6) [![GitHub Stars](https://img.shields.io/github/stars/Yujun-Shi/DragDiffusion?style=social)](https://github.com/Yujun-Shi/DragDiffusion)   [![Project Page](https://img.shields.io/badge/Project-Page-blue?logo=website)](https://yujun-shi.github.io/projects/dragdiffusion.html)
- [MasaCtrl: Tuning-Free Mutual Self-Attention Control for Consistent Image Synthesis and Editing](http://arxiv.org/abs/2304.08465v1) [![GitHub Stars](https://img.shields.io/github/stars/TencentARC/MasaCtrl?style=social)](https://github.com/TencentARC/MasaCtrl)   [![Project Page](https://img.shields.io/badge/Project-Page-blue?logo=website)](https://ljzycmd.github.io/projects/MasaCtrl/)
- [MagicBrush: A Manually Annotated Dataset for Instruction-Guided Image Editing](http://arxiv.org/abs/2306.10012v3) [![GitHub Stars](https://img.shields.io/github/stars/OSU-NLP-Group/MagicBrush?style=social)](https://github.com/OSU-NLP-Group/MagicBrush)   [![Project Page](https://img.shields.io/badge/Project-Page-blue?logo=website)](https://osu-nlp-group.github.io/MagicBrush/) [![Huggingface Face](https://img.shields.io/badge/Hugging-Face-orange?logo=website)](https://huggingface.co/datasets/osunlp/MagicBrush)


</details>

</details>

[<small>â‡§ Back to ToC</small>](#contents)



---

## <span id="datasets">ğŸ—‚ï¸ Datasets</span>
| Dataset Name | Year | Modalities | Task | Paper | Link |
| :--- | :--- | :--- | :--- | :---: | :---: |
| **MS COCO** | 2014 | Text, Image | Text-to-Image Generation, Image Captioning | [![Paper](https://img.shields.io/badge/Paper-Link-red?style=for-the-badge)](https://arxiv.org/abs/1405.0312) | [![Website](https://img.shields.io/badge/Website-Link-orange?style=for-the-badge)](https://cocodataset.org/#home) |
| **Oxford-120 Flowers**| 2008 | Text, Image | Text-to-Image Generation | [![Paper](https://img.shields.io/badge/Paper-Link-red?style=for-the-badge)](https://www.robots.ox.ac.uk/~vgg/publications/2008/Nilsback08/nilsback08.pdf) | [![Website](https://img.shields.io/badge/Website-Link-orange?style=for-the-badge)](https://www.robots.ox.ac.uk/~vgg/data/flowers/102/) |
| **CUB-200-2011** | 2011 | Text, Image | Text-to-Image Generation | [![Paper](https://img.shields.io/badge/Paper-Link-red?style=for-the-badge)](https://resolver.caltech.edu/CaltechCSTR:2010.001) | [![Website](https://img.shields.io/badge/Website-Link-orange?style=for-the-badge)](http://www.vision.caltech.edu/datasets/cub_200_2011/) |
| **LAION-5B** | 2022 | Text, Image | Text-to-Image Generation | [![Paper](https://img.shields.io/badge/Paper-Link-red?style=for-the-badge)](https://arxiv.org/abs/2210.08402) | [![Website](https://img.shields.io/badge/Website-Link-orange?style=for-the-badge)](https://laion.ai/blog/laion-5b/) |
| **DiffusionDB** | 2022 | Text, Image | Text-to-Image Generation | [![Paper](https://img.shields.io/badge/Paper-Link-red?style=for-the-badge)](https://arxiv.org/abs/2210.14896) | [![Website](https://img.shields.io/badge/Website-Link-orange?style=for-the-badge)](https://poloclub.github.io/diffusiondb/) |

[<small>â‡§ Back to ToC</small>](#contents)

---

## <span id="about-us">ğŸ“ About Us</span>

QuenithAI is a professional organization composed of top researchers, dedicated to providing high-quality 1-on-1 research mentoring for university students worldwide. Our mission is to help students bridge the gap from theoretical knowledge to cutting-edge research and publish their work in top-tier conferences and journals.

Maintaining this `Awesome Text-to-Image Generation` list requires significant effort, just as completing a high-quality paper requires focused dedication and expert guidance. If you're looking for one-on-one support from top scholars on your own research project, to quickly identify innovative ideas and make publications, we invite you to contact us ASAP.

â¡ï¸ **Contact us via [WeChat](assets/wechat.jpg) or [E-mail](mailto:your.email@example.com) to start your research journey.**

---

ã€Œåº”è¾¾å­¦æœ¯ã€(QuenithAI) æ˜¯ä¸€å®¶ç”±é¡¶å°–ç ”ç©¶è€…ç»„æˆï¼Œè‡´åŠ›äºä¸ºå…¨çƒé«˜æ ¡å­¦ç”Ÿæä¾›é«˜è´¨é‡1V1ç§‘ç ”è¾…å¯¼çš„ä¸“ä¸šæœºæ„ã€‚æˆ‘ä»¬çš„ä½¿å‘½æ˜¯å¸®åŠ©å­¦ç”ŸåŸ¹å…»å‡ºè‰²å“è¶Šçš„ç§‘ç ”æŠ€èƒ½ï¼Œåœ¨é¡¶çº§ä¼šè®®å’ŒæœŸåˆŠä¸Šå‘è¡¨è‡ªå·±çš„æˆæœã€‚

ç»´æŠ¤ä¸€ä¸ªGitHubè°ƒç ”ä»“åº“éœ€è¦å·¨å¤§çš„ç²¾åŠ›ï¼Œæ­£å¦‚å®Œæˆä¸€ç¯‡é«˜è´¨é‡çš„è®ºæ–‡ä¸€æ ·ï¼Œç¦»ä¸å¼€ä¸“æ³¨çš„æŠ•å…¥å’Œä¸“ä¸šçš„æŒ‡å¯¼ã€‚å¦‚æœæ‚¨å¸Œæœ›åœ¨è‡ªå·±çš„ç ”ç©¶é¡¹ç›®ä¸­ï¼Œè·å¾—æ¥è‡ªé¡¶å°–å­¦è€…çš„ä¸€å¯¹ä¸€æ”¯æŒï¼Œæˆ‘ä»¬è¯šé‚€æ‚¨ä¸æˆ‘ä»¬å–å¾—è”ç³»ã€‚

â¡ï¸ **æ¬¢è¿é€šè¿‡ [å¾®ä¿¡](assets/wechat.jpg) æˆ– [é‚®ä»¶](mailto:your.email@example.com) è”ç³»æˆ‘ä»¬ï¼Œå¼€å¯æ‚¨çš„ç§‘ç ”ä¹‹æ—…ã€‚**


[<small>â‡§ Back to ToC</small>](#contents)

---



## <span id="contributing">ğŸ¤ Contributing</span>

Contributions are welcome! Please see our [**Contribution Guidelines**](CONTRIBUTING.md) for details on how to add new papers, correct information, or improve the repository.
