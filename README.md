<div align="center">
  <a href="YOUR_OFFICIAL_WEBSITE_URL">
    <img src="assets/logo_run_cn.png" alt="QuenithAI Logo" width="200" height="200">
  </a>
</div>

<div align="center">
  <h1>Awesome Text-to-Image Generation by QuenithAI</h1>
  <p>A curated collection of papers, models, and resources for the field of Text-to-Image Generation.</p>
  <p>
    <a href="https://awesome.re"><img src="https://awesome.re/badge.svg" alt="Awesome"></a>
    &nbsp;
    <a href="https://github.com/QuenithAI/T2I-Generation-Paper-List/pulls"><img src="https://img.shields.io/badge/PRs-Welcome-brightgreen.svg?style=flat-square" alt="PRs Welcome"></a>
    &nbsp;
    <a href="https://github.com/QuenithAI/T2I-Generation-Paper-List/issues"><img src="https://img.shields.io/badge/Issues-Welcome-orange?style=flat-square" alt="Issues Welcome"></a>
  </p>
</div>

> [!NOTE]
> This repository is proudly maintained by the frontline research mentors at **QuenithAI (åº”è¾¾å­¦æœ¯)**. It aims to provide the most comprehensive and cutting-edge map of papers and technologies in the field of Text-to-Image generation.
>
> Your contributions are also vitalâ€”feel free to [open an issue](https://github.com/QuenithAI/T2I-Generation-Paper-List/issues) or [submit a pull request](https://github.com/QuenithAI/T2I-Generation-Paper-List/pulls) to become a collaborator of this repository. We expect your participation!
> 
>  If you require expert 1-on-1 guidance on your submissions to top-tier conferences and journals, we invite you to **contact us via [WeChat](assets/wechat.jpg) or [E-mail]((mailto:christzhaung@gmail.com))**.
>
>
> ---
>
> æœ¬ä»“åº“ç”± **ã€Œåº”è¾¾å­¦æœ¯ã€(QuenithAI)** çš„ä¸€çº¿ç§‘ç ”å¯¼å¸ˆå›¢é˜Ÿå€¾åŠ›æ‰“é€ å¹¶æŒç»­ç»´æŠ¤ï¼Œæ—¨åœ¨ä¸ºæ‚¨å‘ˆç°æ–‡ç”Ÿå›¾é¢†åŸŸæœ€å…¨é¢ã€æœ€å‰æ²¿çš„è®ºæ–‡ã€‚
>
> æ‚¨çš„è´¡çŒ®å¯¹æˆ‘ä»¬å’Œç¤¾åŒºæ¥è¯´è‡³å…³é‡è¦â€”â€”æˆ‘ä»¬è¯šé‚€æœ‰å¿—ä¹‹å£«é€šè¿‡ [open an issue](https://github.com/QuenithAI/T2I-Generation-Paper-List/issues) æˆ– [submit a pull request](https://github.com/QuenithAI/T2I-Generation-Paper-List/pulls) æ¥æˆä¸ºè¿™ä¸ªé¡¹ç›®çš„åˆä½œè€…ä¹‹ä¸€ï¼ŒæœŸå¾…æ‚¨çš„åŠ å…¥ï¼
> 
> å¦‚æœæ‚¨åœ¨å†²åˆºç§‘ç ”é¡¶ä¼šçš„é“è·¯ä¸Šéœ€è¦ä¸“ä¸šçš„1V1æŒ‡å¯¼ï¼Œæ¬¢è¿**é€šè¿‡[å¾®ä¿¡](assets/wechat.jpg)æˆ–[é‚®ä»¶](mailto:christzhaung@gmail.com)è”ç³»æˆ‘ä»¬**ã€‚


<details>
<summary><strong>âš¡ Latest Updates</strong></summary>

- **(Aug 21th, 2025)**: Add a new direction: [ğŸ¨ Personalized Image Generation](#personalized).
- **(Aug 20th, 2025)**: Initial commit and repository structure established.

</details>

---

## <span id="contents">ğŸ“š Table of Contents</span>
- [ğŸ“š Table of Contents](#-table-of-contents)
- [ğŸ“œ Papers \& Models](#-papers--models)
  - [âœï¸ Survey Papers](#ï¸-survey-papers)
  - [ğŸ–¼ï¸ Text-to-Image Generation](#ï¸-text-to-image-generation)
  - [ğŸ•¹ï¸ Conditional Image Generation](#ï¸-conditional-image-generation)
  - [ğŸ¨ Personalized Image Generation](#-personalized-image-generation)
  - [âœ‚ï¸ Image Editing](#ï¸-image-editing)
- [ğŸ—‚ï¸ Datasets](#ï¸-datasets)
- [ğŸ“ About Us](#-about-us)
- [ğŸ¤ Contributing](#-contributing)

---

## <span id="papers">ğŸ“œ Papers & Models</span>

### <span id="survey">âœï¸ Survey Papers</span>



[<small>â‡§ Back to ToC</small>](#contents)

### <span id="t2i">ğŸ–¼ï¸ Text-to-Image Generation</span>

<details>
<summary><h4>âœ¨ 2025</h4></summary>

* **[CVPRâ€¯2025]** ***PreciseCam:*** Precise Camera Control for Text-to-Image Generation<br>
    [![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2501.12910)  
    [![Project Page](https://img.shields.io/badge/Project-Page-blue?style=for-the-badge&logo=googlechrome&logoColor=white)](https://graphics.unizar.es/projects/PreciseCam2024/)  
    [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/edurnebernal/PreciseCam)  
    [![HuggingÂ Face](https://img.shields.io/badge/%F0%9F%A4%97-Hugging_Face-yellow?style=for-the-badge)](https://huggingface.co/edurnebb/PreciseCam)

* **[CVPRâ€¯2025]** ***Typeâ€‘R:*** Automatically Retouching Typos for Textâ€‘toâ€‘Image Generation<br>
    [![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/abs/2411.18159)  
    [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/CyberAgentAILab/Type-R)  
    [![HuggingÂ Face](https://img.shields.io/badge/%F0%9F%A4%97-Hugging_Face-yellow?style=for-the-badge)](https://huggingface.co/cyberagent/type-r)

* **[CVPRâ€¯2025]** ***Compassâ€¯Control:*** Multi Object Orientation Control for Textâ€‘toâ€‘Image Generation<br>
    [![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2504.06752)  
    [![Project Page](https://img.shields.io/badge/Project-Page-blue?style=for-the-badge&logo=googlechrome&logoColor=white)](https://rishubhpar.github.io/CompassControl/)

* **[CVPRâ€¯2025]** ***GenerativeÂ Photography:*** Sceneâ€‘Consistent Camera Control for Realistic Textâ€‘toâ€‘Image Synthesis<br>
    [![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2412.02168)  
    [![Project Page](https://img.shields.io/badge/Project-Page-blue?style=for-the-badge&logo=googlechrome&logoColor=white)](https://generative-photography.github.io/project/)  
    [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/pandayuanyu/generative-photography)  
    [![HuggingÂ Face](https://img.shields.io/badge/%F0%9F%A4%97-Hugging_Face-yellow?style=for-the-badge)](https://huggingface.co/pandaphd/generative_photography)

* **[CVPRâ€¯2025]** ***Oneâ€‘WayÂ Ticket:*** Timeâ€‘Independent Unified Encoder for Distilling Textâ€‘toâ€‘Image Diffusion Models<br>
    [![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://cvpr.thecvf.com/virtual/2025/poster/32579)  
    [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/sen-mao/Loopfree)  
    [![HuggingÂ Face](https://img.shields.io/badge/%F0%9F%A4%97-Hugging_Face-yellow?style=for-the-badge)](https://huggingface.co/senmaonk/loopfree-sd2.1-base)

* **[CVPRâ€¯2025]** ***Textâ€¯Embedding is Not All You Need:*** Attention Control for Textâ€‘toâ€‘Image Semantic Alignment with Text Selfâ€‘Attention Maps<br>
    [![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2411.15236)  
    [![Project Page](https://img.shields.io/badge/Project-Page-blue?style=for-the-badge&logo=googlechrome&logoColor=white)](https://t-sam-diffusion.github.io/)  
    [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/t-sam-diffusion/code)

* **[CVPRâ€¯2025]** ***TowardsÂ Uncertainty:*** Understanding and Quantifying Uncertainty for Textâ€‘toâ€‘Image Generation<br>
    [![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2412.03178)  
    [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/ENSTA-U2IS-AI/Uncertainty_diffusion)

* **[CVPRâ€¯2025]** ***ResponsibleÂ Diffusion:*** Plugâ€‘andâ€‘Play Interpretable Responsible Textâ€‘toâ€‘Image Generation via Dualâ€‘Space Multiâ€‘faceted Concept Control<br>
    [![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2503.18324)  
    [![Project Page](https://img.shields.io/badge/Project-Page-blue?style=for-the-badge&logo=googlechrome&logoColor=white)](https://basim-azam.github.io/responsiblediffusion/)  
    [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/basim-azam/responsiblediffusion)

* **[CVPRâ€¯2025]** ***MakeÂ ItÂ Count:*** Textâ€‘toâ€‘Image Generation with an Accurate Number of Objects<br>
    [![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2406.10210)  
    [![Project Page](https://img.shields.io/badge/Project-Page-blue?style=for-the-badge&logo=googlechrome&logoColor=white)](https://make-it-count-paper.github.io/)  
    [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/Litalby1/make-it-count)

* **[CVPRâ€¯2025]** ***MCCD:*** Multiâ€‘Agent Collaborationâ€‘based Compositional Diffusion for Complex Textâ€‘toâ€‘Image Generation<br>
    [![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2505.02648)

* **[CVPRâ€¯2025]** ***Debiasâ€‘SD:*** Rethinking Training for Deâ€‘biasing Textâ€‘toâ€‘Image Generation: Unlocking the Potential of Stable Diffusion<br>
    [![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2408.12692)

* **[CVPRâ€¯2025]** ***ShapeWords:*** Guiding Textâ€‘toâ€‘Image Synthesis with 3D Shapeâ€‘Aware Prompts<br>
    [![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2412.02912)  
    [![Project Page](https://img.shields.io/badge/Project-Page-blue?style=for-the-badge&logo=googlechrome&logoColor=white)](https://lodurality.github.io/shapewords/)  
    [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/lodurality/shapewords_paper_code)  
    [![HuggingÂ Face](https://img.shields.io/badge/%F0%9F%A4%97-Hugging_Face-yellow?style=for-the-badge)](https://huggingface.co/spaces/dmpetrov/shapewords)

* **[CVPRâ€¯2025]** ***SnapGen:*** Taming Highâ€‘Resolution Textâ€‘toâ€‘Image Models for Mobile Devices with Efficient Architectures and Training<br>
    [![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2412.09619)  
    [![Project Page](https://img.shields.io/badge/Project-Page-blue?style=for-the-badge&logo=googlechrome&logoColor=white)](https://snap-research.github.io/snapgen/)

* **[CVPRâ€¯2025]** ***STORM:*** Spatial Transport Optimization by Repositioning Attention Map for Trainingâ€‘Free Textâ€‘toâ€‘Image Synthesis<br>
    [![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2503.22168)  
    [![Project Page](https://img.shields.io/badge/Project-Page-blue?style=for-the-badge&logo=googlechrome&logoColor=white)](https://micv-yonsei.github.io/storm2025/)  
    [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/MICV-yonsei/STORM)

* **[CVPRâ€¯2025]** ***Focusâ€‘Nâ€‘Fix:*** Regionâ€‘Aware Fineâ€‘Tuning for Textâ€‘toâ€‘Image Generation<br>
    [![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2501.06481)

* **[CVPRâ€¯2025]** ***SILMM:*** Selfâ€‘Improving Large Multimodal Models for Compositional Textâ€‘toâ€‘Image Generation<br>
    [![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2412.05818)  
    [![Project Page](https://img.shields.io/badge/Project-Page-blue?style=for-the-badge&logo=googlechrome&logoColor=white)](https://silmm.github.io/)  
    [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/LgQu/SILMM)

* **[CVPRâ€¯2025]** ***GLoCE:*** Localized Concept Erasure for Textâ€‘toâ€‘Image Diffusion Models Using Trainingâ€‘Free Gated Lowâ€‘Rank Adaptation<br>
    [![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2503.12356)  
    [![Project Page](https://img.shields.io/badge/Project-Page-blue?style=for-the-badge&logo=googlechrome&logoColor=white)](https://gl-oce.github.io/)  
    [![GitHub](https://img.shields.io/badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/Hyun1A/GLoCE)

* **[CVPRâ€¯2025]** ***Selfâ€‘Cross Guidance:*** Selfâ€‘Cross Diffusion Guidance for Textâ€‘toâ€‘Image Synthesis of Similar Subjects<br>
    [![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2411.18936)  
    [![Project Page](https://img.shields.io/badge/Project-Page-blue?style=for-the-badge&logo=googlechrome&logoColor=white)](https://selfcross-guidance.github.io/)  
    [![GitHub](https://img.shields.io-badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/mengtang-lab/selfcross-guidance)

* **[CVPRâ€¯2025]** ***NoiseÂ Diffusion:*** Enhancing Semantic Faithfulness in Textâ€‘toâ€‘Image Synthesis<br>
    [![Paper](https://img.shields.io/badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2411.16503)  
    [![GitHub](https://img.shields.io-badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/Bomingmiao/NoiseDiffusion)

* **[CVPRâ€¯2025]** ***PromptSampler:*** Learning to Sample Effective and Diverse Prompts for Textâ€‘toâ€‘Image Generation<br>
    [![Paper](https://img.shields.io-badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2410.07838)  
    [![GitHub](https://img.shields.io-badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/dbsxodud-11/PAG)

* **[CVPRâ€¯2025]** ***STEREO:*** A Twoâ€‘Stage Framework for Adversarially Robust Concept Erasing from Textâ€‘toâ€‘Image Diffusion Models<br>
    [![Paper](https://img.shields.io-badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2408.16807)  
    [![GitHub](https://img.shields.io-badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/koushiksrivats/robust-concept-erasing)

* **[CVPRâ€¯2025]** ***MinorityPrompt:*** Minorityâ€‘Focused Textâ€‘toâ€‘Image Generation via Prompt Optimization<br>
    [![Paper](https://img.shields.io-badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2411.16503)  
    [![GitHub](https://img.shields.io-badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/soobin-um/MinorityPrompt)

* **[CVPRâ€¯2025]** ***DistillT5:*** Scaling Down Text Encoders of Textâ€‘toâ€‘Image Diffusion Models<br>
    [![Paper](https://img.shields.io-badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2503.19897)  
    [![GitHub](https://img.shields.io-badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/LifuWang-66/DistillT5)

* **[CVPRâ€¯2025]** ***TIU:*** The Illusion of Unlearning: The Unstable Nature of Machine Unlearning in Textâ€‘toâ€‘Image Diffusion Models<br>
    [![Paper](https://img.shields.io-badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/??? )  
    [![GitHub](https://img.shields.io-badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/NGK2110/TIU)

* **[CVPRâ€¯2025]** ***Fuseâ€‘DiT:*** Exploring the Deep Fusion of Large Language Models and Diffusion Transformers for Textâ€‘toâ€‘Image Synthesis<br>
    [![Paper](https://img.shields.io-badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/??? )  
    [![GitHub](https://img.shields.io-badge/GitHub-Repo-blue?style=for-the-badge&logo=github)](https://github.com/tang-bd/fuse-dit)  
    [![HuggingÂ Face](https://img.shields.io-badge/%F0%9F%A4%97-Hugging_Face-yellow?style=for-the-badge)](https://huggingface.co/ooutlierr/fuse-dit)

* **[CVPRâ€¯2025]** ***Detectâ€‘andâ€‘Guide:*** Selfâ€‘regulation of Diffusion Models for Safe Textâ€‘toâ€‘Image Generation via Guideline Token Optimization<br>
    [![Paper](https://img.shields.io-badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/2503.15197)

* **[CVPRâ€¯2025]** ***Multiâ€‘GroupÂ T2I:*** Multiâ€‘Group Proportional Representations for Textâ€‘toâ€‘Image Models<br>
    [![Paper](https://img.shields.io-badge/Paper-PDF-red?style=for-the-badge)](https://openaccess.thecvf.com/content/CVPR2025/papers/Jung_Multi-Group_Proportional_Representations_for_Text-to-Image_Models_CVPR_2025_paper.pdf)

* **[CVPRâ€¯2025]** ***VODiff:*** Controlling Object Visibility Order in Textâ€‘toâ€‘Image Generation<br>
    [![Paper](https://img.shields.io-badge/Paper-PDF-red?style=for-the-badge)](https://arxiv.org/pdf/???)  

* **[ICLRâ€¯2025]** ***ImprovingÂ Longâ€‘Text Alignment:*** Improving Longâ€‘Text Alignment for Textâ€‘toâ€‘Image Diffusion Models<br>
    [![Paper](https://img.shields.io-badge/Paper-OpenReview-D15E5E?style=for-the-badge&logo=open-collective)](https://openreview.net/forum?id=2ZK8zyIt7o)

* **[ICLRâ€¯2025]** ***ITTA:*** Information Theoretic Textâ€‘toâ€‘Image Alignment<br>
    [![Paper](https://img.shields.io-badge/Paper-OpenReview-D15E5E?style=for-the-badge&logo=open-collective)](https://openreview.net/forum?id=Ugs2W5XFFo)

* **[ICLRâ€¯2025]** ***Meissonic:*** Revitalizing Masked Generative Transformers for Efficient Highâ€‘Resolution Textâ€‘toâ€‘Image Synthesis<br>
    [![Paper](https://img.shields.io-badge/Paper-OpenReview-D15E5E?style=for-the-badge&logo=open-collective)](https://openreview.net/forum?id=GJsuYHhAga)

* **[ICLRâ€¯2025]** ***PaRa:*** Personalizing Textâ€‘toâ€‘Image Diffusion via Parameter Rank Reduction<br>
    [![Paper](https://img.shields.io-badge/Paper-OpenReview-D15E5E?style=for-the-badge&logo=open-collective)](https://openreview.net/forum?id=KZgo2YQbhc)

* **[ICLRâ€¯2025]** ***Fluid:*** Scaling Autoregressive Textâ€‘toâ€‘image Generative Models with Continuous Tokens<br>
    [![Paper](https://img.shields.io-badge/Paper-OpenReview-D15E5E?style=for-the-badge&logo=open-collective)](https://openreview.net/forum?id=jQP5o1VAVc)

* **[ICLRâ€¯2025]** ***Promptâ€‘Pruning:*** Not All Prompts Are Made Equal â€“ Promptâ€‘based Pruning of Textâ€‘toâ€‘Image Diffusion Models<br>
    [![Paper](https://img.shields.io-badge/Paper-OpenReview-D15E5E?style=for-the-badge&logo=open-collective)](https://openreview.net/forum?id=3BhZCfJ73Y)

* **[ICLRâ€¯2025]** ***DenoisingÂ ARÂ Transformers:*** Denoising Autoregressive Transformers for Scalable Textâ€‘toâ€‘Image Generation<br>
    [![Paper](https://img.shields.io-badge/Paper-OpenReview-D15E5E?style=for-the-badge&logo=open-collective)](https://openreview.net/forum?id=amDkNPVWcn)

* **[ICLRâ€¯2025]** ***ProgressiveÂ Compositionality:*** Progressive Compositionality in Textâ€‘toâ€‘Image Generative Models<br>
    [![Paper](https://img.shields.io-badge/Paper-OpenReview-D15E5E?style=for-the-badge&logo=open-collective)](https://openreview.net/forum?id=S85PP4xjFD)

* **[ICLRâ€¯2025]** ***ClassifierÂ Scores:*** Mining your own secrets: Diffusion Classifier Scores for Continual Personalization of Textâ€‘toâ€‘Image Diffusion Models<br>
    [![Paper](https://img.shields.io-badge/Paper-OpenReview-D15E5E?style=for-the-badge&logo=open-collective)](https://openreview.net/forum?id=hUdLs6TqZL)

* **[ICLRâ€¯2025]** ***Engagement:*** Measuring and Improving Engagement of Textâ€‘toâ€‘Image Generation Models<br>
    [![Paper](https://img.shields.io-badge/Paper-OpenReview-D15E5E?style=for-the-badge&logo=open-collective)](https://openreview.net/forum?id=TmCcNuo03f)

* **[ICLRâ€¯2025]** ***ResidualÂ GateÂ Eraser:*** Concept Pinpoint Eraser for Textâ€‘toâ€‘image Diffusion Models via Residual Attention Gate<br>
    [![Paper](https://img.shields.io-badge/Paper-OpenReview-D15E5E?style=for-the-badge&logo=open-collective)](https://openreview.net/forum?id=ZRDhBwKs7l)

* **[ICLRâ€¯2025]** ***RandomÂ Seeds:*** Enhancing Compositional Textâ€‘toâ€‘Image Generation with Reliable Random Seeds<br>
    [![Paper](https://img.shields.io-badge/Paper-OpenReview-D15E5E?style=for-the-badge&logo=open-collective)](https://openreview.net/forum?id=5BSlakturs)

* **[ICLRâ€¯2025]** ***Oneâ€‘Promptâ€‘Oneâ€‘Story:*** Freeâ€‘Lunch Consistent Textâ€‘toâ€‘Image Generation Using a Single Prompt<br>
    [![Paper](https://img.shields.io-badge/Paper-OpenReview-D15E5E?style=for-the-badge&logo=open-collective)](https://openreview.net/forum?id=cD1kl2QKv1)

* **[ICLRâ€¯2025]** ***YouÂ OnlyÂ SampleÂ Once:*** Taming Oneâ€‘Step Textâ€‘toâ€‘Image Synthesis by Selfâ€‘Cooperative Diffusion GANs<br>
    [![Paper](https://img.shields.io-badge/Paper-OpenReview-D15E5E?style=for-the-badge&logo=open-collective)](https://openreview.net/forum?id=T7bmHkwzS6)

* **[ICLRâ€¯2025]** ***CopyrightÂ Revisiting:*** Rethinking Artistic Copyright Infringements in the Era of Textâ€‘toâ€‘Image Generative Models<br>
    [![Paper](https://img.shields.io-badge/Paper-OpenReview-D15E5E?style=for-the-badge&logo=open-collective)](https://openreview.net/forum?id=0OTVNEm9N4)

* **[ICLRâ€¯2025]** ***ConceptÂ CombinationÂ Erasing:*** Erasing Concept Combination from Textâ€‘toâ€‘Image Diffusion Model<br>
    [![Paper](https://img.shields.io-badge/Paper-OpenReview-D15E5E?style=for-the-badge&logo=open-collective)](https://openreview.net/forum?id=OBjF5I4PWg)

* **[ICLRâ€¯2025]** ***Crossâ€‘AttentionÂ Patterns:*** Crossâ€‘Attention Head Position Patterns Can Align with Human Visual Concepts in Textâ€‘toâ€‘Image Generative Models<br>
    [![Paper](https://img.shields.io-badge/Paper-OpenReview-D15E5E?style=for-the-badge&logo=open-collective)](https://openreview.net/forum?id=1vggIT5vvj)

* **[ICLRâ€¯2025]** ***TIGeR:*** Unifying Textâ€‘toâ€‘Image Generation and Retrieval with Large Multimodal Models<br>
    [![Paper](https://img.shields.io-badge/Paper-OpenReview-D15E5E?style=for-the-badge&logo=open-collective)](https://openreview.net/forum?id=mr2icR6dpD)

* **[ICLRâ€¯2025]** ***DGQ:*** Distributionâ€‘Aware Group Quantization for Textâ€‘toâ€‘Image Diffusion Models<br>
    [![Paper](https://img.shields.io-badge/Paper-OpenReview-D15E5E?style=for-the-badge&logo=open-collective)](https://openreview.net/forum?id=ZyNEr7Xw5L)

* **[ICLRâ€¯2025]** ***JacobiÂ Decoding:*** Accelerating Autoâ€‘regressive Textâ€‘toâ€‘Image Generation with Trainingâ€‘free Speculative Jacobi Decoding<br>
    [![Paper](https://img.shields.io-badge/Paper-OpenReview-D15E5E?style=for-the-badge&logo=open-collective)](https://openreview.net/forum?id=LZfjxvqw0N)

* **[ICLRâ€¯2025]** ***PTâ€‘T2I/V:*** An Efficient Proxyâ€‘Tokenized Diffusion Transformer for Textâ€‘toâ€‘Image/Video Task<br>
    [![Paper](https://img.shields.io-badge/Paper-OpenReview-D15E5E?style=for-the-badge&logo=open-collective)](https://openreview.net/forum?id=lTrrnNdkOX)

* **[ICLRâ€¯2025]** ***GeckoÂ Evaluation:*** Revisiting Textâ€‘toâ€‘Image Evaluation with Gecko: on Metrics, Prompts, and Human Rating<br>
    [![Paper](https://img.shields.io-badge/Paper-OpenReview-D15E5E?style=for-the-badge&logo=open-collective)](https://openreview.net/forum?id=Im2neAMlre)

* **[ICLRâ€¯2025]** ***SANA:*** Efficient Highâ€‘Resolution Textâ€‘toâ€‘Image Synthesis with Linear Diffusion Transformers<br>
    [![Paper](https://img.shields.io-badge/Paper-OpenReview-D15E5E?style=for-the-badge&logo=open-collective)](https://openreview.net/forum?id=N8Oj1XhtYZ)

* **[ICLRâ€¯2025]** ***RectifiedÂ Flow:*** Textâ€‘toâ€‘Image Rectified Flow as Plugâ€‘andâ€‘Play Priors<br>
    [![Paper](https://img.shields.io-badge/Paper-OpenReview-D15E5E?style=for-the-badge&logo=open-collective)](https://openreview.net/forum?id=SzPZK856iI)

* **[ICLRâ€¯2025]** ***HumanÂ FeedbackÂ Filtering:*** Automated Filtering of Human Feedback Data for Aligning Textâ€‘toâ€‘Image Diffusion Models<br>
    [![Paper](https://img.shields.io-badge/Paper-OpenReview-D15E5E?style=for-the-badge&logo=open-collective)](https://openreview.net/forum?id=8jvVNPHtVJ)

* **[ICLRâ€¯2025]** ***SAFREE:*** Trainingâ€‘Free and Adaptive Guard for Safe Textâ€‘toâ€‘Image and Video Generation<br>
    [![Paper](https://img.shields.io-badge/Paper-OpenReview-D15E5E?style=for-the-badge&logo=open-collective)](https://openreview.net/forum?id=hgTFotBRKl)

* **[ICLRâ€¯2025]** ***IterComp:*** Iterative Compositionâ€‘Aware Feedback Learning from Model Gallery for Textâ€‘toâ€‘Image Generation<br>
    [![Paper](https://img.shields.io-badge/Paper-OpenReview-D15E5E?style=for-the-badge&logo=open-collective)](https://openreview.net/forum?id=4w99NAikOE)

* **[ICLRâ€¯2025]** ***ScImage:*** How good are multimodal large language models at scientific textâ€‘toâ€‘image generation?<br>
    [![Paper](https://img.shields.io-badge/Paper-OpenReview-D15E5E?style=for-the-badge&logo=open-collective)](https://openreview.net/forum?id=ugyqNEOjoU)

* **[ICLRâ€¯2025]** ***ScoreÂ Distillation:*** Guided Score Identity Distillation for Dataâ€‘Free Oneâ€‘Step Textâ€‘toâ€‘Image Generation<br>
    [![Paper](https://img.shields.io-badge/Paper-OpenReview-D15E5E?style=for-the-badge&logo=open-collective)](https://openreview.net/forum?id=HMVDiaWMwM)

* **[ICLRâ€¯2025]** ***CausalÂ Variation:*** Evaluating Semantic Variation in Textâ€‘toâ€‘Image Synthesis: A Causal Perspective<br>
    [![Paper](https://img.shields.io-badge/Paper-OpenReview-D15E5E?style=for-the-badge&logo=open-collective)](https://openreview.net/forum?id=NWb128pSCb)


<details>
<summary><h4>âœ… Published Papers</h4></summary>

</details>

<details>
<summary><h4>ğŸ’¡ Pre-Print Papers</h4></summary>

</details>

</details>

<details>
<summary><h4>âœ¨ 2024</h4></summary>

<details>
<summary><h4>âœ… Published Papers</h4></summary>

</details>

<details>
<summary><h4>ğŸ’¡ Pre-Print Papers</h4></summary>

</details>

</details>

<details>
<summary><h4>âœ¨ 2023</h4></summary>

<details>
<summary><h4>âœ… Published Papers</h4></summary>

</details>

<details>
<summary><h4>ğŸ’¡ Pre-Print Papers</h4></summary>

</details>

</details>

[<small>â‡§ Back to ToC</small>](#contents)

### <span id="conditional">ğŸ•¹ï¸ Conditional Image Generation</span>

<details>
<summary><h4>âœ¨ 2025</h4></summary>

<details>
<summary><h4>âœ… Published Papers</h4></summary>

</details>

<details>
<summary><h4>ğŸ’¡ Pre-Print Papers</h4></summary>

</details>

</details>

<details>
<summary><h4>âœ¨ 2024</h4></summary>

<details>
<summary><h4>âœ… Published Papers</h4></summary>

</details>

<details>
<summary><h4>ğŸ’¡ Pre-Print Papers</h4></summary>

</details>

</details>

<details>
<summary><h4>âœ¨ 2023</h4></summary>

<details>
<summary><h4>âœ… Published Papers</h4></summary>

</details>

<details>
<summary><h4>ğŸ’¡ Pre-Print Papers</h4></summary>

</details>

</details>

[<small>â‡§ Back to ToC</small>](#contents)

### <span id="personalized">ğŸ¨ Personalized Image Generation</span>

<details>
<summary><h4>âœ¨ 2025</h4></summary>

<details>
<summary><h4>âœ… Published Papers</h4></summary>

</details>

<details>
<summary><h4>ğŸ’¡ Pre-Print Papers</h4></summary>

</details>

</details>

<details>
<summary><h4>âœ¨ 2024</h4></summary>

<details>
<summary><h4>âœ… Published Papers</h4></summary>

</details>

<details>
<summary><h4>ğŸ’¡ Pre-Print Papers</h4></summary>

</details>

</details>

<details>
<summary><h4>âœ¨ 2023</h4></summary>

<details>
<summary><h4>âœ… Published Papers</h4></summary>

</details>

<details>
<summary><h4>ğŸ’¡ Pre-Print Papers</h4></summary>

</details>

</details>

[<small>â‡§ Back to ToC</small>](#contents)

### <span id="editing">âœ‚ï¸ Image Editing</span>

<details>
<summary><h4>âœ¨ 2025</h4></summary>

<details>
<summary><h4>âœ… Published Papers</h4></summary>

</details>

<details>
<summary><h4>ğŸ’¡ Pre-Print Papers</h4></summary>

</details>

</details>

<details>
<summary><h4>âœ¨ 2024</h4></summary>

<details>
<summary><h4>âœ… Published Papers</h4></summary>

</details>

<details>
<summary><h4>ğŸ’¡ Pre-Print Papers</h4></summary>

</details>

</details>

<details>
<summary><h4>âœ¨ 2023</h4></summary>

<details>
<summary><h4>âœ… Published Papers</h4></summary>

</details>

<details>
<summary><h4>ğŸ’¡ Pre-Print Papers</h4></summary>

</details>

</details>

[<small>â‡§ Back to ToC</small>](#contents)



---

## <span id="datasets">ğŸ—‚ï¸ Datasets</span>
| Dataset Name | Year | Modalities | Task | Paper | Link |
| :--- | :--- | :--- | :--- | :---: | :---: |
| **MS COCO** | 2014 | Text, Image | Text-to-Image Generation, Image Captioning | [![Paper](https://img.shields.io/badge/Paper-Link-red?style=for-the-badge)](https://arxiv.org/abs/1405.0312) | [![Website](https://img.shields.io/badge/Website-Link-orange?style=for-the-badge)](https://cocodataset.org/#home) |
| **Oxford-120 Flowers**| 2008 | Text, Image | Text-to-Image Generation | [![Paper](https://img.shields.io/badge/Paper-Link-red?style=for-the-badge)](https://www.robots.ox.ac.uk/~vgg/publications/2008/Nilsback08/nilsback08.pdf) | [![Website](https://img.shields.io/badge/Website-Link-orange?style=for-the-badge)](https://www.robots.ox.ac.uk/~vgg/data/flowers/102/) |
| **CUB-200-2011** | 2011 | Text, Image | Text-to-Image Generation | [![Paper](https://img.shields.io/badge/Paper-Link-red?style=for-the-badge)](https://resolver.caltech.edu/CaltechCSTR:2010.001) | [![Website](https://img.shields.io/badge/Website-Link-orange?style=for-the-badge)](http://www.vision.caltech.edu/datasets/cub_200_2011/) |
| **LAION-5B** | 2022 | Text, Image | Text-to-Image Generation | [![Paper](https://img.shields.io/badge/Paper-Link-red?style=for-the-badge)](https://arxiv.org/abs/2210.08402) | [![Website](https://img.shields.io/badge/Website-Link-orange?style=for-the-badge)](https://laion.ai/blog/laion-5b/) |
| **DiffusionDB** | 2022 | Text, Image | Text-to-Image Generation | [![Paper](https://img.shields.io/badge/Paper-Link-red?style=for-the-badge)](https://arxiv.org/abs/2210.14896) | [![Website](https://img.shields.io/badge/Website-Link-orange?style=for-the-badge)](https://poloclub.github.io/diffusiondb/) |

[<small>â‡§ Back to ToC</small>](#contents)

---

## <span id="about-us">ğŸ“ About Us</span>

QuenithAI is a professional organization composed of top researchers, dedicated to providing high-quality 1-on-1 research mentoring for university students worldwide. Our mission is to help students bridge the gap from theoretical knowledge to cutting-edge research and publish their work in top-tier conferences and journals.

Maintaining this `Awesome Text-to-Image Generation` list requires significant effort, just as completing a high-quality paper requires focused dedication and expert guidance. If you're looking for one-on-one support from top scholars on your own research project, to quickly identify innovative ideas and make publications, we invite you to contact us ASAP.

â¡ï¸ **Contact us via [WeChat](assets/wechat.jpg) or [E-mail](mailto:your.email@example.com) to start your research journey.**

---

ã€Œåº”è¾¾å­¦æœ¯ã€(QuenithAI) æ˜¯ä¸€å®¶ç”±é¡¶å°–ç ”ç©¶è€…ç»„æˆï¼Œè‡´åŠ›äºä¸ºå…¨çƒé«˜æ ¡å­¦ç”Ÿæä¾›é«˜è´¨é‡1V1ç§‘ç ”è¾…å¯¼çš„ä¸“ä¸šæœºæ„ã€‚æˆ‘ä»¬çš„ä½¿å‘½æ˜¯å¸®åŠ©å­¦ç”ŸåŸ¹å…»å‡ºè‰²å“è¶Šçš„ç§‘ç ”æŠ€èƒ½ï¼Œåœ¨é¡¶çº§ä¼šè®®å’ŒæœŸåˆŠä¸Šå‘è¡¨è‡ªå·±çš„æˆæœã€‚

ç»´æŠ¤ä¸€ä¸ªGitHubè°ƒç ”ä»“åº“éœ€è¦å·¨å¤§çš„ç²¾åŠ›ï¼Œæ­£å¦‚å®Œæˆä¸€ç¯‡é«˜è´¨é‡çš„è®ºæ–‡ä¸€æ ·ï¼Œç¦»ä¸å¼€ä¸“æ³¨çš„æŠ•å…¥å’Œä¸“ä¸šçš„æŒ‡å¯¼ã€‚å¦‚æœæ‚¨å¸Œæœ›åœ¨è‡ªå·±çš„ç ”ç©¶é¡¹ç›®ä¸­ï¼Œè·å¾—æ¥è‡ªé¡¶å°–å­¦è€…çš„ä¸€å¯¹ä¸€æ”¯æŒï¼Œæˆ‘ä»¬è¯šé‚€æ‚¨ä¸æˆ‘ä»¬å–å¾—è”ç³»ã€‚

â¡ï¸ **æ¬¢è¿é€šè¿‡ [å¾®ä¿¡](assets/wechat.jpg) æˆ– [é‚®ä»¶](mailto:your.email@example.com) è”ç³»æˆ‘ä»¬ï¼Œå¼€å¯æ‚¨çš„ç§‘ç ”ä¹‹æ—…ã€‚**


[<small>â‡§ Back to ToC</small>](#contents)

---



## <span id="contributing">ğŸ¤ Contributing</span>

Contributions are welcome! Please see our [**Contribution Guidelines**](CONTRIBUTING.md) for details on how to add new papers, correct information, or improve the repository.